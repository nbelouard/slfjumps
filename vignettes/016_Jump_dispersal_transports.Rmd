---
title: "Making the most of invasion records, the case of the spotted lanternfly, part II: Testing the significance of the location of jumpers, diffusers, and non-detections"
author: 
- Nadege Belouard^[Temple University, nadege.belouard@temple.edu]
- Sebastiona De Bona^[Temple University, seba.debona@temple.edu]
- Jocelyn E. Behm^[Temple University, jebehm@temple.edu]
- Matthew R. Helmus^[Temple University, mrhelmus@temple.edu]
date: "5/1/2021"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 2
  html_document:
    toc: TRUE
    toc_depth: 3
params:
  show_code: FALSE
  export_figures: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup for rendering, include = F}
# here we set the images to png, to reduce the size of the output
# we set some global paramters in the yaml to allow us to switch the chunks
# of code on and off when displaying
knitr::opts_chunk$set(dpi = 300, echo = params$show_code)
```

# 1. Aim and setup
 
For this second vignette, we want to test the anthropogenic character of jump events identified in the first vignette. Our working hypotheses are that (1) SLF hitchhike on roads, railroads, and regional planes, and thus, establish along major transport infrastructures, and (2) SLF get trapped and transported with materials and are dropped at their destination (international airports, intermodal platforms, mail carriers, gathering points, landscaping companies...). To test the significance of this pattern, we measure the distance between the location of jump events (SLF hereafter called 'jumpers') and each type of transport infrastructure. 

Then:   

- To determine whether these jumps are situated significantly closer than random to transport infrastructures, we compare the average value of this distance to a null distribution.  

- To make sure that any significant result would not be due to surveys being conducted mostly close to transport infrastructures, we also calculate the distance to transport infrastructures for SLF established through diffusive spread (SLF hereafter called 'diffusers'), and for surveys that did not detect SLF (hereafter 'undetected'). We test the significance of the distance to transport infrastructures for these two categories using random distributions again.  

- Finally, we test whether jumpers are found significantly closer to transport infrastructures than diffusers or undetected, to see if there is also a direct and significant difference between these categories.  

## Load packages
```{r states names and centroid for global map, message = FALSE, warning = FALSE, echo = params$display}

library(tidyverse)
library(sf)
library(spData)
# library(RVAideMemoire)
library(dplyr)
library(gridExtra)
library(magrittr)
# library(purrr)
library(here)
# library(FSA)
library(ape)
library(spdep)
library(leaflet)
library(slfjumps)

sf::sf_use_s2(FALSE)
```

## States map
```{r states names and centroid for global map, message = FALSE, warning = FALSE, echo = params$display}
# extracts a map of the States and recodes state labels to show the two-letter code rather than the full state name.

# obtaining simple feature objects for states and finding centroids for label positioning
states <- sf::st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))
# sf::st_as_sf(maps::map("county", plot = TRUE, fill = FALSE))
states <- cbind(states, st_coordinates(st_centroid(states)))

# making table key for state 2-letter abbreviations
# the vectors state.abb and state.name contains strings of all
# US states and abbreviations
state_abbr <- tibble(state.name = str_to_lower(state.name), state.abb) %>%
  left_join(tibble(ID = states$ID), ., by = c(ID = "state.name")) %>%
  mutate(state.abb = replace_na(state.abb, ""))

# adding 2-letter codes to sf
states$code <- state_abbr$state.abb


# More precise map
US <- st_read("C:/Users/labuser/Documents/Postdoc_SLF/SLF_Dispersal/data/raw_data/states/gadm36_Cont_USA_county/gadm36_Cont_USA_county.shp", crs = "EPSG:4326", quiet = T)
st_crs(US)
US <- st_transform(US, crs = "ESRI:102010")

```



# 2. Calculate distances of SLF to transport infrastructures

## Prepare the SLF dataset
Load the dataset for the SLF data
```{r load datasets, message = FALSE, warning = FALSE}

# SLF data (in the folder SLF_datascience)
# First, load the dataset that contains the location of each survey
grid_data <- read.csv(file.path(here(), "exported-data", "grid_data.csv"))
head(grid_data)
dim(grid_data) #58144
unique(grid_data$bio_year)
dim(grid_data %>% filter(slf_established == T))

# We can eliminate points at longitudes west of -90 to eliminate some useless points
grid_data %<>% filter(longitude_rounded > -90)
dim(grid_data) #58144
dim(grid_data %>% filter(slf_established == T))[1] #the number of positive points did not change (7044)
```


Select only points in the convex hull of positive points

To avoid biasing the landscape analysis towards significance by using negative points over areas that SLF have not reached so far, we subset the dataset to keep only surveys within the convex hull of all positive points (Figure S1). 

1. Create the minimum convex polygon of the SLF data
```{r create chull}

grid_data <- st_as_sf(x = grid_data, 
                               coords = c("longitude_rounded", "latitude_rounded"), 
                               crs = "EPSG:4269", remove = F)
grid_data_WGS <- st_transform(grid_data, crs = "ESRI:102010")
grid_data_positive <- grid_data_WGS %>% filter(slf_established == TRUE)
dim(grid_data_positive) #7044
hull <- st_convex_hull(st_union(grid_data_positive))

st_area(hull)
st_crs(hull)


# early_surveys <- grid_data_positive %>% filter(bio_year %in% c(2014:2017))
# early_hull <- st_convex_hull(st_union(early_surveys))
# st_area(early_hull)

#Verify that no positive point is left in grid_data
setdiff(grid_data, grid_data_positive) %>% filter(slf_established) #0

# Visualize points and chull
chull <- ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = grid_data, aes(col = slf_established)) +
  geom_sf(data = hull, alpha = 0.5, fill = "white") + 
  labs(x = "Longitude", y = "Latitude") +
  # coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)
  coord_sf(xlim = c(-83, -72), ylim = c(37, 44), expand = FALSE)

chull

# save the polygon
st_write(hull, file.path(here(), "figures", "GIS", "chull.shp"), driver = "ESRI Shapefile", append = F)
```


2. Keep only the points that are in the chull
```{r subset grid data}
dim(grid_data) #58144
dim(grid_data %>% filter(slf_established)) #7044

hull <- st_read(file.path(here(), "figures", "GIS", "chull.shp"), quiet = T) 
st_crs(hull)
hull_WGS <- st_transform(hull, crs = "ESRI:102010")


# We need to make a small buffer around the chull so that points that make the bounding box are included in it!
chull <- st_buffer(hull_WGS, dist = 100)
grid_data_chull <- st_intersection(grid_data_WGS, chull)
dim(grid_data_chull) #45964, lower than grid_data
dim(grid_data_chull %>% filter(slf_established)) #7044, same as grid_data
head(grid_data_chull)

ggplot(data = states, fill = "white") +
  geom_sf() +
  # geom_sf(data = grid_data, col = "black") +
  geom_sf(data = grid_data_chull, col = "blue") +
  geom_sf(data = chull, alpha = 0, col = "black") +
  labs(x = "Longitude", y = "Latitude") #+
  # coord_sf(xlim = c(-81, -73), ylim = c(38, 43))


# save the dataset
st_geometry(grid_data_chull) <- NULL
write.csv(grid_data_chull, file.path(here(), "exported-data", "grid_data_chull.csv"), row.names = F)

```


3. Summarise it so that we calculate the distances for each point only once
```{r summarize grid dataset}
# Extract each point independently of the year it was sampled (for distance calculations)
grid_data_chull <- read.csv(file.path(here(),  "exported-data", "grid_data_chull.csv"), h=T)
dim(grid_data_chull) #45964
head(grid_data_chull)

# are there still duplicated rows?
anyDuplicated(grid_data_chull %>% 
                select(longitude_rounded, latitude_rounded))

grid_chull_unique <- grid_data_chull %>%
  select(latitude_rounded, longitude_rounded) %>% 
  distinct(latitude_rounded, longitude_rounded)
dim(grid_chull_unique) #32911
head(grid_chull_unique)

# are there still duplicated rows?
anyDuplicated(grid_chull_unique %>% 
                select(longitude_rounded, latitude_rounded))

# Visualize the data
grid_unique_layer <- st_as_sf(x = grid_chull_unique, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)

# Visualize the data
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  # geom_sf(data = grid_data_chull, col = "red") +
  geom_sf(data = grid_unique_layer, col = "blue") +
    labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)

# save the dataset
write.csv(grid_chull_unique, file.path(here(), "exported-data", "grid_chull_unique.csv"), row.names = F)

```



## Prepare the railroad and road datasets

1. Load the GIS shapefiles for the landscape data

```{r load landscape features, message = FALSE, warning = FALSE}

#Shapefiles for:

## SLF dropped along the way:
# Railroads (lines, buffer radius = 5 m)
# These are railroads as defined by the USGS National Transportation Dataset. All lines have been merged and projected before buffer construction.
rail <- st_read(file.path(here(), "figures", "GIS", "Railways_full_buffer5m.shp"), quiet = T)
st_crs(rail)
# Roads (lines, buffer radius = 15 m)
# This shapefile contains primary and secondary roads as defined by the US Census bureau. There is no information on traffic volume (AADT). All lines have been merged and projected before buffer construction.
road <- st_read(file.path(here(), "figures", "GIS", "road_buffer15m.shp"), quiet = T)
st_crs(road)

```


2. Make a buffer around the chull to subset the lansdscape features
We use a buffer because for points close to the border of the chull, the closest rail or road might be outside of the chull
```{r buffer around chull, message = FALSE, warning = FALSE}

hull <- st_read(file.path(here(), "figures", "GIS", "chull.shp"), quiet = T)
# We need to project the hull for homogeneity with road and rails
st_crs(hull)
chull <- st_transform(hull, crs = "ESRI:102010")
chull_buffer <- st_buffer(chull, dist = 100000) #100 km to be sure

# Visualize points and chull
ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = chull_buffer, alpha = 0.5, fill = "white") +
  geom_sf(data = chull, alpha = 0.5, fill = "yellow") + 
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)

```


3. Subset rails and roads within the chull
```{r load landscape features, message = FALSE, warning = FALSE}

rail_chull <- st_intersection(rail, chull_buffer)
st_write(rail_chull, file.path(here(), "figures", "GIS", "rail_chull.shp"), driver = "ESRI Shapefile")

road_chull <- st_intersection(road, chull_buffer)
st_write(road_chull, file.path(here(), "figures", "GIS", "road_chull.shp"), driver = "ESRI Shapefile")

# Visualize landscape features and chull
ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = rail_chull, alpha = 0.5, col = "black") +
  # geom_sf(data = road_chull, alpha = 0.5, col = "red") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)

```


## Intersection of layers
4. Create a layer for the intersect of rail and road
```{r intersect of rail and road}

# Create a buffer around rail
rail_chull <- st_read(file.path(here(), "figures", "GIS", "rail_chull.shp"))
st_crs(rail_chull)
rail_buffer200 <- st_buffer(rail_chull, dist = 200)
rail_buffer100 <- st_buffer(rail_chull, dist = 100)

# Create a buffer around roads
road_chull <- st_read(file.path(here(), "figures", "GIS", "road_chull.shp"))
st_crs(road_chull)
road_buffer200 <- st_buffer(road_chull, dist = 200)
road_buffer100 <- st_buffer(road_chull, dist = 100)

# Their intersect
roadrail_intersect200 <- st_intersection(rail_buffer200, road_buffer200)

#dissolve the polygon
roadrail_intersect200 %<>% 
  st_union() %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84") 
st_write(roadrail_intersect200, file.path(here(), "figures", "GIS", "roadrail200m_union.shp"), driver = "ESRI Shapefile")



roadrail_intersect100 <- st_intersection(rail_buffer100, road_buffer100)

#dissolve the polygon
roadrail_intersect100 %<>% 
  st_union() %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84") 
st_write(roadrail_intersect100, file.path(here(), "figures", "GIS", "roadrail100m_union.shp"), driver = "ESRI Shapefile")

```


## Calculate the distances of each observed point to transport infrastructure

Distance to rail and roads
```{r distance of SLF to transport infrastructures, eval = FALSE}

grid_chull_unique <- read.csv(file.path(here(), "exported-data", "grid_chull_unique.csv"))
dim(grid_chull_unique)
head(grid_chull_unique)

grid_transports <- st_as_sf(x = grid_chull_unique, 
                            coords = c("longitude_rounded", "latitude_rounded"), 
                            crs = "EPSG:4269", remove = F)
grid_transports <- st_transform(grid_transports, crs = "ESRI:102010")

# Create rows for distances
grid_transports %<>% add_column(DistToRail = NA,
                          DistToRoad = NA)

# Load landscape data
rail_chull <- st_read(file.path(here(), "figures", "GIS", "rail_chull.shp"), quiet = T)
road_chull <- st_read(file.path(here(), "figures", "GIS", "road_chull.shp"), quiet = T)


#Calculate their distance to transport infrastructures
for (j in 1:length(grid_transports$DistToRail)){ 
  # Print the row being considered
  print(j)
  
  point_clip <- st_buffer(grid_transports[j,], dist = 50000)
  
  # Calculate distance to the closest railroad
  rail_clip <- st_intersection(rail_chull, point_clip)
  dist_rail <- st_distance(x = grid_transports[j,], y = rail_clip)
  grid_transports$DistToRail[j] <- min(dist_rail)
  rm(rail_clip)
  
  # Calculate distance to the closest major road
  road_clip <- st_intersection(road_chull, point_clip)
  dist_road <- st_distance(x = grid_transports[j,], y = road_clip)
  grid_transports$DistToRoad[j] <- min(dist_road)
  
  rm(point_clip, road_clip)
  
  if (j %% 1000 == 0){
    st_write(grid_transports, file.path(here(), "exported-data", "obs_distances_transport_TEST.shp"), driver = "ESRI Shapefile", append = FALSE)
  }
}

sum(is.na(grid_transports$DistToRoad))

# Save file
st_geometry(grid_transports) <- NULL
write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports.csv"), row.names = F)
```


Make sure all distances have been calculated
```{r check distances}
# Distance data
grid_transports <- read.csv(file.path(here(), "exported-data", "distances_observed_transports.csv"), h=T)
head(grid_transports)
dim(grid_transports)

# Check if there are points without distance
grid_transports %>% filter(DistToRail == Inf | is.na(DistToRail))
grid_transports %>% filter(DistToRoad == Inf | is.na(DistToRoad))

# #Calculate the distance for points where they are missing
# grid_transports <- st_as_sf(x = grid_data_chull, 
#                             coords = c("longitude_rounded", "latitude_rounded"), 
#                             crs = "EPSG:4269", remove = F)
# grid_transports <- st_transform(grid_transports, crs = "ESRI:102010")
#     
# # calculate the distance for missing points
# for (j in 1:length(grid_transports$DistToRail)){ 
#   if (grid_transports$DistToRail[j] > 50000){
#     print(j)
# 
#     # Calculate distance to the closest railroad
#     dist_rail <- st_distance(x = grid_transports[j,], y = rail_chull)
#     grid_transports$DistToRail[j] <- min(dist_rail)
#   }
#   
#   if (grid_transports$DistToRoad[j] > 50000){
#     print(j)
# 
#     # Calculate distance to the closest road
#     dist_road <- st_distance(x = grid_transports[j,], y = road_chull)
#     grid_transports$DistToRoad[j] <- min(dist_road)
#   }
# }
# 
# # Check result
# grid_transports %>% filter(DistToRail == Inf | is.na(DistToRail))
# grid_transports %>% filter(DistToRoad == Inf | is.na(DistToRoad))
# 
# # Save file
# st_geometry(grid_transports) <- NULL
# write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports_complete.csv"), row.names = F)
```


Same for the distance to the intersect road/rail
```{r distance of SLF to transport infrastructures, eval = FALSE}

roadrail_intersect <- st_read(file.path(here(), "figures", "GIS", "roadrail100m_union.shp"), quiet = T) %>% 
  st_transform(crs = "ESRI:102010")

grid_transports <- st_read(file.path(here(), "exported-data", "obs_distances_transport.shp"))
st_crs(grid_transports)

# Create rows for distances
grid_transports %<>% add_column(DistIntRlRd = NA)


#Calculate their distance to transport infrastructures
for (j in 1:length(grid_transports$DistIntRlRd)){ 
  # Print the row being considered
  print(j)
  
  point_clip <- st_buffer(grid_transports[j,], dist = 50000)
  
  # Calculate distance to the closest railroad
  rlrd_clip <- st_intersection(roadrail_intersect, point_clip)
  dist_rlrd <- st_distance(x = grid_transports[j,], y = rlrd_clip)
  grid_transports$DistIntRlRd[j] <- min(dist_rlrd)
  rm(point_clip, rlrd_clip)
  
  if (j %% 1000 == 0){
    st_write(grid_transports, file.path(here(), "exported-data", "obs_distances_transport_TEST.shp"), driver = "ESRI Shapefile", append = FALSE)
  }
}


# Save file
st_geometry(grid_transports) <- NULL
write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports.csv"), row.names = F)
```


Make sure all distances have been calculated
```{r check distances}
# Distance data
grid_transports <- read.csv(file.path(here(), "exported-data", "distances_observed_transports.csv"), h=T)

# Check if there are points without distance
grid_transports %>% filter(DistIntRlRd == Inf | is.na(DistIntRlRd))

```

\newpage


# 3. Create datasets for jumpers/diffusers/negatives

We need to associate each point to the fact that it's a jumper, or diffuser, or negative point, by merging the table with observed distances and the table with status.

1. Prepare the tables
```{r choose which dataset you are testing}

grid_transports <- read.csv(file.path(here(), "exported-data", "distances_observed_transports.csv"))
dim(grid_transports)
head(grid_transports)

# Merge it with the grid data to get the whole dataset back, including column slf established
grid_data_chull <- read.csv(file.path(here(), "exported-data", "grid_data_chull.csv"))
dim(grid_data_chull)
head(grid_data_chull)

grid_data_chull %<>% left_join(grid_transports)
head(grid_data_chull)
dim(grid_data_chull)

# Verify if all points got a distance
grid_data_chull %>% filter(DistToRail == Inf | is.na(DistToRail))
grid_data_chull %>% filter(DistToRoad == Inf | is.na(DistToRoad))
grid_data_chull %>% filter(DistIntRlRd == Inf | is.na(DistIntRlRd))

# Create the categories diffusers (if established) or negatives (if not)
grid_data_chull %<>% mutate(Category_out = ifelse(slf_established == TRUE, "Diffusers", "Negatives"))

# Next load the dataset that contains all jumpers identified by sets of parameters
jumpers <- read.csv(file.path(here(), "exported-data", "jumps_full_rarefied.csv"))
jumpers <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))
jumpers %<>% add_column(Category = "Jumpers")
head(jumpers)
```


2. Create full dataset (multiple jumps per location)
```{r create full dataset}

# Put jumpers into the grid data and complete with the rest
grid_full <- grid_data_chull %>% 
  left_join(jumpers %>% select(latitude_rounded, longitude_rounded, slf_established, bio_year, Category, Group)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(grid_full %>% filter(Category == "Jumpers"))[1] == dim(jumpers)[1]
grid_full %<>% rename(Category_full = Category)

grid_full %>% group_by(Category_full) %>% count()
head(grid_full)
```


3. Create rarefied dataset (one jump per location)
```{r create rarefied dataset}

# Put jumpers into the grid data and complete with the rest
grid_rarefied <- grid_data_chull %>% 
  left_join(jumpers %>% filter(Rarefied == TRUE) %>% 
              select(latitude_rounded, longitude_rounded, bio_year, slf_established, Category)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(grid_rarefied %>% filter(Category == "Jumpers"))[1] == dim(jumpers %>% filter(Rarefied == TRUE))[1]
grid_rarefied %<>% rename(Category_rarefied = Category) 

grid_rarefied %>% filter(Category_rarefied == "Jumpers") %>% count()
```


4. Reassemble in one long dataset with one column for the type of dataset
```{r reassemble full and rarefied dataset}
slf_observed <- merge(grid_full, grid_rarefied)
head(slf_observed)
write.csv(slf_observed, file.path(here(), "exported-data", "slf_observed.csv"), row.names = F)
```

\newpage



# 4. Create dataset "as of today" or "most up to date"

Count each point only once as positive or negative (summarise data for each point)
```{r generate a grid of unique points for situation as of 2020}

slf_observed <- read.csv(file.path(here(), "exported-data", "slf_observed.csv"))
slf_observed <- grid_full
dim(slf_observed)
head(slf_observed)

# Show the number of duplicates per point
slf_observed %>% group_by(latitude_rounded, longitude_rounded) %>% count() %>% 
  group_by(n) %>% count(n)

# Order the Category levels
unique(slf_observed$Category_rarefied)
slf_observed$Category_rarefied <- factor(slf_observed$Category_rarefied, levels = c("Negatives", "Diffusers", "Jumpers"))
slf_observed$Category_full <- factor(slf_observed$Category_full, levels = c("Negatives", "Diffusers", "Jumpers"))

# Translate factors into ordinal
slf_uptodate <- slf_observed %>% mutate(
  #Category_rare_num = as.numeric(Category_rarefied),
  Category_full_num = as.numeric(Category_full)) %>%  
  group_by(latitude_rounded, longitude_rounded, DistToRail, DistToRoad, DistIntRlRd) %>% 
  summarize(
    #Category_rare_max = max(Category_rare_num),
    Category_full_max = max(Category_full_num)) %>% 
  mutate(
    #Category_rare = recode(Category_rare_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers"),
    Category_full = recode(Category_full_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers")) %>% 
  select(
    #-Category_rare_max, 
    -Category_full_max)
  

dim(slf_uptodate) #32,911

head(jumpers)
slf_uptodate %<>% left_join(jumpers %>% select(latitude_rounded, longitude_rounded, Group))
head(slf_uptodate)

# Save this file
write.csv(slf_uptodate, file.path(here(), "exported-data", "slf_obs_uptodate.csv"), row.names=F)
```


Calculate statistics
```{r calculate proportions of data}

positive <- slf_uptodate %>% filter(Category_full %in% c("Diffusers", "Jumpers")) 
dim(positive)[1]/dim(slf_uptodate)[1] #17.93%
```

\newpage



# 5. Check for differences in observed means between categories of SLF

## Calculate observed values
```{r distance of jumpers to transport infrastructures}

slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))

# Summary for Category_full
slf_uptodate %>% group_by(Category_full) %>%
  summarise(#medianDistToRail = median(DistToRail), 
            #medianDistToRoad = median(DistToRoad),
            #medianDistIntRlRd = median(DistIntRlRd),
            meanDistToRail = mean(DistToRail), 
            meanDistToRoad = mean(DistToRoad),
            meanDistIntRlRd = mean(DistIntRlRd))

# Summary for Category_rare
slf_uptodate %>% group_by(Category_rare) %>%
  summarise(#medianDistToRail = median(DistToRail),
            #medianDistToRoad = median(DistToRoad),
            #medianDistIntRlRd = median(DistIntRlRd),
            meanDistToRail = mean(DistToRail), 
            meanDistToRoad = mean(DistToRoad),
            meanDistIntRlRd = mean(DistIntRlRd))



```

```{compare jumpers from full and rarefied datasets}

head(slf_uptodate)
# create a dataset for jumpers in rarefied
name <- rbind(slf_uptodate %>% filter(Category_rare == "Jumpers") %>% add_column(Dataset = "Rarefied"),
      slf_uptodate %>% filter(Category_full == "Jumpers") %>%  add_column(Dataset = "Full"))


ggplot(data = name, aes(x = Dataset, y = DistToRail)) +
  geom_boxplot()
```


## Box plot

We have a first look at differences in distances to transport infrastructures between categories (Figure 1). Note that the y axis is truncated to show more clearly the boxes. Refer to the previous section to get the quartiles and maximum values of the variables. 
Jumpers seem to be closer to rail and roads than the other two categories, but there is no visible difference regarding the distance to airports. Diffusers are intermediate between jumpers and undetected for roads and railroads. 

```{r plot histogram of distances between jumpers, diffusers, undetected, fig.height=5, fig.width = 6, fig.cap="Distance of jumpers, diffusers and non-detections to railroads (top), roads (middle), and airports (bottom). The y axis is truncated to better show the boxes. Refer to section 1 for variables summary."}

slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))
head(slf_uptodate)

#Modify dataset to get distribution of distances with a column for the type of distance (Road, Rail...), and one column for the type of dataset (Full or Rarefied)
slf_uptodate_long <- slf_uptodate %>% 
  pivot_longer(cols = starts_with("Dist"), names_to = "DistanceType", values_to = "DistanceValue")

# Order the variables (for plots)
unique(slf_uptodate_long$Category_full)
slf_uptodate_long$Category_full <- factor(slf_uptodate_long$Category_full, levels = c("Jumpers", "Diffusers", "Negatives"))

unique(slf_uptodate_long$Category_rare)
slf_uptodate_long$Category_rare <- factor(slf_uptodate_long$Category_rare, levels = c("Jumpers", "Diffusers", "Negatives"))

slf_uptodate_long$DistanceType <- factor(slf_uptodate_long$DistanceType, levels = c("DistToRoad", "DistToRail", "DistIntRlRd"))

slf_uptodate_long %>% group_by(Category_rare, DistanceType) %>% count()



# Plot distances (full dataset)
transport_bp <- ggplot(slf_uptodate_long, aes(y = DistanceValue/1000, x = Category_full)) + 
  geom_boxplot(aes(fill = Category_full), 
               show.legend = F,
               # outlier.shape = NA
               ) +
  scale_fill_brewer(palette = "Dark2") +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 4, 
             labeller = labeller(DistanceType = 
    c("DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Intersection of railroads and roads"))) +
  # coord_cartesian(ylim=c(0, 16)) +
  xlab("Category") + ylab("Distance to the nearest... (km)") +
  theme_classic()

transport_bp

ggsave(file.path(here(), "figures", "jump_transports", "1bis. boxplot transport_fulldata.jpg"), transport_bp, width = 5, height = 3)


# Plot distances (rarefied dataset)
transport_bp <- ggplot(slf_uptodate_long, aes(y = DistanceValue/1000, x = Category_rare)) + 
  geom_boxplot(aes(fill = Category_rare), alpha = 0.5, show.legend = F) +
  scale_fill_brewer(palette = "Dark2") +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 4,
              labeller = labeller(DistanceType =
    c("DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Intersection of railroads and roads"))) +
  xlab("Category") + ylab("Distance to the nearest... (km)") +
  theme_classic()

transport_bp

ggsave(file.path(here(), "figures", "jump_transports", "2bis. boxplot transport_rarefieddata.jpg"), transport_bp, width = 5, height = 3)

```


## Statistical test 

Test of the difference of the means between jumpers, diffusers and non-detections


Power analysis: how likely are we to find a significant result?
```{r power analysis}
library(pwr)
# install.packages("pwr")

# The F test has numerator and denominator degrees of freedom (see summary of lm!). The numerator degrees of freedom, u, is the number of coefficients you'll have in your model (minus the intercept). In our example, u = 2. The denominator degrees of freedom, v, is the number of error degrees of freedom: v = n − u − 1. This implies n = v + u + 1.

# The effect size, f2, is R2/(1−R2), where R2 is the coefficient of determination, aka the “proportion of variance explained”. To determine effect size you hypothesize the proportion of variance your model explains, or the R2. For example, if I think my model explains 45% of the variance in my dependent variable, the effect size is 0.45/(1 - 0.45) ≈ 0.81.

#Here, we have 135 jumps + 135 diffusers + 135 negatives = 405 individuals in the full dataset
# and 37 jumps + 37 diffusers + 37 negatives = 111 individuals in the rarefied dataset.
# we have 3 parameters in the model
# so u = 3 and v = 405 - 3 - 1 = 401 for the full dataset
# so u = 3 and v = 111 - 3 - 1 = 107 for the rarefied dataset

# Imagining a model with a small (0.05) to moderate (0.1) effect size
pwr.f2.test(u = 3, 
            v = 401, 
            f2 = 0.1, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power > 0.99

pwr.f2.test(u = 3, 
            v = 401, 
            f2 = 0.05, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.98

# So there is a high chance of finding even a significant result with even a small effect size with the full dataset


pwr.f2.test(u = 3, 
            v = 107, 
            f2 = 0.1, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.79

pwr.f2.test(u = 3, 
            v = 107, 
            f2 = 0.05, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.47


#And now for PA only:
# Imagining a model with a small (0.05) to moderate (0.1) effect size
pwr.f2.test(u = 3, 
            v = 243, 
            f2 = 0.1, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power > 0.99

pwr.f2.test(u = 3, 
            v = 243, 
            f2 = 0.05, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.85

```



##1. Test autocorrelation
Because we are calculating distances between points and landscape features, we need to test if there is any autocorrelation in the dataset.

``` {r test autocorrelation}
# Detect spatial autocorrelation in the datasets 

# Start with the rarefied dataset
Jumpers <- slf_uptodate %>% filter(Category_rare == "Jumpers")

# Calculate the matrix of coordinates
distLonLat <- as.matrix(dist(cbind(Jumpers$longitude_rounded, Jumpers$latitude_rounded)))
distLonLat.inv <- 1/distLonLat
diag(distLonLat.inv) <- 0

Moran.I(Jumpers$DistToRail, distLonLat.inv)
# $observed: # [1] 0.02370837
# $expected: # [1] -0.02777778
# $sd: # [1] 0.03475753
# $p.value: # [1] 0.138528

Moran.I(Jumpers$DistToRoad, distLonLat.inv)
# $observed: [1] -0.01918829
# $expected: [1] -0.02777778
# $sd: [1] 0.03460668
# $p.value: [1] 0.8039772



# Continue with the full dataset
Jumpers <- slf_uptodate %>% filter(Category_full == "Jumpers")

distLonLat <- as.matrix(dist(cbind(Jumpers$longitude_rounded, Jumpers$latitude_rounded)))
distLonLat.inv <- 1/distLonLat
diag(distLonLat.inv) <- 0

Moran.I(Jumpers$DistToRail, distLonLat.inv)
# $observed: # [1] 0.3414846
# $expected: # [1] -0.007246377
# $sd: # [1] 0.02978898
# $p.value: # [1] 0 ***

Moran.I(Jumpers$DistToRoad, distLonLat.inv)
# $observed: # [1] 0.1339166
# $expected: # [1] -0.007246377
# $sd: # [1] 0.03139476
# $p.value: # [1] 6.911767e-06 ***


# Now do the same for diffusers
# Detect spatial autocorrelation in the datasets
Diffusers <- slf_uptodate %>% filter(Category_rare == "Diffusers")

distLonLat <- as.matrix(dist(cbind(Diffusers$longitude_rounded, Diffusers$latitude_rounded)))
distLonLat.inv <- 1/distLonLat
diag(distLonLat.inv) <- 0

Moran.I(Diffusers$DistToRail, distLonLat.inv) #error
# $observed = 0.0866
# $expected = -0.000170
# $sd = 0.000454
# $p.value = 0

Moran.I(Diffusers$DistToRoad, distLonLat.inv)
# $observed = 0.088
# $expected = -0.0001705611
# $sd = 0.0004544
# $p.value = 0

```

There is major autocorrelation in the dataset! We will use a linear model to compare the categories and add a coefficient to account for autocorrelation.




## 2. Linear model + random effect

```{r load model data}

slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))
dim(slf_uptodate) #32911
head(slf_uptodate)

# Let's try with just jumpers and diffusers as a test
# slf_uptodate %<>% filter(Category_full %in% c("Jumpers", "Diffusers")) 
# dim(slf_uptodate) #5901
```

Because of large differences in sample sizes between categories, we need to resample negatives with n = n(Jumpers), then run the model, x 10,000 times 

### Full dataset
Note: a version with only diffusers and jumpers was calculated and is called "full_pos"
```{r lm with ac, echo = FALSE}
library(lme4)
ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
#Diffusers_full <- slf_uptodate %>% filter(Category_full == "Diffusers")
Negatives_full <- slf_uptodate %>% filter(Category_full == "Negatives")
Jumpers_full <- slf_uptodate %>% filter(Category_full == "Jumpers")
njumpers_full = dim(Jumpers_full)[1]


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  # Diffusers_full_sample <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]
  Negatives_full_sample <- Negatives_full[sample(nrow(Negatives_full), size = njumpers_full, replace = FALSE),]
  # Make a new dataset
  dataset <- rbind(Jumpers_full, 
                   #Diffusers_full_sample,
                   Negatives_full_sample)
  dataset <- group_jumps(dataset, gap_size = 15)
  #Make a matrix of coordinates 
  # coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  # ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  # if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC railroad")}
  # dataset %<>% add_column(ac_rail = ac_railroad)
  
  # Run model
  modRail <- lmer(log(DistToRail+1) ~ Category_full + (1|Group), data = dataset)
      # library(RVAideMemoire)
  # plotresid(modRail_ac)
  anova_modRail <- car::Anova(modRail)
  summary_modRail <- summary(modRail)
  ModelsRail <- rbind(ModelsRail, 
                      c(summary_modRail$coefficients[c(1:2)], 
                      anova_modRail$`Pr(>Chisq)`)) 
  #estimates: intercept, diffusers-negatives; 
  #p-values: category
  
  
    ## 2. Model for road distance:
  # Calculate ac coefficients
  # ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  # if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  # dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad <- lmer(log(DistToRoad+1) ~ Category_full + (1|Group), data = dataset)
  # plotresid(modRoad_ac)
  anova_modRoad <- car::Anova(modRoad)
  summary_modRoad <- summary(modRoad)
  ModelsRoad <- rbind(ModelsRoad, 
                      c(summary_modRoad$coefficients[c(1:2)],  #for pos only, use 1:3, 10:12 
                      anova_modRoad$`Pr(>Chisq)`)) 
  #estimates: intercept, diffusers-negatives; 
  #p-values: category
  
  
  
  ## 3. Model for intersections:
  # Calculate ac coefficients
  # ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  # if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  # dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt <- lmer(log(DistIntRlRd+1) ~ Category_full + (1|Group), data = dataset)
  # plotresid(modInt_ac)
  anova_modInt <- car::Anova(modInt)
  summary_modInt <- summary(modInt)
  ModelsInt <- rbind(ModelsInt, 
                     c(summary_modInt$coefficients[c(1:2)],  #for pos only, use 1:3, 10:12 
                      anova_modRoad$`Pr(>Chisq)`)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "NJ_est", "NJp")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_full_lmer.csv"))

ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "NJ_est", "NJp")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_full_lmer.csv"))

ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "NJ_est", "NJp")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_full_lmer.csv"))

```


Visualize full dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "linear_models_transports", "ModelsRail_full.csv"))

ModelsRail %>% mutate(NJsignif = ifelse(NJp > 0.05, "NS", "S")) %>% 
  count(NJsignif)
#DN NS = 43, S = 9957 --> difference between negatives and diffusers extremely significant
#DJ NS = 17, S = 9983 --> difference between diffusers and jumpers extremely significant

```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "linear_models_transports", "ModelsRoad_full.csv"))

ModelsRoad %>% mutate(NJsignif = ifelse(NJp > 0.05, "NS", "S")) %>% 
  count(NJsignif)
#DN NS = 8528, S = 1472 --> difference between negatives and diffusers non-significant
#DJ NS = 296, S = 9704 --> difference between diffusers and jumpers is significant

```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}

ModelsInt <- read.csv(file.path(here(), "tables", "linear_models_transports", "ModelsInt_full.csv"))

ModelsInt %>% mutate(NJsignif = ifelse(NJp > 0.05, "NS", "S")) %>% 
  count(NJsignif)
#DN, NS = 216, S = 9784 --> difference between negatives and diffusers is significant
#DJ, NS = 9, S = 9991 --> difference between diffusers and jumpers is extremely significant

```




### Rarefied dataset 
Note: a version with only diffusers and jumpers was calculated and is called "rarefied_pos"
```{r lm with ac, echo = FALSE}

ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_rare <- slf_uptodate %>% filter(Category_rare == "Diffusers")
Negatives_rare <- slf_uptodate %>% filter(Category_rare == "Negatives")
Jumpers_rare <- slf_uptodate %>% filter(Category_rare == "Jumpers")
njumpers_rare = dim(Jumpers_rare)


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  Diffusers_rare_sample <- Diffusers_rare[sample(nrow(Diffusers_rare), size = njumpers_rare, replace = FALSE),]
  Negatives_rare_sample <- Negatives_rare[sample(nrow(Negatives_rare), size = njumpers_rare, replace = FALSE),]
  
  # Make a new dataset
  dataset <- rbind(Jumpers_rare, Diffusers_rare_sample
  , Negatives_rare_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC rail")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_rare + ac_rail, data = dataset)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, 
                      c(summary_modRailac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRailac$r.squared, 
                      summary_modRailac$adj.r.squared)) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_rare + ac_road, data = dataset)
  # plotresid(modRail_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, 
                      c(summary_modRoadac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRoadac$r.squared, 
                      summary_modRoadac$adj.r.squared)) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
    ## 3. Model for interactions:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_rare + ac_int, data = dataset)
  # plotresid(modRail_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, 
                     c(summary_modIntac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                       summary_modIntac$r.squared, 
                       summary_modIntac$adj.r.squared))
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_rarefied.csv"), row.names = F)


ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_rarefied.csv"), row.names = F)


ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", 
                     "AC_est",
                      "Intp", "DJp", "DNp", 
                     "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_rarefied.csv"), row.names = F)
```


Visualize rarefied dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "linear_models_transports", "ModelsRail_rarefied.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DN: NS = 4024, S = 5976 --> no
#DJ: NS = 9895, S = 105 --> no


# positives only
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_rarefied_pos.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ, NS = 9908, S = 92 --> same as DJN
```


Visualize rarefied dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "linear_models_transports", "ModelsRoad_rarefied.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DN: NS = 8628, S = 1372 --> no
#DJ: NS = 9940, S = 60 --> no

# positives only
ModelsRoad <- read.csv(file.path(here(), "tables", "ModelsRoad_rarefied_pos.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ, NS = 9913, S = 87 --> same as DJN
```


Visualize rarefied dataset - DistIntRlRd data
```{r visualize full DistToRail data}
ModelsInt <- read.csv(file.path(here(), "tables", "linear_models_transports", "ModelsInt_rarefied.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ: NS = 9631, S = 369
#DN: NS = 4887, S = 5113

# positives only
ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_rarefied_pos.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ, NS = 9916, S = 84 --> same as DJN
```





### Rarefied dataset but resample 1 random jump per group instead of centroid
```{r lm with ac, echo = FALSE}

#Prepare a dataset with groups to draw jumpers from
jump_groups <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))
head(jump_groups)
jump_groups %>% 
  group_by(bio_year) %>% count(Group) %>%
  filter(n > 1) %>%
  group_by(bio_year) %>% summarise(mean(n))
  # group_by(bio_year) %>% count()

ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Negatives_rare <- slf_uptodate %>% filter(Category_rare == "Negatives")
Jumpers_full <- slf_uptodate %>% filter(Category_full == "Jumpers") %>%
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF, -DistToIntro, -bio_year))
Jumpers_rare <- slf_uptodate %>% filter(Category_rare == "Jumpers")
njumpers_rare = dim(Jumpers_rare)


for (i in 1:10000){
  print(i)
  # One iteration
    # Sample 1 jumper per group from the full dataset to create the rarefied jump dataset
  Jumpers_rare_sample = NULL
  for (i in 1:max(unique(Jumpers_full$Group))){
    Group <- Jumpers_full %>% filter(Group == i)
    Sample <- Group[sample(nrow(Group), size = 1, replace = FALSE),]
    Jumpers_rare_sample <- rbind(Jumpers_rare_sample, Sample)
  }
  #Remove the group column to bind with other samples
  #Indicate that all of them are jumps now
  Jumpers_rare_sample %<>% select(-Group) %>% mutate(Category_rare = recode(Category_rare, 
                                                                            "Diffusers" = "Jumpers"))
  dim(Jumpers_rare_sample)
  
  # Redefine diffusers (that are not jumps)
  new_Diffusers_rare <- slf_uptodate %>% 
    filter(Category_rare != "Negatives") %>% # Select jumpers+diffusers
    select(-Category_rare, -Category_full) %>% # remove previous cats
    left_join(Jumpers_rare_sample, by = c("latitude_rounded", "longitude_rounded", "DistToRail", "DistToRoad", "DistIntRlRd")) %>% # Join the new jumpers
    mutate(Category_rare = ifelse(is.na(Category_rare), "Diffusers", "Jumpers")) %>%  # and name all other non-negatives as diffusers
    filter(Category_rare == "Diffusers") # keep only diffusers

  # Sample diffusers and negatives
  Diffusers_rare_sample <- new_Diffusers_rare[sample(nrow(new_Diffusers_rare), size = njumpers_rare, replace = FALSE),]
  Negatives_rare_sample <- Negatives_rare[sample(nrow(Negatives_rare), size = njumpers_rare, replace = FALSE),]



  # Make a new dataset
  dataset <- rbind(Jumpers_rare_sample, Diffusers_rare_sample, Negatives_rare_sample)
  # dim(dataset)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC rail")}
  dataset %<>% add_column(ac_rail = ac_railroad)

  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_rare + ac_rail, data = dataset)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, 
                      c(summary_modRailac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRailac$r.squared, 
                      summary_modRailac$adj.r.squared)) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef

  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_rare + ac_road, data = dataset)
  # plotresid(modRail_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, 
                      c(summary_modRoadac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRoadac$r.squared, 
                      summary_modRoadac$adj.r.squared)) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
    ## 3. Model for interactions:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_rare + ac_int, data = dataset)
  # plotresid(modRail_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, 
                     c(summary_modIntac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                       summary_modIntac$r.squared, 
                       summary_modIntac$adj.r.squared))
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  if (i %% 100 == 0){
    print(i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_rarefied_resampled.csv"), row.names = F)


ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_rarefied_resampled.csv"), row.names = F)


ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", 
                     "AC_est",
                      "Intp", "DJp", "DNp", 
                     "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_rarefied_resampled.csv"), row.names = F)
```


Visualize full dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_rarefied_resampled.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  # DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
# DJ, S = 189, NS = 9811

```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables","ModelsRoad_rarefied_resampled.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
# DJ, S = 191, NS = 9809

```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}

ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_rarefied_resampled.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
# DJ, S = 688, NS = 9312

```





### Full dataset but without Winchester, Harrisburg and Wilkes-Barre (biggest clusters)
```{r full dataset without big outbreaks}
#Prepare a dataset with groups to get groups
jump_groups <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))
head(jump_groups)
jump_groups %>% 
  group_by(bio_year) %>% count(Group) %>%
  filter(n > 1) 
# The largest clusters are groups 3, 4, and 14

# Rerun the models
ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_full <- slf_uptodate %>% filter(Category_full == "Diffusers")
Negatives_full <- slf_uptodate %>% filter(Category_full == "Negatives")
Jumpers_full <- slf_uptodate %>% filter(Category_full == "Jumpers") %>%
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF, -DistToIntro, -bio_year)) %>% 
  filter(!Group %in% c(3,4,14)) %>% 
  select(-Group) #remove Group column to bind it back with the other categories
njumpers_full = dim(Jumpers_full)


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  Diffusers_full_sample <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]
  Negatives_full_sample <- Negatives_full[sample(nrow(Negatives_full), size = njumpers_full, replace = FALSE),]

  # Make a new dataset
  dataset <- rbind(Jumpers_full, Diffusers_full_sample, Negatives_full_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC railroad")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_full + ac_rail, data = dataset)
  # library(RVAideMemoire)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, 
                      c(summary_modRailac$coefficients[c(1:4, 13:16)], #for pos only, use 1:3, 10:12 
                      summary_modRailac$r.squared, 
                      summary_modRailac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; 
  #p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_full + ac_road, data = dataset)
  # plotresid(modRoad_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, 
                      c(summary_modRoadac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRoadac$r.squared, 
                      summary_modRoadac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 3. Model for intersections:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_full + ac_int, data = dataset)
  # plotresid(modInt_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, 
                     c(summary_modIntac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modIntac$r.squared, 
                      summary_modIntac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_full_woWH.csv"))

ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_full_woWH.csv"))

ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", 
                     "AC_est",
                      "Intp", "DJp", "DNp", 
                     "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_full_woWH.csv"))

```


Visualize full dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_full_woWH.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ NS = 3158, S = 6842
# DN NS = , S =
```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "ModelsRoad_full_woWH.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ NS = 6794, S = 3206 
# DN NS = , S =
```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}

ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_full_woWH.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ, NS = 2399, S = 7601 
# DN NS = , S =
```




### Full dataset but same number as rarefied
```{r full dataset without big outbreaks}

# Rerun the models
ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_full <- slf_uptodate %>% filter(Category_full == "Diffusers")
Negatives_full <- slf_uptodate %>% filter(Category_full == "Negatives")
Jumpers_full <- slf_uptodate %>% filter(Category_full == "Jumpers") 

(njumpers_full = dim(slf_uptodate %>% filter(Category_rare == "Jumpers")))


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  Diffusers_full_sample <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]
  Negatives_full_sample <- Negatives_full[sample(nrow(Negatives_full), size = njumpers_full, replace = FALSE),]
  Jumpers_full_sample <- Jumpers_full[sample(nrow(Jumpers_full), size = njumpers_full, replace = FALSE),]

  # Make a new dataset
  dataset <- rbind(Jumpers_full_sample, Diffusers_full_sample, Negatives_full_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC railroad")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_full + ac_rail, data = dataset)
  # library(RVAideMemoire)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, 
                      c(summary_modRailac$coefficients[c(1:4, 13:16)], #for pos only, use 1:3, 10:12 
                      summary_modRailac$r.squared, 
                      summary_modRailac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; 
  #p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_full + ac_road, data = dataset)
  # plotresid(modRoad_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, 
                      c(summary_modRoadac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRoadac$r.squared, 
                      summary_modRoadac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 3. Model for intersections:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_full + ac_int, data = dataset)
  # plotresid(modInt_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, 
                     c(summary_modIntac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modIntac$r.squared, 
                      summary_modIntac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_full_sizerare.csv"))

ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_full_sizerare.csv"))

ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", 
                     "AC_est",
                      "Intp", "DJp", "DNp", 
                     "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_full_sizerare.csv"))

```


Visualize full dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_full_sizerare.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ NS = 3064
```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "ModelsRoad_full_sizerare.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ NS = 5692
```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}

ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_full_sizerare.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ, NS = 2619
```



### Full dataset but without Winchester, Harrisburg and Wilkes-Barre AND same number as rarefied
```{r full dataset without big outbreaks}
#Prepare a dataset with groups to get groups
jump_groups <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))
head(jump_groups)
jump_groups %>% 
  group_by(bio_year) %>% count(Group) %>%
  filter(n > 1) 
# The largest clusters are groups 3, 4, and 14

# Rerun the models
ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_full <- slf_uptodate %>% filter(Category_full == "Diffusers")
Negatives_full <- slf_uptodate %>% filter(Category_full == "Negatives")
Jumpers_full <- slf_uptodate %>% filter(Category_full == "Jumpers") %>%
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF, -DistToIntro, -bio_year)) %>% 
  filter(!Group %in% c(3,4,14)) %>% 
  select(-Group) #remove Group column to bind it back with the other categories
(njumpers_full = dim(slf_uptodate %>% filter(Category_rare == "Jumpers")))


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  Diffusers_full_sample <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]
  Negatives_full_sample <- Negatives_full[sample(nrow(Negatives_full), size = njumpers_full, replace = FALSE),]
  Jumpers_full_sample <- Jumpers_full[sample(nrow(Jumpers_full), size = njumpers_full, replace = FALSE),]

  # Make a new dataset
  dataset <- rbind(Jumpers_full_sample, Diffusers_full_sample, Negatives_full_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC railroad")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_full + ac_rail, data = dataset)
  # library(RVAideMemoire)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, 
                      c(summary_modRailac$coefficients[c(1:4, 13:16)], #for pos only, use 1:3, 10:12 
                      summary_modRailac$r.squared, 
                      summary_modRailac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; 
  #p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_full + ac_road, data = dataset)
  # plotresid(modRoad_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, 
                      c(summary_modRoadac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modRoadac$r.squared, 
                      summary_modRoadac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 3. Model for intersections:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_full + ac_int, data = dataset)
  # plotresid(modInt_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, 
                     c(summary_modIntac$coefficients[c(1:4, 13:16)],  #for pos only, use 1:3, 10:12 
                      summary_modIntac$r.squared, 
                      summary_modIntac$adj.r.squared)) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_full_woWH_sizerare.csv"))

ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", 
                      "AC_est",
                      "Intp", "DJp", "DNp", 
                      "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_full_woWH_sizerare.csv"))

ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", 
                     "AC_est",
                      "Intp", "DJp", "DNp", 
                     "ACp", "Rsquared", "Adj Rsquared")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_full_woWH_sizerare.csv"))

```


Visualize full dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_full_woWH_sizerare.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ NS = 8233
```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "ModelsRoad_full_woWH_sizerare.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ NS = 9010
```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}

ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_full_woWH_sizerare.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ, NS = 7414
```




# 6. Check for differences between outbreaks and non-outbreaks

1. Create variable outbreaks vs non-outbreaks
```{r load data for oubreaks vs non outbreaks}
slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))

jump_groups <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))

DistToThreshold <- read.csv(file.path(here(), "exported-data", "DistToThreshold.csv")) 
dim(DistToThreshold)

# Join all jumpers, their distances and their groups
outbreaks <- slf_uptodate %>% 
  filter(Category_full == "Jumpers") %>% 
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF))

# Define which groups are outbreaks: identify groups with duplicates and attribute them a TRUE value.
outbreaks %<>% mutate(Outbreaks = ifelse(outbreaks$Group %in% unique(outbreaks[duplicated(outbreaks$Group),10]), TRUE, FALSE))


# Merge DistToThreshold
outbreaks %<>% left_join(DistToThreshold %>% select(-X, -slf_present, -slf_established, -theta, -DistToSLF, -DistToIntro, -Rarefied, -sectors, -longitude_threshold, -latitude_threshold))


head(outbreaks)
dim(outbreaks) 

non_outbreaks <- outbreaks %>% filter(Outbreaks == F) %>% add_column(Dataset = "Non-outbreaks")
# non_outbreaks is the dataset for non-outbreak points
outbreaks_all <- outbreaks %>% filter(Outbreaks == T) %>% add_column(Dataset = "Outbreaks, all points")
# outbreaks_all is all the points from outbreaks
rarefied_dataset <- outbreaks %>% filter(Category_rare == "Jumpers") %>% add_column(Dataset = "Rarefied dataset")
# rarefied_dataset is only the rarefied dataset
outbreaks_centroid <- outbreaks %>% filter(Outbreaks == T, Category_rare == "Jumpers") %>% add_column(Dataset = "Centroid of outbreaks")
# outbreaks_centroid is all the points from outbreaks
outbreaks %<>% add_column(Dataset = "All points")
#outbreaks is the dataset for all points

test_outbreaks <- rbind(non_outbreaks, outbreaks_all, outbreaks_centroid, outbreaks)
test_outbreaks <- rbind(non_outbreaks, outbreaks_centroid)
#bind all rows
head(test_outbreaks)
test_outbreaks %<>% select(-DistToIntro)

```

2. Boxplot
```{r boxplot outbreaks vs non outbreaks}

# pivot dataset for facet_wrap
outbreaks_long <- test_outbreaks %>% 
  pivot_longer(cols = starts_with("Dist"), names_to = "DistanceType", values_to = "DistanceValue")
head(outbreaks_long)

# Order the variables (for plots)
unique(outbreaks_long$DistanceType)
outbreaks_long$DistanceType <- factor(outbreaks_long$DistanceType, levels = c("DistToThreshold", "DistToRail", "DistToRoad", "DistIntRlRd"))
outbreaks_long$Dataset <- factor(outbreaks_long$Dataset, levels = c("All points", "Non-outbreaks", "Outbreaks, all points", "Centroid of outbreaks"))

# Boxplot
outbreaks_plot <- ggplot(outbreaks_long, aes(y = DistanceValue/1000, x = Dataset)) + 
  geom_boxplot() +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 4,
             labeller = labeller(DistanceType = 
    c("DistToThreshold" = "Invasion front", 
      "DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Both"))) +
  ylab("Distance to... (km)") +
  theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

outbreaks_plot

ggsave(file.path(here(), "figures", "jump_transports", "5. boxplot outbreaks.jpg"), outbreaks_plot, width = 10, height = 5)
```


3. Statistical tests

Is the centroid representative of all points of the group?
```{r boxplot points per group vs their centroid}
# pivot dataset for facet_wrap
outbreaks_long <- test_outbreaks %>% 
  pivot_longer(cols = starts_with("Dist"), names_to = "DistanceType", values_to = "DistanceValue")
head(outbreaks_long)

represent <- outbreaks_long %>% filter(Dataset %in% c("Centroid of outbreaks",
                                         "Outbreaks, all points"))

# Boxplot
represent_plot <- ggplot() + 
  geom_boxplot(data = represent %>% filter(Dataset == "Outbreaks, all points"), aes(y = DistanceValue/1000, x = as.factor(Group), col = as.factor(Group)), show.legend = F) +
  geom_point(data = represent %>% filter(Dataset == "Centroid of outbreaks"), aes(y = DistanceValue/1000, x = as.factor(Group))) +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 2,
             labeller = labeller(DistanceType = 
    c("DistToThreshold" = "Invasion front", 
      "DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Both"))) +
  ylab("Distance to... (km)") +
  theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

represent_plot

ggsave(file.path(here(), "figures", "jump_transports", "6. boxplot per outbreak.jpg"), represent_plot, width = 5, height = 5)
```

Statistical test (should be paired somehow + transformed into permutation test)
```{r statistical test all outbreaks vs their centroid}

# DistToThreshold
bartlett.test(DistToThreshold ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.55, no diff in variance
t.test(DistToThreshold ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.73, no diff


# DistToRail
bartlett.test(DistToRail ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.044, diff in variance!
t.test(DistToRail ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.99, no diff


# DistToRoad
bartlett.test(DistToRoad ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 10, no diff in variance
t.test(DistToRoad ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.487, no diff


# DistToIntRlRd
bartlett.test(DistIntRlRd ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.044, diff in variance!
t.test(DistIntRlRd ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Outbreaks, all points", "Centroid of outbreaks")))
# p = 0.87, no diff
```

No diff, so yes the centroid is a good representation of the group



Is there a difference between non-outbreaks and the centroid of outbreaks?
Use permutation tests because sample size is small and distributions are not normal
```{r statistical test all outbreaks vs non-outbreaks}

(obs_rail <- mean(non_outbreaks$DistToRail) - mean(outbreaks_centroid$DistToRail))
(obs_road <- mean(non_outbreaks$DistToRoad) - mean(outbreaks_centroid$DistToRoad))
(obs_int <- mean(non_outbreaks$DistIntRlRd) - mean(outbreaks_centroid$DistIntRlRd))
#H0 = non_outbreaks$DistToRail = outbreaks_centroid$DistToRail
#Ha = non_outbreaks$DistToRail - outbreaks_centroid$DistToRail > 0
# This is what we are going to test!

# set the number of permutations 
sim <- 10^4 #number of permutations

#create an empty vector to store the simulated averages
permRail <- rep(NA, sim)
permRoad <- rep(NA, sim) 
permIntRlRd <- rep(NA, sim) 

# Pool the data
test_outbreaks <- rbind(non_outbreaks, outbreaks_centroid)
boxplot(test_outbreaks$DistToRail ~ test_outbreaks$Dataset)

set.seed(2022) # make sure the results are going to be the same every time we run the code
(k <- nrow(non_outbreaks)) # number of individuals to sample/permute from group 1


# Iterate 10,000 times
for (i in 1:sim) { 
  # Randomly split the data into 2 groups
  # one group has the same number of items that outbreaks_centroid
  # one group has the same number of items that non_outbreaks
   these <- sample(1:nrow(test_outbreaks), size = k)
   non_outbreaks_sim <- test_outbreaks[these,]  
   outbreaks_centroid_sim <- test_outbreaks[-these,]
  
  # calculate the mean for each group and find the difference
  # store this difference in means in a vector (that's the null distribution)
  permRail[i] = mean(non_outbreaks_sim$DistToRail) - mean(outbreaks_centroid_sim$DistToRail)
  permRoad[i] = mean(non_outbreaks_sim$DistToRoad) - mean(outbreaks_centroid_sim$DistToRoad)
  permIntRlRd[i] = mean(non_outbreaks_sim$DistIntRlRd) - mean(outbreaks_centroid_sim$DistIntRlRd)
} 

#add the observed difference as the final item in the vector
permRail[10000] = obs_rail
permRoad[10000] = obs_road
permIntRlRd[10000] = obs_int

# compare observed vs permuted
# count how many simulations are larger than the observed statistic
# one or two alternatives (abs or not abs values)
tablepropRail = table(permRail >= obs_rail)
pRail = tablepropRail[2]/10000
pRail #p = 0.1709
hist(permRail)
abline(v = permRail[10000], col = "red")

tablepropRoad = table(permRoad >= obs_road)
pRoad = tablepropRoad[2]/10000
pRoad #p = 0.3487
hist(permRoad)
abline(v = permRoad[10000], col = "red")

tablepropInt = table(permIntRlRd >= obs_int)
pInt = tablepropInt[2]/10000
pInt #p = 0.2079
hist(permIntRlRd)
abline(v = permIntRlRd[10000], col = "red")
```

Classic tests
```{r test diff stat}
# DistToThreshold
bartlett.test(DistToThreshold ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.53, no diff in variance
t.test(DistToThreshold ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.90, no diff


# DistToRail
bartlett.test(DistToRail ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.059, no diff in variance
t.test(DistToRail ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.27, no diff


# DistToRoad
bartlett.test(DistToRoad ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.54, no diff in variance
t.test(DistToRoad ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.65, no diff


# DistToIntRlRd
bartlett.test(DistIntRlRd ~ Dataset,  data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.04, no diff in variance
t.test(DistIntRlRd ~ Dataset, data = test_outbreaks %>% filter(Dataset %in% c("Centroid of outbreaks", "Non-outbreaks")))
# p = 0.33, no diff
```


No difference between non-outbreaks and the centroid of outbreaks
Even though the centroid is representative of outbreaks
Even though there is a huge difference between full and rarefied dataset
However this difference disappears if we remove the biggest clusters from the full dataset
Could these big clusters be responsible for this tendency?

Let's test the difference between all points and these clusters (and/or their centroid).
```{r statistical test all outbreaks vs non-outbreaks}

outbreaks <- slf_uptodate %>% 
  filter(Category_full == "Jumpers") %>% 
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF))

# Define which groups are outbreaks: identify groups with duplicates and attribute them a TRUE value.
outbreaks %<>% mutate(Outbreaks = ifelse(outbreaks$Group %in% unique(outbreaks[duplicated(outbreaks$Group),10]), TRUE, FALSE))

hist(table(outbreaks$Group), breaks = 30)
# Largest group = group 4 (30 points), group 3 (19 points), group 14 (18 points)

# Centroid of big clusters
centroids_bigoutbreaks <- outbreaks %>% 
  filter(#Outbreaks == T, 
         Category_rare == "Jumpers"
                                               ) %>% 
  # filter(Group %in% c(3,4,14)) %>% 
  filter(Group %in% c(34,36,13)) %>% 
  add_column(Dataset = "Big clusters")
  
all_centroids <- outbreaks %>% 
  filter(Category_rare == "Jumpers") %>%
  # filter(!Group %in% c(3,4,14)) %>% 
  filter(!Group %in% c(34,36,13)) %>% 
  add_column(Dataset = "All points except big clusters")





(obs_rail <- mean(all_centroids$DistToRail) - mean(centroids_bigoutbreaks$DistToRail))
(obs_road <- mean(all_centroids$DistToRoad) - mean(centroids_bigoutbreaks$DistToRoad))
(obs_int <- mean(all_centroids$DistIntRlRd) - mean(centroids_bigoutbreaks$DistIntRlRd))

# set the number of permutations 
sim <- 10^4 #number of permutations

#create an empty vector to store the simulated averages
permRail <- rep(NA, sim)
permRoad <- rep(NA, sim) 
permIntRlRd <- rep(NA, sim) 

# Pool the data
test_outbreaks <- rbind(centroids_bigoutbreaks, all_centroids)
boxplot(test_outbreaks$DistToRail~test_outbreaks$Dataset)

set.seed(2022) # make sure the results are going to be the same every time we run the code
(k <- nrow(all_centroids)) # number of individuals to sample/permute from group 1


# Iterate 10,000 times
for (i in 1:sim) { 
  # Randomly split the data into 2 groups
  # one group has the same number of items that outbreaks_centroid
  # one group has the same number of items that non_outbreaks
   these <- sample(1:nrow(test_outbreaks), size = k)
   allcentroids_sim <- test_outbreaks[these,]  
   bigoutbreaks_centroid_sim <- test_outbreaks[-these,]
  
  # calculate the mean for each group and find the difference
  # store this difference in means in a vector (that's the null distribution)
  permRail[i] = mean(allcentroids_sim$DistToRail) - mean(bigoutbreaks_centroid_sim$DistToRail)
  permRoad[i] = mean(allcentroids_sim$DistToRoad) - mean(bigoutbreaks_centroid_sim$DistToRoad)
  permIntRlRd[i] = mean(allcentroids_sim$DistIntRlRd) - mean(bigoutbreaks_centroid_sim$DistIntRlRd)
} 

#add the observed difference as the final item in the vector
permRail[10000] = obs_rail
permRoad[10000] = obs_road
permIntRlRd[10000] = obs_int

# compare observed vs permuted
# count how many simulations are larger than the observed statistic
# one or two alternatives (abs or not abs values)
tablepropRail = table(abs(permRail) >= abs(obs_rail))
pRail = tablepropRail[2]/10000
pRail #p = 0.1816
hist(permRail)
abline(v = permRail[10000], col = "red")

tablepropRoad = table(permRoad >= obs_road)
pRoad = tablepropRoad[2]/10000
pRoad #p = 0.3487
hist(permRoad)
abline(v = permRoad[10000], col = "red")

tablepropInt = table(permIntRlRd >= obs_int)
pInt = tablepropInt[2]/10000
pInt #p = 0.2079
hist(permIntRlRd)
abline(v = permIntRlRd[10000], col = "red")
```

The distances are much higher for the big clusters when considering all points,
but not when considering only their centroids.
So I am wondering: could it be, instead, that some of the jumps without clusters are farther than all the others?
No! (replaced in previous chunk)



Now can we check if the number of points of location is linked to these distances!
```{r lm nb points vs distance}
nb_points_group <- outbreaks %>% count(Group)

rarefied_dataset <- outbreaks %>% filter(Category_rare == "Jumpers") %>% add_column(Dataset = "Rarefied dataset")
rarefied_dataset %<>% left_join(nb_points_group) 

model <- lm(n ~ DistToRail, data = rarefied_dataset)
summary(model)
```
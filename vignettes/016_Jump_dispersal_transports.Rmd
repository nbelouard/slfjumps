---
title: "Making the most of invasion records, the case of the spotted lanternfly, part II: Testing the significance of the location of jumpers, diffusers, and non-detections"
author: 
- Nadege Belouard^[Temple University, nadege.belouard@temple.edu]
- Sebastiona De Bona^[Temple University, seba.debona@temple.edu]
- Jocelyn E. Behm^[Temple University, jebehm@temple.edu]
- Matthew R. Helmus^[Temple University, mrhelmus@temple.edu]
date: "5/1/2021"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 2
  html_document:
    toc: TRUE
    toc_depth: 3
params:
  show_code: FALSE
  export_figures: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup for rendering, include = F}
# here we set the images to png, to reduce the size of the output
# we set some global paramters in the yaml to allow us to switch the chunks
# of code on and off when displaying
knitr::opts_chunk$set(dpi = 300, echo = params$show_code)
```

# 1. Aim and setup
 
For this second vignette, we want to test the anthropogenic character of jump events identified in the first vignette. Our working hypotheses are that (1) SLF hitchhike on roads, railroads, and regional planes, and thus, establish along major transport infrastructures, and (2) SLF get trapped and transported with materials and are dropped at their destination (international airports, intermodal platforms, mail carriers, gathering points, landscaping companies...). To test the significance of this pattern, we measure the distance between the location of jump events (SLF hereafter called 'jumpers') and each type of transport infrastructure. 

Then:   

- To determine whether these jumps are situated significantly closer than random to transport infrastructures, we compare the average value of this distance to a null distribution.  

- To make sure that any significant result would not be due to surveys being conducted mostly close to transport infrastructures, we also calculate the distance to transport infrastructures for SLF established through diffusive spread (SLF hereafter called 'diffusers'), and for surveys that did not detect SLF (hereafter 'undetected'). We test the significance of the distance to transport infrastructures for these two categories using random distributions again.  

- Finally, we test whether jumpers are found significantly closer to transport infrastructures than diffusers or undetected, to see if there is also a direct and significant difference between these categories.  

## Load packages
```{r states names and centroid for global map, message = FALSE, warning = FALSE, echo = params$display}

library(tidyverse)
library(sf)
library(spData)
# library(RVAideMemoire)
library(dplyr)
library(gridExtra)
library(magrittr)
# library(purrr)
library(here)
# library(FSA)
library(ape)
library(spdep)
library(leaflet)

```

## States map
```{r states names and centroid for global map, message = FALSE, warning = FALSE, echo = params$display}
# extracts a map of the States and recodes state labels to show the two-letter code rather than the full state name.

# obtaining simple feature objects for states and finding centroids for label positioning
states <- sf::st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))
# sf::st_as_sf(maps::map("county", plot = TRUE, fill = FALSE))
states <- cbind(states, st_coordinates(st_centroid(states)))

# making table key for state 2-letter abbreviations
# the vectors state.abb and state.name contains strings of all
# US states and abbreviations
state_abbr <- tibble(state.name = str_to_lower(state.name), state.abb) %>%
  left_join(tibble(ID = states$ID), ., by = c(ID = "state.name")) %>%
  mutate(state.abb = replace_na(state.abb, ""))

# adding 2-letter codes to sf
states$code <- state_abbr$state.abb


# More precise map
US <- st_read("C:/Users/labuser/Documents/Postdoc_SLF/SLF_Dispersal/data/raw_data/states/gadm36_Cont_USA_county/gadm36_Cont_USA_county.shp", crs = "EPSG:4326", quiet = T)
st_crs(US)
US <- st_transform(US, crs = "ESRI:102010")

```



# 2. Calculate distances of SLF to transport infrastructures

## Prepare the SLF dataset
Load the dataset for the SLF data
```{r load datasets, message = FALSE, warning = FALSE}

# SLF data (in the folder SLF_datascience)
# First, load the dataset that contains the location of each survey
grid_data <- read.csv(file.path(here(), "exported-data", "grid_data.csv"))
head(grid_data)
dim(grid_data) #58144
unique(grid_data$bio_year)
dim(grid_data %>% filter(slf_established == T))

```


Select only points in the convex hull of positive points

To avoid biasing the landscape analysis towards significance by using negative points over areas that SLF have not reached so far, we subset the dataset to keep only surveys within the convex hull of all positive points (Figure S1). 

1. Create the minimum convex polygon of the SLF data
```{r create chull}

grid_data <- st_as_sf(x = grid_data, 
                               coords = c("longitude_rounded", "latitude_rounded"), 
                               crs = "EPSG:4269", remove = F)
grid_data_positive <- grid_data %>% filter(slf_established == TRUE)
dim(grid_data_positive) #7044
hull <- st_convex_hull(st_union(grid_data_positive))

#Verify that no positive point is left in grid_data
setdiff(grid_data, grid_data_positive) %>% filter(slf_established) #0

# Visualize points and chull
chull <- ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = grid_data, aes(col = slf_established)) +
  geom_sf(data = hull, alpha = 0.5, fill = "white") + 
  labs(x = "Longitude", y = "Latitude") +
  # coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)
  coord_sf(xlim = c(-83, -72), ylim = c(37, 44), expand = FALSE)

chull

# save the polygon
st_write(hull, file.path(here(), "figures", "GIS", "chull.shp"), driver = "ESRI Shapefile", append = F)
```


2. Keep only the points that are in the chull
```{r subset grid data}
dim(grid_data) #58144
dim(grid_data %>% filter(slf_established)) #7044

hull <- st_read(file.path(here(), "figures", "GIS", "chull.shp"), quiet = T)
st_crs(hull)

# We need to make a small buffer around the chull so that points that make the bounding box are included in it!
chull <- st_buffer(hull, dist = 100)
grid_data_chull <- st_intersection(grid_data, chull)
dim(grid_data_chull) #45964, lower than grid_data
dim(grid_data_chull %>% filter(slf_established)) #7044, same as grid_data
head(grid_data_chull)

ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = grid_data, col = "black") +
  geom_sf(data = grid_data_chull, col = "blue") +
  geom_sf(data = chull, alpha = 0, col = "black") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-81, -73), ylim = c(38, 43))


# save the dataset
st_geometry(grid_data_chull) <- NULL
write.csv(grid_data_chull, file.path(here(), "exported-data", "grid_data_chull.csv"), row.names = F)

```


3. Summarise it so that we calculate the distances for each point only once
```{r summarize grid dataset}
# Extract each point independently of the year it was sampled (for distance calculations)
grid_data_chull <- read.csv(file.path(here(),  "exported-data", "grid_data_chull.csv"), h=T)
dim(grid_data_chull) #45964
head(grid_data_chull)

# are there still duplicated rows?
anyDuplicated(grid_data_chull %>% 
                select(longitude_rounded, latitude_rounded))

grid_chull_unique <- grid_data_chull %>%
  select(latitude_rounded, longitude_rounded) %>% 
  distinct(latitude_rounded, longitude_rounded)
dim(grid_chull_unique) #32911
head(grid_chull_unique)

# are there still duplicated rows?
anyDuplicated(grid_chull_unique %>% 
                select(longitude_rounded, latitude_rounded))

# Visualize the data
grid_unique_layer <- st_as_sf(x = grid_chull_unique, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)

# Visualize the data
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = grid_data_chull, col = "red") +
  geom_sf(data = grid_unique_layer, col = "blue") +
    labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)

# save the dataset
write.csv(grid_chull_unique, file.path(here(), "exported-data", "grid_chull_unique.csv"), row.names = F)

```



## Prepare the railroad and road datasets

1. Load the GIS shapefiles for the landscape data

```{r load landscape features, message = FALSE, warning = FALSE}

#Shapefiles for:

## SLF dropped along the way:
# Railroads (lines, buffer radius = 5 m)
# These are railroads as defined by the USGS National Transportation Dataset. All lines have been merged and projected before buffer construction.
rail <- st_read(file.path(here(), "figures", "GIS", "Railways_full_buffer5m.shp"), quiet = T)
st_crs(rail)
# Roads (lines, buffer radius = 15 m)
# This shapefile contains primary and secondary roads as defined by the US Census bureau. There is no information on traffic volume (AADT). All lines have been merged and projected before buffer construction.
road <- st_read(file.path(here(), "figures", "GIS", "road_buffer15m.shp"), quiet = T)
st_crs(road)

```


2. Make a buffer around the chull to subset the lansdscape features
We use a buffer because for points close to the border of the chull, the closest rail or road might be outside of the chull
```{r buffer around chull, message = FALSE, warning = FALSE}

hull <- st_read(file.path(here(), "figures", "GIS", "chull.shp"), quiet = T)
# We need to project the hull for homogeneity with road and rails
st_crs(hull)
chull <- st_transform(hull, crs = "ESRI:102010")
chull_buffer <- st_buffer(chull, dist = 100000) #100 km to be sure

# Visualize points and chull
ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = chull_buffer, alpha = 0.5, fill = "white") +
  geom_sf(data = chull, alpha = 0.5, fill = "yellow") + 
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)

```


3. Subset rails and roads within the chull
```{r load landscape features, message = FALSE, warning = FALSE}

rail_chull <- st_intersection(rail, chull_buffer)
st_write(rail_chull, file.path(here(), "figures", "GIS", "rail_chull.shp"), driver = "ESRI Shapefile")

road_chull <- st_intersection(road, chull_buffer)
st_write(road_chull, file.path(here(), "figures", "GIS", "road_chull.shp"), driver = "ESRI Shapefile")

# Visualize landscape features and chull
ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = rail_chull, alpha = 0.5, col = "black") +
  # geom_sf(data = road_chull, alpha = 0.5, col = "red") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-88, -68), ylim = c(33, 46), expand = FALSE)

```


## Intersection of layers
4. Create a layer for the intersect of rail and road
```{r intersect of rail and road}

# Create a buffer around rail
rail_chull <- st_read(file.path(here(), "figures", "GIS", "rail_chull.shp"))
st_crs(rail_chull)
rail_buffer200 <- st_buffer(rail_chull, dist = 200)
rail_buffer100 <- st_buffer(rail_chull, dist = 100)

# Create a buffer around roads
road_chull <- st_read(file.path(here(), "figures", "GIS", "road_chull.shp"))
st_crs(road_chull)
road_buffer200 <- st_buffer(road_chull, dist = 200)
road_buffer100 <- st_buffer(road_chull, dist = 100)

# Their intersect
roadrail_intersect200 <- st_intersection(rail_buffer200, road_buffer200)
st_write(roadrail_intersect200, file.path(here(), "figures", "GIS", "roadrail200m_intersect.shp"), driver = "ESRI Shapefile")

#dissolve the polygon
roadrail_intersect200 %<>% 
  st_union() %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84") 
st_write(roadrail_intersect200, file.path(here(), "figures", "GIS", "roadrail200m_union.shp"), driver = "ESRI Shapefile")



roadrail_intersect100 <- st_intersection(rail_buffer100, road_buffer100)

### RUN FROM HERE NEXT ################
st_write(roadrail_intersect100, file.path(here(), "figures", "GIS", "roadrail100m_intersect.shp"), driver = "ESRI Shapefile")

#dissolve the polygon
roadrail_intersect100 %<>% 
  st_union() %>% 
  st_transform(crs = "+proj=longlat +datum=WGS84") 
st_write(roadrail_intersect100, file.path(here(), "figures", "GIS", "roadrail100m_union.shp"), driver = "ESRI Shapefile")

```


## Calculate the distances of each observed point to transport infrastructure

Distance to rail and roads
```{r distance of SLF to transport infrastructures, eval = FALSE}

grid_chull_unique <- read.csv(file.path(here(), "exported-data", "grid_chull_unique.csv"))
dim(grid_chull_unique)
head(grid_chull_unique)

grid_transports <- st_as_sf(x = grid_chull_unique, 
                            coords = c("longitude_rounded", "latitude_rounded"), 
                            crs = "EPSG:4269", remove = F)
grid_transports <- st_transform(grid_transports, crs = "ESRI:102010")

# Create rows for distances
grid_transports %<>% add_column(DistToRail = NA,
                          DistToRoad = NA)

# Load landscape data
rail_chull <- st_read(file.path(here(), "figures", "GIS", "rail_chull.shp"), quiet = T)
road_chull <- st_read(file.path(here(), "figures", "GIS", "road_chull.shp"), quiet = T)


#Calculate their distance to transport infrastructures
for (j in 1:length(grid_transports$DistToRail)){ 
  # Print the row being considered
  print(j)
  
  point_clip <- st_buffer(grid_transports[j,], dist = 50000)
  
  # Calculate distance to the closest railroad
  rail_clip <- st_intersection(rail_chull, point_clip)
  dist_rail <- st_distance(x = grid_transports[j,], y = rail_clip)
  grid_transports$DistToRail[j] <- min(dist_rail)
  rm(rail_clip)
  
  # Calculate distance to the closest major road
  road_clip <- st_intersection(road_chull, point_clip)
  dist_road <- st_distance(x = grid_transports[j,], y = road_clip)
  grid_transports$DistToRoad[j] <- min(dist_road)
  
  rm(point_clip, road_clip)
  
  if (j %% 1000 == 0){
    st_write(grid_transports, file.path(here(), "exported-data", "obs_distances_transport_TEST.shp"), driver = "ESRI Shapefile", append = FALSE)
  }
}

sum(is.na(grid_transports$DistToRoad))

# Save file
st_geometry(grid_transports) <- NULL
write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports.csv"), row.names = F)
```


Make sure all distances have been calculated
```{r check distances}
# Distance data
grid_transports <- read.csv(file.path(here(), "exported-data", "distances_observed_transports.csv"), h=T)
head(grid_transports)
dim(grid_transports)

# Check if there are points without distance
grid_transports %>% filter(DistToRail == Inf | is.na(DistToRail))
grid_transports %>% filter(DistToRoad == Inf | is.na(DistToRoad))

# #Calculate the distance for points where they are missing
# grid_transports <- st_as_sf(x = grid_data_chull, 
#                             coords = c("longitude_rounded", "latitude_rounded"), 
#                             crs = "EPSG:4269", remove = F)
# grid_transports <- st_transform(grid_transports, crs = "ESRI:102010")
#     
# # calculate the distance for missing points
# for (j in 1:length(grid_transports$DistToRail)){ 
#   if (grid_transports$DistToRail[j] > 50000){
#     print(j)
# 
#     # Calculate distance to the closest railroad
#     dist_rail <- st_distance(x = grid_transports[j,], y = rail_chull)
#     grid_transports$DistToRail[j] <- min(dist_rail)
#   }
#   
#   if (grid_transports$DistToRoad[j] > 50000){
#     print(j)
# 
#     # Calculate distance to the closest road
#     dist_road <- st_distance(x = grid_transports[j,], y = road_chull)
#     grid_transports$DistToRoad[j] <- min(dist_road)
#   }
# }
# 
# # Check result
# grid_transports %>% filter(DistToRail == Inf | is.na(DistToRail))
# grid_transports %>% filter(DistToRoad == Inf | is.na(DistToRoad))
# 
# # Save file
# st_geometry(grid_transports) <- NULL
# write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports_complete.csv"), row.names = F)
```


Same for the distance to the intersect road/rail
```{r distance of SLF to transport infrastructures, eval = FALSE}

roadrail_intersect <- st_read(file.path(here(), "figures", "GIS", "roadrail100m_union.shp"), quiet = T) %>% 
  st_transform(crs = "ESRI:102010")

grid_transports <- st_read(file.path(here(), "exported-data", "obs_distances_transport.shp"))
st_crs(grid_transports)

# Create rows for distances
grid_transports %<>% add_column(DistIntRlRd = NA)


#Calculate their distance to transport infrastructures
for (j in 1:length(grid_transports$DistIntRlRd)){ 
  # Print the row being considered
  print(j)
  
  point_clip <- st_buffer(grid_transports[j,], dist = 50000)
  
  # Calculate distance to the closest railroad
  rlrd_clip <- st_intersection(roadrail_intersect, point_clip)
  dist_rlrd <- st_distance(x = grid_transports[j,], y = rlrd_clip)
  grid_transports$DistIntRlRd[j] <- min(dist_rlrd)
  rm(point_clip, rlrd_clip)
  
  if (j %% 1000 == 0){
    st_write(grid_transports, file.path(here(), "exported-data", "obs_distances_transport_TEST.shp"), driver = "ESRI Shapefile", append = FALSE)
  }
}


# Save file
st_geometry(grid_transports) <- NULL
write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports.csv"), row.names = F)
```


Make sure all distances have been calculated
```{r check distances}
# Distance data
grid_transports <- read.csv(file.path(here(), "exported-data", "distances_observed_transports.csv"), h=T)

# Check if there are points without distance
grid_transports %>% filter(DistIntRlRd == Inf | is.na(DistIntRlRd))

```

\newpage


# 3. Create datasets for jumpers/diffusers/negatives

We need to associate each point to the fact that it's a jumper, or diffuser, or negative point, by merging the table with observed distances and the table with status.

1. Prepare the tables
```{r choose which dataset you are testing}

grid_transports <- read.csv(file.path(here(), "exported-data", "distances_observed_transports.csv"))
dim(grid_transports)
head(grid_transports)

# Merge it with the grid data to get the whole dataset back, including column slf established
grid_data_chull <- read.csv(file.path(here(), "exported-data", "grid_data_chull.csv"))
dim(grid_data_chull)
head(grid_data_chull)

grid_data_chull %<>% left_join(grid_transports)
head(grid_data_chull)
dim(grid_data_chull)

# Verify if all points got a distance
grid_data_chull %>% filter(DistToRail == Inf | is.na(DistToRail))
grid_data_chull %>% filter(DistToRoad == Inf | is.na(DistToRoad))
grid_data_chull %>% filter(DistIntRlRd == Inf | is.na(DistIntRlRd))

# Create the categories diffusers (if established) or negatives (if not)
grid_data_chull %<>% mutate(Category_out = ifelse(slf_established == TRUE, "Diffusers", "Negatives"))

# Next load the dataset that contains all jumpers identified by sets of parameters
jumpers <- read.csv(file.path(here(), "exported-data", "jumps_full_rarefied.csv"))
jumpers %<>% add_column(Category = "Jumpers")
```


2. Create full dataset (multiple jumps per location)
```{r create full dataset}

# Put jumpers into the grid data and complete with the rest
grid_full <- grid_data_chull %>% 
  left_join(jumpers %>% select(latitude_rounded, longitude_rounded, slf_established, bio_year, Category)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(grid_full %>% filter(Category == "Jumpers"))[1] == dim(jumpers)[1]
grid_full %<>% rename(Category_full = Category)

grid_full %>% group_by(Category_full) %>% count()
```


3. Create rarefied dataset (one jump per location)
```{r create rarefied dataset}

# Put jumpers into the grid data and complete with the rest
grid_rarefied <- grid_data_chull %>% 
  left_join(jumpers %>% filter(Rarefied == TRUE) %>% 
              select(latitude_rounded, longitude_rounded, bio_year, slf_established, Category)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(grid_rarefied %>% filter(Category == "Jumpers"))[1] == dim(jumpers %>% filter(Rarefied == TRUE))[1]
grid_rarefied %<>% rename(Category_rarefied = Category) 

grid_rarefied %>% filter(Category_rarefied == "Jumpers") %>% count()
```


4. Reassemble in one long dataset with one column for the type of dataset
```{r reassemble full and rarefied dataset}
slf_observed <- merge(grid_full, grid_rarefied)
head(slf_observed)
write.csv(slf_observed, file.path(here(), "exported-data", "slf_observed.csv"), row.names = F)
```

\newpage



# 4. Create dataset "as of today" or "most up to date"

Count each point only once as positive or negative (summarise data for each point)
```{r generate a grid of unique points for situation as of 2020}

slf_observed <- read.csv(file.path(here(), "exported-data", "slf_observed.csv"))
dim(slf_observed)

# Show the number of duplicates per point
slf_observed %>% group_by(latitude_rounded, longitude_rounded) %>% count() %>% 
  group_by(n) %>% count(n)

# Order the Category levels
unique(slf_observed$Category_rarefied)
slf_observed$Category_rarefied <- factor(slf_observed$Category_rarefied, levels = c("Negatives", "Diffusers", "Jumpers"))
slf_observed$Category_full <- factor(slf_observed$Category_full, levels = c("Negatives", "Diffusers", "Jumpers"))

# Translate factors into ordinal
slf_uptodate <- slf_observed %>% mutate(Category_rare_num = as.numeric(Category_rarefied),
                    Category_full_num = as.numeric(Category_full)) %>%  
  group_by(latitude_rounded, longitude_rounded, DistToRail, DistToRoad, DistIntRlRd) %>% 
  summarize(Category_rare_max = max(Category_rare_num),
            Category_full_max = max(Category_full_num)) %>% 
  mutate(Category_rare = recode(Category_rare_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers"),
         Category_full = recode(Category_full_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers")) %>% 
  select(-Category_rare_max, -Category_full_max)
  

dim(slf_uptodate) #32,911
head(slf_uptodate)

# Save this file
write.csv(slf_uptodate, file.path(here(), "exported-data", "slf_obs_uptodate.csv"), row.names=F)
```


Calculate statistics
```{r calculate proportions of data}

positive <- slf_uptodate %>% filter(Category_full %in% c("Diffusers", "Jumpers")) 
dim(positive)[1]/dim(slf_uptodate)[1] #17.93%
```

\newpage



# 5. Check for differences in observed means between categories of SLF

## Calculate observed values
```{r distance of jumpers to transport infrastructures}

slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))

# Summary for Category_full
slf_uptodate %>% group_by(Category_full) %>%
  summarise(medianDistToRail = median(DistToRail), 
            medianDistToRoad = median(DistToRoad),
            medianDistIntRlRd = median(DistIntRlRd),
            meanDistToRail = mean(DistToRail), 
            meanDistToRoad = mean(DistToRoad),
            meanDistIntRlRd = mean(DistIntRlRd))

# Summary for Category_rare
slf_uptodate %>% group_by(Category_rare) %>%
  summarise(medianDistToRail = median(DistToRail),
            medianDistToRoad = median(DistToRoad),
            medianDistIntRlRd = median(DistIntRlRd),
            meanDistToRail = mean(DistToRail), 
            meanDistToRoad = mean(DistToRoad),
            meanDistIntRlRd = mean(DistIntRlRd))

```


## Box plot

We have a first look at differences in distances to transport infrastructures between categories (Figure 1). Note that the y axis is truncated to show more clearly the boxes. Refer to the previous section to get the quartiles and maximum values of the variables. 
Jumpers seem to be closer to rail and roads than the other two categories, but there is no visible difference regarding the distance to airports. Diffusers are intermediate between jumpers and undetected for roads and railroads. 

```{r plot histogram of distances between jumpers, diffusers, undetected, fig.height=5, fig.width = 6, fig.cap="Distance of jumpers, diffusers and non-detections to railroads (top), roads (middle), and airports (bottom). The y axis is truncated to better show the boxes. Refer to section 1 for variables summary."}

slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))
head(slf_uptodate)

#Modify dataset to get distribution of distances with a column for the type of distance (Road, Rail...), and one column for the type of dataset (Full or Rarefied)
slf_uptodate_long <- slf_uptodate %>% 
  pivot_longer(cols = starts_with("Dist"), names_to = "DistanceType", values_to = "DistanceValue")

# Order the variables (for plots)
unique(slf_uptodate_long$Category_full)
slf_uptodate_long$Category_full <- factor(slf_uptodate_long$Category_full, levels = c("Jumpers", "Diffusers", "Negatives"))

unique(slf_uptodate_long$Category_rare)
slf_uptodate_long$Category_rare <- factor(slf_uptodate_long$Category_rare, levels = c("Jumpers", "Diffusers", "Negatives"))

slf_uptodate_long$DistanceType <- factor(slf_uptodate_long$DistanceType, levels = c("DistToRoad", "DistToRail", "DistIntRlRd"))

slf_uptodate_long %>% group_by(Category_rare, DistanceType) %>% count()



# Plot distances (full dataset)
transport_bp <- ggplot(slf_uptodate_long, aes(y = DistanceValue/1000, x = Category_full)) + 
  geom_boxplot(aes(fill = Category_full), 
               show.legend = F,
               # outlier.shape = NA
               ) +
  scale_fill_brewer(palette = "Dark2") +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 4, 
             labeller = labeller(DistanceType = 
    c("DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Both"))) +
  # coord_cartesian(ylim=c(0, 16)) +
  xlab("Category") + ylab("Distance to the nearest... (km)") +
  theme_classic()

transport_bp

ggsave(file.path(here(), "figures", "jump_transports", "1bis. boxplot transport_fulldata.jpg"), transport_bp, width = 5, height = 3)


# Plot distances (rarefied dataset)
transport_bp <- ggplot(slf_uptodate_long, aes(y = DistanceValue/1000, x = Category_rare)) + 
  geom_boxplot(aes(fill = Category_rare), alpha = 0.5, show.legend = F) +
  scale_fill_brewer(palette = "Dark2") +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 4,
              labeller = labeller(DistanceType =
    c("DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Both"))) +
  xlab("Category") + ylab("Distance to the nearest... (km)") +
  theme_classic()

transport_bp

ggsave(file.path(here(), "figures", "jump_transports", "2bis. boxplot transport_rarefieddata.jpg"), transport_bp, width = 5, height = 3)

```


## Statistical test 

Test of the difference of the means between jumpers, diffusers and non-detections

##1. Test autocorrelation
Because we are calculating distances between points and landscape features, we need to test if there is any autocorrelation in the dataset.

``` {r test autocorrelation}
# Detect spatial autocorrelation in the datasets 

# Start with the rarefied dataset
Jumpers <- slf_uptodate %>% filter(Category_rare == "Jumpers")

# Calculate the matrix of coordinates
distLonLat <- as.matrix(dist(cbind(Jumpers$longitude_rounded, Jumpers$latitude_rounded)))
distLonLat.inv <- 1/distLonLat
diag(distLonLat.inv) <- 0

Moran.I(Jumpers$DistToRail, distLonLat.inv)
# $observed: # [1] 0.02370837
# $expected: # [1] -0.02777778
# $sd: # [1] 0.03475753
# $p.value: # [1] 0.138528

Moran.I(Jumpers$DistToRoad, distLonLat.inv)
# $observed: [1] -0.01918829
# $expected: [1] -0.02777778
# $sd: [1] 0.03460668
# $p.value: [1] 0.8039772



# Continue with the full dataset
Jumpers <- slf_uptodate %>% filter(Category_full == "Jumpers")

distLonLat <- as.matrix(dist(cbind(Jumpers$longitude_rounded, Jumpers$latitude_rounded)))
distLonLat.inv <- 1/distLonLat
diag(distLonLat.inv) <- 0

Moran.I(Jumpers$DistToRail, distLonLat.inv)
# $observed: # [1] 0.3414846
# $expected: # [1] -0.007246377
# $sd: # [1] 0.02978898
# $p.value: # [1] 0 ***

Moran.I(Jumpers$DistToRoad, distLonLat.inv)
# $observed: # [1] 0.1339166
# $expected: # [1] -0.007246377
# $sd: # [1] 0.03139476
# $p.value: # [1] 6.911767e-06 ***


# Now do the same for diffusers
# Detect spatial autocorrelation in the datasets
Diffusers <- slf_uptodate %>% filter(Category_rare == "Diffusers")

distLonLat <- as.matrix(dist(cbind(Diffusers$longitude_rounded, Diffusers$latitude_rounded)))
distLonLat.inv <- 1/distLonLat
diag(distLonLat.inv) <- 0

Moran.I(Diffusers$DistToRail, distLonLat.inv) #error
# $observed = 0.0866
# $expected = -0.000170
# $sd = 0.000454
# $p.value = 0

Moran.I(Diffusers$DistToRoad, distLonLat.inv)
# $observed = 0.088
# $expected = -0.0001705611
# $sd = 0.0004544
# $p.value = 0

```

There is major autocorrelation in the dataset! We will use a linear model to compare the categories and add a coefficient to account for autocorrelation.




## 2. Linear model + autocorrelation coefficient 

```{r load model data}

slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))
dim(slf_uptodate) #32911
```

Because of large differences in sample sizes between categories, we need to resample diffusers and negatives 10,000 times with n = n(Jumpers)
Next we calculate the autocorrelation coefficient for these datasets
Finally we run the model

### Full dataset
```{r lm with ac, echo = FALSE}
ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_full <- slf_uptodate %>% filter(Category_full == "Diffusers")
Negatives_full <- slf_uptodate %>% filter(Category_full == "Negatives")
Jumpers_full <- slf_uptodate %>% filter(Category_full == "Jumpers")
njumpers_full = dim(Jumpers_full)


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  Diffusers_full_sample <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]
  Negatives_full_sample <- Negatives_full[sample(nrow(Negatives_full), size = njumpers_full, replace = FALSE),]

  # Make a new dataset
  dataset <- rbind(Jumpers_full, Diffusers_full_sample, Negatives_full_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC railroad")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_full + ac_rail, data = dataset)
  # library(RVAideMemoire)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, summary_modRailac$coefficients[c(1:4, 13:16)]) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; 
  #p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_full + ac_road, data = dataset)
  # plotresid(modRoad_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, summary_modRoadac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 3. Model for intersections:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_full + ac_int, data = dataset)
  # plotresid(modInt_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, summary_modIntac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_full.csv"))

ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_full.csv"))

ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_full.csv"))
```

Power analysis: how likely are we to find a significant result?
```{r power analysis}
library(pwr)
# install.packages("pwr")

# The F test has numerator and denominator degrees of freedom (see summary of lm!). The numerator degrees of freedom, u, is the number of coefficients you'll have in your model (minus the intercept). In our example, u = 2. The denominator degrees of freedom, v, is the number of error degrees of freedom: v = n − u − 1. This implies n = v + u + 1.

summary_modRailac
summary_modRoadac
summary_modIntac

#Here, we have 135 jumps + 135 diffusers + 135 negatives = 405 ind
# we have 3 parameters in the model
# so u = 3 and v = 405 - 3 - 1 = 401

# The effect size, f2, is R2/(1−R2), where R2 is the coefficient of determination, aka the “proportion of variance explained”. To determine effect size you hypothesize the proportion of variance your model explains, or the R2. For example, if I think my model explains 45% of the variance in my dependent variable, the effect size is 0.45/(1 - 0.45) ≈ 0.81.

summary_modRailac #R2adj = 0.22
0.22/(1-0.22) #0.27

summary_modRoadac #R2 = 0.06
0.06/(1-0.06) #0.06

summary_modIntac #R2 = 0.20
0.20/(1-0.20) #0.25

# For the full dataset, effect size of 0.2 (moderate)
pwr.f2.test(u = 3, 
            v = 401, 
            f2 = 0.2, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 1

# For the full dataset, effect size of 0.05 (small)
pwr.f2.test(u = 3, 
            v = 401, 
            f2 = 0.05, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.9754


# For the full dataset, effect size of 0.1 (small)
pwr.f2.test(u = 3, 
            v = 401, 
            f2 = 0.1, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.9999
```


Visualize full dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_full.csv"))

hist(ModelsRail$Int_est)
hist(ModelsRail$DJ_est)
hist(ModelsRail$DN_est)
hist(ModelsRail$AC_est)

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DN NS = 38, S = 9962 --> difference between negatives and diffusers extremely significant
#DJ NS = 17, S = 9983 --> difference between diffusers and jumpers extremely significant

ModelsRail %>% summarise(meanInt = mean(Int_est),
                         sdInt = sd(Int_est),
                     meanDJ = mean(DJ_est),
                     sdDJ = sd(DJ_est),
                     meanDN = mean(DN_est),
                     sdDN = sd(DN_est),
                     meanAC = mean(AC_est),
                     sdAC = sd(AC_est))

# round(quantile(ModelsRail$DJ_est, probs = 0.975), 2)
# round(quantile(ModelsRail$DJ_est, probs = 0.025), 2)
# 
# quantile(ModelsRail$DN_est, probs = 0.975)
# quantile(ModelsRail$DN_est, probs = 0.025)
```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "ModelsRoad_full.csv"))

hist(ModelsRoad$Int_est)
hist(ModelsRoad$DJ_est)
hist(ModelsRoad$DN_est)
hist(ModelsRoad$AC_est)

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DN NS = 8544, S = 1456 --> difference between negatives and diffusers non-significant
#DJ NS = 345, S = 9655 --> difference between diffusers and jumpers is significant

ModelsRoad %>% summarise(meanInt = mean(Int_est),
                         sdInt = sd(Int_est),
                     meanDJ = mean(DJ_est),
                     sdDJ = sd(DJ_est),
                     meanDN = mean(DN_est),
                     sdDN = sd(DN_est),
                     meanAC = mean(AC_est),
                     sdAC = sd(AC_est))


```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}
ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_full.csv"))

hist(ModelsInt$Int_est)
hist(ModelsInt$DJ_est)
hist(ModelsInt$DN_est)
hist(ModelsInt$AC_est)

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DN, NS = 214, S = 9786 --> difference between negatives and diffusers is significant
#DJ, NS = 16, S = 9984 --> difference between diffusers and jumpers is extremely significant

ModelsInt %>% summarise(meanInt = mean(Int_est),
                         sdInt = sd(Int_est),
                     meanDJ = mean(DJ_est),
                     sdDJ = sd(DJ_est),
                     meanDN = mean(DN_est),
                     sdDN = sd(DN_est),
                     meanAC = mean(AC_est),
                     sdAC = sd(AC_est))


```




### Rarefied dataset 
```{r lm with ac, echo = FALSE}

modRoad_ac <- lm(log(DistToRoad+1) ~ Category_full, data = slf_uptodate)
summary(modRoad_ac)

ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_rare <- slf_uptodate %>% filter(Category_rare == "Diffusers")
Negatives_rare <- slf_uptodate %>% filter(Category_rare == "Negatives")
Jumpers_rare <- slf_uptodate %>% filter(Category_rare == "Jumpers")
njumpers_rare = dim(Jumpers_rare)


for (i in 1:10000){
  # One iteration
  # Sample diffusers and negatives
  Diffusers_rare_sample <- Diffusers_rare[sample(nrow(Diffusers_rare), size = njumpers_rare, replace = FALSE),]
  Negatives_rare_sample <- Negatives_rare[sample(nrow(Negatives_rare), size = njumpers_rare, replace = FALSE),]
  
  # Make a new dataset
  dataset <- rbind(Jumpers_rare, Diffusers_rare_sample, Negatives_rare_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC rail")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_rare + ac_rail, data = dataset)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, summary_modRailac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_rare + ac_road, data = dataset)
  # plotresid(modRail_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, summary_modRoadac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
    ## 3. Model for interactions:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_rare + ac_int, data = dataset)
  # plotresid(modRail_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, summary_modIntac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  if (i %% 100 == 0){
    print (i)
  }
}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_rarefied.csv"))


ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_rarefied.csv"))


ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_rarefied.csv"))
```


Power analysis: how likely are we to find a significant result?
```{r power analysis 2}
library(pwr)
# install.packages("pwr")

# The F test has numerator and denominator degrees of freedom (see summary of lm!). The numerator degrees of freedom, u, is the number of coefficients you'll have in your model (minus the intercept). In our example, u = 2. The denominator degrees of freedom, v, is the number of error degrees of freedom: v = n − u − 1. This implies n = v + u + 1.

summary_modRailac
summary_modRoadac
summary_modIntac

#Here, we have 37 jumps + 37 diffusers + 37 negatives = 111 ind
# we have 3 parameters in the model
# so u = 3 and v = 111 - 3 - 1 = 107

# The effect size, f2, is R2/(1−R2), where R2 is the coefficient of determination, aka the “proportion of variance explained”. To determine effect size you hypothesize the proportion of variance your model explains, or the R2. For example, if I think my model explains 45% of the variance in my dependent variable, the effect size is 0.45/(1 - 0.45) ≈ 0.81.

summary_modRailac #R2 = 0.18
0.18/(1-0.18) #0.22

summary_modRoadac #R2 = 0.04
0.04/(1-0.04) #0.04

summary_modIntac #R2 = 0.16
0.16/(1-0.16) #0.19

# For the rarefied dataset, effect size of 0.2
pwr.f2.test(u = 3, 
            v = 107, 
            f2 = 0.2, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.9825

# For the rarefied dataset, effect size of 0.05
pwr.f2.test(u = 3, 
            v = 107, 
            f2 = 0.05, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.47

# For the rarefied dataset, effect size of 0.1
pwr.f2.test(u = 3, 
            v = 107, 
            f2 = 0.1, #effect size
            sig.level = 0.05, #significance level
            power = NULL)
# power = 0.79
```


Visualize rarefied dataset - DistToRail data
```{r visualize full DistToRail data}
ModelsRail <- read.csv(file.path(here(), "tables", "ModelsRail_rarefied.csv"))

hist(ModelsRail$Int_est)
hist(ModelsRail$DJ_est)
hist(ModelsRail$DN_est)
hist(ModelsRail$AC_est)

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DN: NS = 4024, S = 5976 --> no
#DJ: NS = 9880, S = 120 --> no

ModelsRail %>% summarise(meanInt = mean(Int_est),
                         sdInt = sd(Int_est),
                     meanDJ = mean(DJ_est),
                     sdDJ = sd(DJ_est),
                     meanDN = mean(DN_est),
                     sdDN = sd(DN_est),
                     meanAC = mean(AC_est),
                     sdAC = sd(AC_est))

```


Visualize full dataset - DistToRoad data
```{r visualize full DistToRail data}
ModelsRoad <- read.csv(file.path(here(), "tables", "ModelsRoad_rarefied.csv"))

hist(ModelsRoad$Int_est)
hist(ModelsRoad$DJ_est)
hist(ModelsRoad$DN_est)
hist(ModelsRoad$AC_est)


ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DNsignif)
#DN: NS = 8640, S = 1360 --> no
#DJ: NS = 9925, S = 75 --> no

ModelsRoad %>% summarise(meanInt = mean(Int_est),
                         sdInt = sd(Int_est),
                     meanDJ = mean(DJ_est),
                     sdDJ = sd(DJ_est),
                     meanDN = mean(DN_est),
                     sdDN = sd(DN_est),
                     meanAC = mean(AC_est),
                     sdAC = sd(AC_est))


```


Visualize full dataset - DistIntRlRd data
```{r visualize full DistToRail data}
ModelsInt <- read.csv(file.path(here(), "tables", "ModelsInt_rarefied.csv"))

hist(ModelsInt$Int_est)
hist(ModelsInt$DJ_est)
hist(ModelsInt$DN_est)
hist(ModelsInt$AC_est)


ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DNsignif)
#DJ: NS = 9619, S = 381
#DN: NS = 4895, S = 5105

ModelsInt %>% summarise(meanInt = mean(Int_est),
                         sdInt = sd(Int_est),
                     meanDJ = mean(DJ_est),
                     sdDJ = sd(DJ_est),
                     meanDN = mean(DN_est),
                     sdDN = sd(DN_est),
                     meanAC = mean(AC_est),
                     sdAC = sd(AC_est))


```


### Full dataset but resample 1 jump per group
```{r lm with ac, echo = FALSE}

#Prepare a dataset with groups to draw jumpers from
jump_groups <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))


# Run model
ModelsRail = NULL
ModelsRoad = NULL
ModelsInt = NULL

# Define the datasets
Diffusers_full <- slf_uptodate %>% filter(Category_full == "Diffusers")
Negatives_full <- slf_uptodate %>% filter(Category_full == "Negatives")
Jumpers_full <- slf_uptodate %>% 
  filter(Category_full == "Jumpers") %>% 
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF, -DistToIntro, -bio_year))
Jumpers_rare <- slf_uptodate %>% filter(Category_rare == "Jumpers")
njumpers_full = dim(Jumpers_rare)


for (i in 1:10000){
  print(i)
  # One iteration
  # Sample diffusers and negatives
  Diffusers_full_sample <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]
  Negatives_full_sample <- Negatives_full[sample(nrow(Negatives_full), size = njumpers_full, replace = FALSE),]
  
  # Sample 1 jumper per group
  Jumpers_full_sample = NULL
  for (i in 1:max(unique(Jumpers_full$Group))){
    Group <- Jumpers_full %>% filter(Group == i)
    Sample <- Group[sample(nrow(Group), size = 1, replace = FALSE),]
    Jumpers_full_sample <- rbind(Jumpers_full_sample, Sample)
  }
  
  #Remove the group column to bind with other samples
  Jumpers_full_sample %<>% select(-Group)
  
  # Make a new dataset
  dataset <- rbind(Jumpers_full_sample, Diffusers_full_sample, Negatives_full_sample)
  
  #Make a matrix of coordinates 
  coords <- as.matrix(cbind(dataset$longitude_rounded,dataset$latitude_rounded))
  
  
  ## 1. Model for railroad distance:
  # Calculate ac coefficients
  ac_railroad <- autocov_dist(dataset$DistToRail, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_railroad)){ print("Error AC railroad")}
  dataset %<>% add_column(ac_rail = ac_railroad)
  # Run model
  modRail_ac <- lm(log(DistToRail+1) ~ Category_full + ac_rail, data = dataset)
  # library(RVAideMemoire)
  # plotresid(modRail_ac)
  summary_modRailac <- summary(modRail_ac)
  ModelsRail <- rbind(ModelsRail, summary_modRailac$coefficients[c(1:4, 13:16)]) 
  #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; 
  #p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 2. Model for road distance:
  # Calculate ac coefficients
  ac_road <- autocov_dist(dataset$DistToRoad, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_road)){ print("Error AC road")}
  dataset %<>% add_column(ac_road = ac_road)
  # Run model
  modRoad_ac <- lm(log(DistToRoad+1) ~ Category_full + ac_road, data = dataset)
  # plotresid(modRoad_ac)
  summary_modRoadac <- summary(modRoad_ac)
  ModelsRoad <- rbind(ModelsRoad, summary_modRoadac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef
  
  
  
  ## 3. Model for intersections:
  # Calculate ac coefficients
  ac_int <- autocov_dist(dataset$DistIntRlRd, coords, nbs = 500, type = "inverse", longlat = T)
  if (dim(dataset)[1] != length(ac_int)){ print("Error AC int")}
  dataset %<>% add_column(ac_int = ac_int)
  # Run model
  modInt_ac <- lm(log(DistIntRlRd+1) ~ Category_full + ac_int, data = dataset)
  # plotresid(modInt_ac)
  summary_modIntac <- summary(modInt_ac)
  ModelsInt <- rbind(ModelsInt, summary_modIntac$coefficients[c(1:4, 13:16)]) #estimates: intercept, diffusers-jumpers, diffusers-negatives, autocorrelation coef; p-values: diffusers-jumpers, diffusers-negatives, autocorrelation coef

}


ModelsRail <- data.frame(ModelsRail)
names(ModelsRail) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsRail, file.path(here(), "tables", "ModelsRail_fullbsgroup.csv"))

ModelsRail %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DNsignif)
#DJ: NS = 9819, S = 181
#DN: NS = 4667, S = 5333


ModelsRoad <- data.frame(ModelsRoad)
names(ModelsRoad) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsRoad, file.path(here(), "tables", "ModelsRoad_fullbsgroup.csv"))

ModelsRoad %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DNsignif)
#DJ: NS = 9771, S = 229
#DN: NS = 9010, S = 990


ModelsInt <- data.frame(ModelsInt)
names(ModelsInt) = c("Int_est", "DJ_est", "DN_est", "AC_est",
                      "Intp", "DJp", "DNp", "ACp")
write.csv(ModelsInt, file.path(here(), "tables", "ModelsInt_fullbsgroup.csv"))

ModelsInt %>% mutate(DJsignif = ifelse(DJp > 0.05, "NS", "S"),
                  DNsignif = ifelse(DNp > 0.05, "NS", "S"),
                  ACsignif = ifelse(ACp > 0.05, "NS", "S")) %>% 
  count(DJsignif)
#DJ: NS = 9237, S = 763
#DN: NS = 5628, S = 4372
```





# 6. Check for differences between outbreaks and non-outbreaks

```{r load data for oubreaks vs non outbreaks}
slf_uptodate <- read.csv(file.path(here(), "exported-data", "slf_obs_uptodate.csv"))

jump_groups <- read.csv(file.path(here(), "exported-data", "jump_groups.csv"))

DistToThreshold <- read.csv(file.path(here(), "exported-data", "DistToThreshold.csv")) 
dim(DistToThreshold)

# Join all jumpers, their distances and their groups
outbreaks <- slf_uptodate %>% 
  filter(Category_full == "Jumpers") %>% 
  left_join(jump_groups %>% select(-slf_present, -slf_established, -theta, -DistToSLF))

# Define which groups are outbreaks: identify groups with duplicates and attribute them a TRUE value.
outbreaks %<>% mutate(Outbreaks = ifelse(outbreaks$Group %in% unique(outbreaks[duplicated(outbreaks$Group),10]), TRUE, FALSE))

head(outbreaks)
dim(outbreaks)

# Merge DistToThreshold
outbreaks %<>% left_join(DistToThreshold %>% select(-X, -slf_present, -slf_established, -theta, -DistToSLF, -Rarefied, -sectors, -longitude_threshold, -latitude_threshold))

# Now select only the rarefied points
jumps_compare <- outbreaks %>% filter(Category_rare == "Jumpers")
head(jumps_compare)
dim(jumps_compare)
table(jumps_compare$Outbreaks)

#Remove DistToIntro
jumps_compare %<>% select(-DistToIntro) 
```

Test center of outbreak vs non-outbreak
Boxplot
```{r boxplot outbreaks vs non outbreaks}

# pivot dataset for facet_wrap
jumps_compare_long <- jumps_compare %>% 
  pivot_longer(cols = starts_with("Dist"), names_to = "DistanceType", values_to = "DistanceValue")

# Order the variables (for plots)
unique(jumps_compare_long$DistanceType)
jumps_compare_long$DistanceType <- factor(jumps_compare_long$DistanceType, levels = c("DistToThreshold", "DistToRail", "DistToRoad", "DistIntRlRd"))

# Boxplot
outbreaks_plot <- ggplot(jumps_compare_long, aes(y = DistanceValue/1000, x = Outbreaks)) + 
  geom_boxplot(aes(col= Outbreaks)) +
  facet_wrap(~DistanceType, scales = "free_y", ncol = 4,
             labeller = labeller(DistanceType = 
    c("DistToThreshold" = "Invasion front", 
      "DistToRail" = "Railroad",
      "DistToRoad" = "Major road",
      "DistIntRlRd" = "Both"))) +
  ylab("Distance to... (km)") +
  theme_classic()

outbreaks

ggsave(file.path(here(), "figures", "jump_transports", "3. boxplot outbreaks.jpg"), outbreaks, width = 10, height = 3)

```

Statistical test
```{r statistical test outbreak vs non-outbreak}
table(jumps_compare$Outbreaks)

# DistToThreshold
bartlett.test(DistToThreshold ~ Outbreaks,  data = jumps_compare)
# p = 0.54, no diff in variance
t.test(DistToThreshold ~ Outbreaks, data = jumps_compare)
# p = 0.91

# DistToRail
bartlett.test(DistToRail ~ Outbreaks,  data = jumps_compare)
# p = 0.06, no diff in variance
t.test(DistToRail ~ Outbreaks, data = jumps_compare)
# p = 0.27

# DistToRoad
bartlett.test(DistToRoad ~ Outbreaks,  data = jumps_compare)
# p = 0.53
t.test(DistToRoad ~ Outbreaks, data = jumps_compare)
# p = 0.65

# DistToIntRlRd
bartlett.test(DistIntRlRd ~ Outbreaks,  data = jumps_compare)
# p = 0.044
t.test(DistIntRlRd ~ Outbreaks, data = jumps_compare)
# p = 0.34
```


Test 1 random jump per group vs non-outbreak
Statistical test
```{r statistical test 1 random jump per group}

outbreaks %>% filter(Category_rare == "Jumpers")


# sample 1 per group
sample_jumps <- Diffusers_full[sample(nrow(Diffusers_full), size = njumpers_full, replace = FALSE),]

# DistToThreshold
bartlett.test(DistToThreshold ~ Outbreaks,  data = jumps_compare)
# p = 0.54, no diff in variance
t.test(DistToThreshold ~ Outbreaks, data = jumps_compare)
# p = 0.91

# DistToRail
bartlett.test(DistToRail ~ Outbreaks,  data = jumps_compare)
# p = 0.06, no diff in variance
t.test(DistToRail ~ Outbreaks, data = jumps_compare)
# p = 0.27

# DistToRoad
bartlett.test(DistToRoad ~ Outbreaks,  data = jumps_compare)
# p = 0.53
t.test(DistToRoad ~ Outbreaks, data = jumps_compare)
# p = 0.65

# DistToIntRlRd
bartlett.test(DistIntRlRd ~ Outbreaks,  data = jumps_compare)
# p = 0.044
t.test(DistIntRlRd ~ Outbreaks, data = jumps_compare)
# p = 0.34
```

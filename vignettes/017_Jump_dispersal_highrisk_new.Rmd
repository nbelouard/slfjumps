---
title: "Making the most of invasion records, the case of the spotted lanternfly, part III: Extending knowledge to northeastern US"
author: 
- Nadege Belouard^[Temple University, nadege.belouard@temple.edu]
- Sebastiona De Bona^[Temple University, seba.debona@temple.edu]
- Jocelyn E. Behm^[Temple University, jebehm@temple.edu]
- Matthew R. Helmus^[Temple University, mrhelmus@temple.edu]
date: "5/3/2021"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 2
  html_document:
    toc: TRUE
    toc_depth: 3
params:
  show_code: FALSE
  export_figures: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup for rendering, include = F}
# here we set the images to png, to reduce the size of the output
# we set some global paramters in the yaml to allow us to switch the chunks
# of code on and off when displaying
knitr::opts_chunk$set(dpi = 300, echo = params$show_code)


library(tidyverse)
library(sf)
library(spData)
library(dplyr)
library(reshape2)
library(here)
library(magrittr)

aaa
```

\newpage

# Aim and setup
 
For this third vignette, we want to investigate the relationship between properties generating or receiving high levels of traffic and the actual presence of established populations of SLF. A list of areas considered at high risk of colonization by SLF in PA has been built by the iEcolab.  

(1) High-risk areas as jump locations? We will calculate the distance of jumpers, diffusers and non-detections to high-risk areas, and test whether these distances are shorter than random using the same methods as in the previous vignette.

(2) Are high-risk locations at risk relative to transport infrastructures? We will calculate how far these high-risk areas are from transport infrastructures. We will determine whether all categories of high-risk areas are comparable regarding their proximity to transport infrastructure.  

(3) Finally, we will use the knowledge we have on the location of SLF jumpers relative to transports, to project potential areas of colonization over six states (PA, WV, VA, MD, DE, NJ). We will assess the proportion of high-risk locations that are situated in this zone, and whether there are variations between categories of high-risk locations.


```{r states names and centroid for global map, message = FALSE, warning = FALSE, echo = params$display}
# extracts a map of the States and recodes state labels to show the two-letter code rather than the full state name.

# obtaining simple feature objects for states and finding centroids for label positioning
states <- sf::st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))
states <- cbind(states, st_coordinates(st_centroid(states)))
states <- st_transform(states, crs = "ESRI:102010")
st_crs(states)

# making table key for state 2-letter abbreviations
# the vectors state.abb and state.name contains strings of all
# US states and abbreviations
state_abbr <- tibble(state.name = str_to_lower(state.name), state.abb) %>% 
  left_join(tibble(ID = states$ID), ., by = c(ID = "state.name")) %>% 
  mutate(state.abb = replace_na(state.abb, ""))

# adding 2-letter codes to sf
states$code <- state_abbr$state.abb

US <- st_read("C:/Users/labuser/Documents/Postdoc_SLF/SLF_Dispersal/data/raw_data/states/gadm36_Cont_USA_county/gadm36_Cont_USA_county.shp", crs = "EPSG:4326", quiet = T)
st_crs(US)
US <- st_transform(US, crs = "ESRI:102010")
Pennsylvania <- US %>% filter(NAME_1 == "Pennsylvania")

# Visualize the data
# ggplot(data = states) +
#     geom_sf(data = states, fill = "white") +
#     geom_sf(data = Pennsylvania, fill = "blue") +
#     labs(x = "Longitude", y = "Latitude")
```


# 1. Calculate distances of SLF to high risk locations in PA

We first want to check whether SLF are preferentially established near high-risk locations, and whether there is a difference between jumpers, diffusers and non-detections. Because we have listed high-risk areas in PA only, we subset the jumpers, diffusers and non-detections datasets to points situated in PA only.


First load the dataset for the SLF data
```{r load datasets, message = FALSE, warning = FALSE}

# SLF data (in the folder SLF_datascience)
# First, load the dataset that contains the location of each survey
grid_data <- read.csv(file.path(here(), "exported-data", "grid_data_chull.csv"))
# Extract each point independently of the year it was sampled (for distance calculations)
grid_data %<>% filter(bio_year != 2021) %>% select(latitude_rounded, longitude_rounded) %>%
  distinct(latitude_rounded, longitude_rounded, .keep_all = T) 
dim(grid_data) # 43,984 rows

# Make it a shapefile to visualize the data
grid_layer <- st_as_sf(x = grid_data, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)
grid_layer <- st_transform(grid_layer, crs = "ESRI:102010")

# Visualize the data
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
    # geom_sf(data = NE, col = "blue") +
  geom_sf(data = grid_layer, col = "red") +
  geom_sf(data = slf_core, col = "blue") +
      # coord_sf(xlim = c(-82, -72), ylim = c(37, 43), expand = FALSE) +
    labs(x = "Longitude", y = "Latitude")

```


```{r prepare dataset of high-risk areas for PA}
# Create a list with all files names
files <- list.files(path = "./GIS/high-risk-areas-PA", 
           pattern = NULL, all.files = FALSE,
           full.names = T, recursive = FALSE,
           ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)

# Add all the high risk locations in a single table
Highrisk <-  read.csv(files[1], sep=";")
file_name = sub("\\.[a-z]+$", "", files[1])
Highrisk$category = gsub("./GIS/high-risk-areas-PA/jocelynb_pa_locations_webmap_table_", "", file_name) 

for (f in files[-1]) {
file <- read.csv(f, sep=";")
file_name = sub("\\.[a-z]+$", "", f)
file$category = gsub("./GIS/high-risk-areas-PA/jocelynb_pa_locations_webmap_table_", "", file_name) 
Highrisk <- rbind(Highrisk, file)
} 

# dim(Highrisk)


write.csv(Highrisk, "./exported-data/highrisk.csv", row.names = F)
# transient_file <- read.csv2("../exported-data/highrisk.csv")
# write.csv(transient_file[,-1], "../exported-data/highrisk.csv", row.names= F)
# transient_file_test <- read.csv("../exported-data/highrisk.csv")

```


Setup the layers for each type of point of interest

```{r calculate distances to high risk areas}

Highrisk <- read.csv("./exported-data/highrisk.csv")
Highrisk %<>% mutate(type = recode(category,
                                  "fedex" = "mail carriers", 
                                  "ups" = "mail carriers",
                                  "amazonFullfilment" = "mail carriers", 
                                  "landscape" = "wood", 
                                  "lumberYards" = "wood", 
                                  "sawmill" = "wood",
                                  "amusementParks" = "popular destinations",
                                  "auctionCenter" = "popular destinations",
                                  "campground" = "popular destinations", 
                                  "casino" = "popular destinations",
                                  "fairgrounds" = "popular destinations",
                                  "fleamarket" = "popular destinations",
                                  "racetracks" = "popular destinations",
                                  "stadiums" = "popular destinations", 
                                  "summerCamp" = "popular destinations",
                                  "truckGarage" = "garages", 
                                  "autoRepair" = "garages",
                                  "boatLaunches" = "boat", 
                                  "marinas" = "boat"))
unique(Highrisk$type)
write.csv(Highrisk, file.path(here(), "exported-data", "highrisk_cat.csv"), row.names=F)

Highrisk_layer <- st_as_sf(x = Highrisk, coords = c("Longitude", "Latitude"), crs = 4269)
Highrisk_proj <- st_transform(Highrisk_layer, crs = "ESRI:102010")


# Visualize shapefiles
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  # geom_sf(data = Highrisk_proj, col = "blue") +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Subset this file in all categories & Apply buffers around points
unique(Highrisk_proj$category)


# Level of interest: high
# Fedex, amazon, ups
mail <- Highrisk_proj %>% filter(category %in% c("fedex", "ups", "amazonFullfilment"))
mail_buffer <- st_buffer(mail, dist = 50)
dim(mail) #86

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = mail_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Landscaping companies, lumber yards
wood <- Highrisk_proj %>% filter(category %in% c("landscape", "lumberYards", "sawmill"))
dim(wood)
wood_buffer <- st_buffer(wood, dist = 100)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = wood_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Wineries
wineries <- Highrisk_proj %>% filter(category %in% c("winery"))
wineries_buffer <- st_buffer(wineries, dist = 100)
dim(wineries)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = wineries_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)



# Level of interest: medium
# People hobbies: campgrounds, summer camps, casino, stadiums, fairgrounds, amusement parks, flea markets, auction centers
people <- Highrisk_proj %>% filter(category %in% c("amusementParks", "auctionCenter", "campground", "casino", "fairgrounds", "fleamarket", "racetracks", "stadiums", "summerCamp"))
people_buffer <- st_buffer(people, dist = 100)
dim(people)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = people_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Level of interest: low
garages <- Highrisk_proj %>% filter(category %in% c("truckGarage", "autoRepair"))
garages_buffer <- st_buffer(garages, dist = 50)
dim(garages)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = garages_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)



boats <- Highrisk_proj %>% filter(category %in% c("boatLaunches", "marinas"))
boats_buffer <- st_buffer(boats, dist = 50)
dim(boats)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = boats_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


moving_companies <- Highrisk_proj %>% filter(category %in% c("movingCompanies"))
moving_companies_buffer <- st_buffer(moving_companies, dist = 50)
dim(moving_companies)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = moving_companies_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


bottling_plants <- Highrisk_proj %>% filter(category %in% c("bottlingPlants"))
bottling_plants_buffer <- st_buffer(bottling_plants, dist = 100)  
dim(bottling_plants)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = bottling_plants_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


colleges <- Highrisk_proj %>% filter(category %in% c("college"))
colleges_buffer <- st_buffer(colleges, dist = 200)
dim(colleges)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = colleges_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)
  

farmer_market <- Highrisk_proj %>% filter(category %in% c("farmerMarket"))
farmer_market_buffer <- st_buffer(farmer_market, dist = 100)
dim(farmer_market)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = farmer_market_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)




truck_stops <- Highrisk_proj %>% filter(category %in% c("truckStops"))
truck_stops_buffer <- st_buffer(truck_stops, dist = 50)
dim(truck_stops)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = truck_stops_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


distribution_centers <- Highrisk_proj %>% filter(category %in% c("distributionCenter")) 
distribution_centers_buffer <- st_buffer(distribution_centers, dist = 100)
dim(distribution_centers)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = distribution_centers_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Train station (intermodal) PARTIAL DATA?
intermodal <-  Highrisk_proj %>% filter(category %in% c("intermodal"))
intermodal_buffer <- st_buffer(intermodal, dist = 100)
dim(intermodal)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = intermodal_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)
```    



Calculate distances to points of interest: DONE (a few hours overnight locally)

ADD AIRPORTS AND PORTS HERE

```{r distance of SLF to points of high and medium interest, eval = FALSE}

slfPA <- st_intersection(slf_core, Pennsylvania) 

# Visualize shapefiles
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = slfPA, col = "blue") +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top")


# Create rows for distances
slfPA %<>% add_column(DistToMail = NA,
                      DistToWood = NA,
                      DistToWineries = NA,
                      DistToPeople = NA,
                      DistToGarages = NA,
                      DistToBoats = NA,
                      DistToMoving = NA,
                      DistToBottling = NA,
                      DistToColleges = NA,
                      DistToMarket = NA,
                      DistToTruckStop = NA,
                      DistToDistrib = NA,
                      DistToIntermodal = NA)


#Calculate their distance to transport infrastructures
for (j in 1:length(slfPA$DistToMail)){ 
  # Print the row being considered
  print(j)
  
  # Calculate distance to the closest mail-related point
  dist_mail <- st_distance(x = slfPA[j,], y = mail_buffer)
  slfPA$DistToMail[j] <- min(dist_mail)
  
  # Calculate distance to the closest wood-related point
  dist_wood <- st_distance(x = slfPA[j,], y = wood_buffer)
  slfPA$DistToWood[j] <- min(dist_wood)
  
  # Calculate distance to the closest winery
  dist_wine <- st_distance(x = slfPA[j,], y = wineries_buffer)
  slfPA$DistToWineries[j] <- min(dist_wine)
  
  # Calculate distance to the closest location for people
  dist_people <- st_distance(x = slfPA[j,], y = people_buffer)
  slfPA$DistToPeople[j] <- min(dist_people)
  
  # Calculate distance to the closest garage
  dist_garage <- st_distance(x = slfPA[j,], y = garages_buffer)
  slfPA$DistToGarages[j] <- min(dist_garage)

  # Calculate distance to the closest boat launch
  dist_boats <- st_distance(x = slfPA[j,], y = boats_buffer)
  slfPA$DistToBoats[j] <- min(dist_boats)
  
  # Calculate distance to the closest moving company
  dist_moving <- st_distance(x = slfPA[j,], y = moving_companies_buffer)
  slfPA$DistToMoving[j] <- min(dist_moving)
  
  # Calculate distance to the closest bottling plant
  dist_bottling <- st_distance(x = slfPA[j,], y = bottling_plants_buffer)
  slfPA$DistToBottling[j] <- min(dist_bottling)
  
  # Calculate distance to the closest college
  dist_college <- st_distance(x = slfPA[j,], y = colleges_buffer)
  slfPA$DistToColleges[j] <- min(dist_college)
  
  # Calculate distance to the closest farmers market
  dist_market <- st_distance(x = slfPA[j,], y = farmer_market_buffer)
  slfPA$DistToMarket[j] <- min(dist_market)
  
  # Calculate distance to the closest truck stop
  dist_truckstop <- st_distance(x = slfPA[j,], y = truck_stops_buffer)
  slfPA$DistToTruckStop[j] <- min(dist_truckstop)
  
  # Calculate distance to the closest distribution center
  dist_distrib <- st_distance(x = slfPA[j,], y = distribution_centers_buffer)
  slfPA$DistToDistrib[j] <- min(dist_distrib)
  
  # Calculate distance to the closest intermodal
  dist_intermodal <- st_distance(x = slfPA[j,], y = intermodal_buffer)
  slfPA$DistToIntermodal[j] <- min(dist_intermodal)
  
  if (j %% 1000 == 0){
    st_write(slfPA, file.path(here(), "exported-data", "Distances_observed", "grid_distances_poi.shp"), driver = "ESRI Shapefile")  
    }
}


# Save file
st_geometry(slfPA) <- NULL
dist_poi <- slfPA
write.csv(slfPA, file.path(here(), "exported-data", "Distances_observed", "grid_distances_poi.csv"), row.names = F)
```



# 2. Create dataset and attribute values to jumpers, established or negatives

Merge distances for each unique point with the full data frame (with duplicates)
```{r add distances to full data frame}

# SLF data (in the folder SLF_datascience)
grid_data <- read.csv(file.path(here(), "exported-data", "grid_data.csv"))
grid_data %<>% filter(!bio_year == 2021, longitude_rounded > -90) 
head(grid_data)
dim(grid_data)

# Select only points in PA
grid <- st_as_sf(x = grid_data, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)
grid <- st_transform(grid, crs = "ESRI:102010")
slfPA <- st_intersection(grid, Pennsylvania) 
st_geometry(slfPA) <- NULL

# Distance data
dist_poi <- read.csv(file.path(here(), "exported-data", "Distances_observed", "grid_distances_poi.csv"))
tail(dist_poi)
dim(dist_poi)

# Join the distance data to the SLF data
slfPA %<>% left_join(dist_poi) %>% select(-c(GID_0, NAME_0, GID_1, NAME_1, NL_NAME_1, GID_2, NAME_2, VARNAME_2, NL_NAME_2, TYPE_2, CC_2, HASC_2, ENGTYPE_2))
head(slfPA)
dim(slfPA)

# Save this file
write.csv(slfPA, file.path(here(), "exported-data", "gridPA_distances_poi.csv"), row.names = F)
```



Attribute points to jumpers, diffusers or undetected
```{r choose which dataset you are testing}

# Reload the dataset if necessary
slfPA <- read.csv(file.path(here(), "exported-data", "gridPA_distances_poi.csv"))
dim(slfPA)

# Next load the dataset that contains all jumpers identified by sets of parameters
jumpers <- read.csv(file.path(here(), "exported-data", "jumps_full_rarefied.csv"))
# Identify the number of jumpers per set of parameters
jumpers %>% group_by(Rarefied) %>% count()

jumpers <- st_as_sf(x = jumpers, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)
jumpers <- st_transform(jumpers, crs = "ESRI:102010")
jumpersPA <- st_intersection(jumpers, Pennsylvania) 
st_geometry(jumpersPA) <- NULL

# get rid of the category "Present"
jumpersPA %<>% add_column(Category = "Jumpers")
slfPA %<>% mutate(Category_out = ifelse(Status == "Established", "Diffusers", "Negatives"))

###################
# SCENARIO 1: full dataset (multiple jumps per location)
###################

# Put jumpers into the grid data and complete with the rest
slfPA_full <- slfPA %>% left_join(jumpersPA %>% select(latitude_rounded, longitude_rounded, bio_year, Category, Status)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(slfPA_full %>% filter(Category == "Jumpers"))[1] == dim(jumpersPA)[1]

slfPA_full %<>% rename(Category_full = Category)


###################
# SCENARIO 2: rarefied dataset (one jump per location)
###################

# Put jumpers into the grid data and complete with the rest
slfPA_rarefied <- slfPA %>% left_join(jumpersPA %>% filter(Rarefied == TRUE) %>% 
                                    select(latitude_rounded, longitude_rounded, bio_year, Category, Status)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(slfPA_rarefied %>% filter(Category == "Jumpers"))[1] == dim(jumpersPA %>% filter(Rarefied == TRUE))[1]

slfPA_rarefied %<>% rename(Category_rarefied = Category) 



# Reassemble in one long dataset with one column for the type of dataset
slfPA_cat <- merge(slfPA_full, slfPA_rarefied)

write.csv(slfPA_cat, file.path(here(), "exported-data", "slfPA_cat.csv"), row.names = F)
```


# 4. Create dataset "as of today"
That way, each point is only counted once (and cannot be both in negatives and positives for example)
```{r generate a grid of unique points for situation as of 2020}

# Show the number of duplicates
slfPA_cat %>% group_by(latitude_rounded, longitude_rounded) %>% count() %>% 
  group_by(n) %>% count(n)

slfPA_cat$Category_rarefied <- as.factor(slfPA_cat$Category_rarefied)
levels(slfPA_cat$Category_rarefied)
slfPA_cat$Category_rarefied <- factor(slfPA_cat$Category_rarefied, levels = c("Negatives", "Diffusers", "Jumpers"))
slfPA_cat$Category_full <- factor(slfPA_cat$Category_full, levels = c("Negatives", "Diffusers", "Jumpers"))
levels(slfPA_cat$Category_full)

names(slfPA_cat)[5:17]

slfPA_uptodate <- slfPA_cat %>% mutate(Category_rare_num = as.numeric(Category_rarefied),
                    Category_full_num = as.numeric(Category_full)) %>%  
  group_by(latitude_rounded, longitude_rounded, DistToMail, DistToWood, DistToWineries, DistToPeople, DistToGarages, DistToBoats, DistToMoving, DistToBottling, DistToColleges, DistToMarket, DistToTruckStop, DistToDistrib, DistToIntermodal, DistToRail, DistToRoad, DistToAirport, DistToPort) %>% 
  summarize(Category_rare_max = max(Category_rare_num),
            Category_full_max = max(Category_full_num)) %>% 
  mutate(Category_rare = recode(Category_rare_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers"),
         Category_full = recode(Category_full_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers"))
  

dim(slfPA_uptodate) #21,601
head(slfPA_uptodate[7:10])

write.csv(slfPA_uptodate, file.path(here(), "exported-data", "slfPA_uptodate.csv"), row.names=F)

slfPA_uptodate <- read.csv(file.path(here(), "exported-data", "slfPA_uptodate.csv"))
dim(slfPA_uptodate)

ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_point(data = slfPA_uptodate, aes(x = longitude_rounded, y = latitude_rounded), alpha = 0.5, col = "blue") +
  # geom_sf(data = slfPA, col = "red") +
  labs(x = "Longitude", y = "Latitude") 
  # coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000))

# Keep only surveys that are within the chull
slf_layer <- st_as_sf(x = slfPA_uptodate, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)
slf_layer <- st_transform(slf_layer, crs = "ESRI:102010")
slf_chull <- st_intersection(slf_layer, hull)

ggplot(data = states, fill = "white") +
  geom_sf() +
  geom_sf(data = slf_layer) +
  geom_sf(data = hull, alpha = 0.5, fill = "yellow") + 
  geom_sf(data = slf_chull, col = "blue") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)

st_geometry(slf_chull) <- NULL
write.csv(slf_chull, file.path(here(), "exported-data", "pointsPA_chull.csv"), row.names = F)

dim(slf_chull) #32,743 points
table(slf_chull$Category_full) #19% positive points
3756+85
3841/dim(slf_chull)[1]
```

\newpage


# 2. Generate a random dispersal distribution of distances of jumpers to high-risk areas

We now compare whether SLF are situated significantly closer than random to these high-risk areas. As in the previous vignette, We generate a null distribution of jumpers (n = 45), simulated 9,999 times, across PA. 

Calculate all possible coordinates. We could remove those that were already calculated with slfPA, but here 
the calculation is relatively quick (and I could not make the code work because the coordinates seem to be slightly off between the slfPA and Coordinates_PA layers, for some reason)

```{r dataset with points only for PA, echo=FALSE, warning =FALSE, message = FALSE}

# Generate random samples in the polygon
# test <- st_sample(pennsylvania, size = 45, type = "random")

# Calculate all potential coordinates
maxlat <- max(slfPA$latitude_rounded)
minlat <- min(slfPA$latitude_rounded)
maxlong <- max(slfPA$longitude_rounded)  
minlong <- min(slfPA$longitude_rounded)

Seqlat <- seq(from = minlat, to = maxlat, by = 1/111)
Seqlong <- seq(from = minlong, to = maxlong, by = 1/85)
Coordinates <- expand.grid(latitude_rounded = Seqlat, longitude_rounded = Seqlong)
Coordinates <- st_as_sf(x = Coordinates, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)
Coordinates <- st_transform(Coordinates, crs = "ESRI:102010")

ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Coordinates, alpha = 0.5, col = "blue") +
  geom_sf(data = slfPA, col = "red") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


#Keep only those in PA
Coordinates_PA <- st_intersection(Coordinates, Pennsylvania)

ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Coordinates_PA, col = "blue") +
  geom_sf(data = slfPA, col = "red") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)

Coordinates_PA %<>% select(latitude_rounded, longitude_rounded, geometry)
st_write(Coordinates_PA, file.path(here(), "exported-data", "Distances_random distrib", "coordinates_PA.shp"), driver = "ESRI Shapefile")
```


Calculate distances to high risk for those points (copy paste code from above), done locally.
Should be done in a few hours locally

```{r calculate distances of PA points to POI}

# Create rows for distances
Coordinates_PA %<>% add_column(DistToMail = NA,
                      DistToWood = NA,
                      DistToWineries = NA,
                      DistToPeople = NA,
                      DistToGarages = NA,
                      DistToBoats = NA,
                      DistToMoving = NA,
                      DistToBottling = NA,
                      DistToColleges = NA,
                      DistToMarket = NA,
                      DistToTruckStop = NA,
                      DistToDistrib = NA,
                      DistToIntermodal = NA)

# If the run has been interrupted and we need to load the last dataset saved
Coordinates_PA <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "grid_distances_poiPA_old.csv"))
Coordinates_PA <- st_as_sf(x = Coordinates_PA, coords = c("longitude_rounded", "latitude_rounded"), crs = 4269, remove = F)
Coordinates_PA <- st_transform(Coordinates_PA, crs = "ESRI:102010")

#Calculate their distance to transport infrastructures
for (j in 115000:length(Coordinates_PA$DistToMail)){ 
  
  # Calculate distance to the closest mail-related point
  dist_mail <- st_distance(x = Coordinates_PA[j,], y = mail_buffer)
  Coordinates_PA$DistToMail[j] <- min(dist_mail)
  
  # Calculate distance to the closest wood-related point
  dist_wood <- st_distance(x = Coordinates_PA[j,], y = wood_buffer)
  Coordinates_PA$DistToWood[j] <- min(dist_wood)
  
  # Calculate distance to the closest winery
  dist_wine <- st_distance(x = Coordinates_PA[j,], y = wineries_buffer)
  Coordinates_PA$DistToWineries[j] <- min(dist_wine)
  
  # Calculate distance to the closest location for people
  dist_people <- st_distance(x = Coordinates_PA[j,], y = people_buffer)
  Coordinates_PA$DistToPeople[j] <- min(dist_people)
  
  # Calculate distance to the closest garage
  dist_garage <- st_distance(x = Coordinates_PA[j,], y = garages_buffer)
  Coordinates_PA$DistToGarages[j] <- min(dist_garage)

  # Calculate distance to the closest boat launch
  dist_boats <- st_distance(x = Coordinates_PA[j,], y = boats_buffer)
  Coordinates_PA$DistToBoats[j] <- min(dist_boats)
  
  # Calculate distance to the closest moving company
  dist_moving <- st_distance(x = Coordinates_PA[j,], y = moving_companies_buffer)
  Coordinates_PA$DistToMoving[j] <- min(dist_moving)
  
  # Calculate distance to the closest bottling plant
  dist_bottling <- st_distance(x = Coordinates_PA[j,], y = bottling_plants_buffer)
  Coordinates_PA$DistToBottling[j] <- min(dist_bottling)
  
  # Calculate distance to the closest college
  dist_college <- st_distance(x = Coordinates_PA[j,], y = colleges_buffer)
  Coordinates_PA$DistToColleges[j] <- min(dist_college)
  
  # Calculate distance to the closest farmers market
  dist_market <- st_distance(x = Coordinates_PA[j,], y = farmer_market_buffer)
  Coordinates_PA$DistToMarket[j] <- min(dist_market)
  
  # Calculate distance to the closest truck stop
  dist_truckstop <- st_distance(x = Coordinates_PA[j,], y = truck_stops_buffer)
  Coordinates_PA$DistToTruckStop[j] <- min(dist_truckstop)
  
  # Calculate distance to the closest distribution center
  dist_distrib <- st_distance(x = Coordinates_PA[j,], y = distribution_centers_buffer)
  Coordinates_PA$DistToDistrib[j] <- min(dist_distrib)
  
  # Calculate distance to the closest intermodal
  dist_intermodal <- st_distance(x = Coordinates_PA[j,], y = intermodal_buffer)
  Coordinates_PA$DistToIntermodal[j] <- min(dist_intermodal)
  
  if (j %% 1000 == 0){
    print(j)
    distances_random_PA <- Coordinates_PA
    st_geometry(distances_random_PA) <- NULL
    write.csv(distances_random_PA, file.path(here(), "exported-data", "Distances_random distrib", "grid_distances_poiPA.csv"), row.names = F)  
    }
}

# Save file
st_geometry(Coordinates_PA) <- NULL
write.csv(Coordinates_PA, file.path(here(), "exported-data", "Distances_random distrib", "grid_distances_poiPA.csv"), row.names = F)
```



Select random datasets

```{r select random datasets}

slfPA_cat <- read.csv(file.path(here(), "exported-data", "pointsPA_chull.csv"))

Coordinates_PA <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "grid_distances_poiPA.csv"))

# Size of the dataset to be sampled
jumpers_full = dim(slfPA_cat %>% filter(Category_full == "Jumpers"))[1]
jumpers_rare = dim(slfPA_cat %>% filter(Category_rare == "Jumpers"))[1]
diffusers_full = dim(slfPA_cat %>% filter(Category_full == "Diffusers"))[1]
diffusers_rare = dim(slfPA_cat %>% filter(Category_rare == "Diffusers"))[1]
negatives = dim(slfPA_cat %>% filter(Category_full == "Negatives"))[1] #There is no difference in the negatives between the full and rarefied datasets!

for (i in 1:9999){
  #Generate a set of coordinates
  Random_jumpers_full <- Coordinates_PA[sample(nrow(Coordinates_PA), size = jumpers_full, replace = F),] %>%
    add_column(Category_full = "Jumpers")
  Random_diffusers_full <- Coordinates_PA[sample(nrow(Coordinates_PA), size = diffusers_full, replace = F),] %>%
    add_column(Category_full = "Diffusers")
  Random_negatives <- Coordinates_PA[sample(nrow(Coordinates_PA), size = negatives, replace = F),] %>%
    add_column(Category_full = "Negatives")
  
  Random_coordinates <- rbind(Random_jumpers_full, Random_diffusers_full,
                              Random_negatives)
  
  #Calculate the mean distance per simulation
  Random_means <- Random_coordinates %>% group_by(Category_full) %>% 
    summarise_at(vars(starts_with("DistTo")), list(mean = mean, median = median, sd = sd)) %>% 
    add_column(Simulation = i)
  
  #Save the table with the simulation number
  if (i == 1){
    Simulations <- Random_means
  } else {
    Simulations <- bind_rows(Simulations, Random_means)
  }
  
  if (i %% 100 == 0){ print(i)}
} 

write.csv(Simulations, "./exported-data/Distances_random distrib/SimulatedMeans_fullhighriskPA.csv", row.names = F)






#Rarefied dataset
for (i in 1:9999){
  #Generate a set of coordinates
  Random_jumpers_rare <- Coordinates_PA[sample(nrow(Coordinates_PA), size = jumpers_rare, replace = F),] %>%
    add_column(Category_rare = "Jumpers")
  Random_diffusers_rare <- Coordinates_PA[sample(nrow(Coordinates_PA), size = diffusers_rare, replace = F),] %>%
    add_column(Category_rare = "Diffusers")
  Random_negatives <- Coordinates_PA[sample(nrow(Coordinates_PA), size = negatives, replace = F),] %>%
    add_column(Category_rare = "Negatives")
  
  Random_coordinates <- rbind(Random_jumpers_rare, Random_diffusers_rare,
                              Random_negatives)
  
  #Calculate the mean distance per simulation
  Random_means <- Random_coordinates %>% group_by(Category_rare) %>% 
    summarise_at(vars(starts_with("DistTo")), list(mean = mean, median = median)) %>% 
    add_column(Simulation = i)
  
  #Save the table with the simulation number
  if (i == 1){
    Simulations <- Random_means
  } else {
    Simulations <- bind_rows(Simulations, Random_means)
  }
  
  if (i %% 100 == 0){ print(i)}
} 

write.csv(Simulations, "./exported-data/Distances_random distrib/SimulatedMeans_rarehighriskPA.csv", row.names = F)
```


```{r map of random points for jumpers, fig.width= 6, fig.height=7, eval = FALSE}
# Check on the first randomly generated dataset that the points location corresponds to the expectation in each disk portion (Figure 2).

states <- st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))

ggplot(data = states) +
    geom_sf(fill = "white") +
    geom_point(data = Random_coordinates,
            aes(x = longitude_rounded, y = latitude_rounded), shape = 19, size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(-81, -73), ylim = c(38, 42.5), expand = FALSE)

```


## Plot the null distribution against observed values

Full dataset
```{r plot null distribution to high risk, fig.height=2, fig.width = 6, fig.cap="Comparison of the distance of jumpers to high-risk areas to a random distribution."}

# Simulated means
MeanDistances <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "SimulatedMeans_fullhighriskPA.csv"))
names(MeanDistances)
head(MeanDistances)

#Modify dataset to get distribution of distances with a column for the type of distance, and one column for the type of dataset (Full or Rarefied)
randomPA_long <- MeanDistances %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

head(randomPA_long)
unique(randomPA_long$DistanceType)

## FOR MATT SLF 101 MEAN FULL
randomPA_long_mean <- randomPA_long %>% filter(grepl("_mean", DistanceType))
head(randomPA_long_mean)
randomPA_long_mean$DistanceType <- as.factor(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType) <- gsub(pattern = "_mean", replacement = "", x = levels(randomPA_long_mean$DistanceType))


head(randomPA_long_mean)
summary_sim_full <- randomPA_long_mean %>% group_by(Category_full, DistanceType) %>% summarise(mean_sim = mean(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_full)



slfPA_obsmeans <- slfPA_cat_long %>% 
  group_by(Category_full, DistanceType) %>% 
  summarise(MeanDistance = mean(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmeans %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))



summary_full <- merge(summary_sim_full, slfPA_obsmeans)
summary_full %<>% rename(mean_obs = MeanDistance) %>% 
  mutate(effect_size = (mean_obs - mean_sim)/sd_sim)
write.csv(summary_full, "summary_simulations_full.csv")


Category = as.vector(unique(summary_full$DistanceType))
str(Category)
Properties = c("Boat launches and marinas", 
               "Bottling plants",
               "Colleges",
               "Distribution centers",
               "Truck garages and auto repairs",
               "Intermodal platforms",
               "Amazon fulfillment, Fedex and UPS",
               "Farmers markets",
               "Moving companies",
               "Popular destinations: amusement parks, auction centers, campgrounds, casinos, fairgrounds, flea markets, race tracks, stadiums, summer camps",
               "Truck stops",
               "Wineries",
               "Landscaping companies, lumber yards, sawmills")
Names <- data.frame(DistanceType = Category, Properties = Properties)


summary_full_cat <- merge(summary_full, Names)
write.csv(summary_full_cat, "summary_simulations_full.csv")


# GRAPH
ggplot(summary_full_cat, aes(y = effect_size, x = DistanceType)) + 
  geom_point(aes(col = Category_full)) +
  # scale_fill_brewer(palette = "Dark2") +
  # facet_wrap(~Category_full, scales = "free_y", ncol = 1) +
             # labeller = labeller(DistanceType = 
  #   c("DistToAirport" = "Airport",
  #     "DistToBoats" = "Boating",
  #     "DistToBottling" = "Bottling plants",
  #     "DistToColleges" = "Colleges",
  #     "DistToDistrib" = "Distribution centers",
  #     "DistToGarages" = "Garages",
  #     "DistToIntermodal" = "Intermodal platforms",
  #     "DistToMail" = "Mail carriers",
  #     "DistToMarket" = "Farmers market",
  #     "DistToMoving" = "Moving companies",
  #     "DistToPeople" = "Popular destinations",
  #     "DistToPort" = "Port",
  #     "DistToRail" =  "Railroad",
  #     "DistToRoad" = "Major road",
  #     "DistToTruckStop" = "Truck stops",
  #     "DistToWineries" = "Wineries",
  #     "DistToWood" = "Wood-related activities"))) +
  # # coord_cartesian(ylim=c(0, 30000)) +
  # xlab("Category") + ylab("Distance to the nearest... (km)") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  


## FOR MATT SLF 101 MEDIANS FULL
randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
head(randomPA_long_median)
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))


head(randomPA_long_median)
summary_sim_medianfull <- randomPA_long_median %>% group_by(Category_full, DistanceType) %>% summarise(median_sim = median(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_medianfull)



slfPA_obsmedians <- slfPA_cat_long %>% 
  group_by(Category_full, DistanceType) %>% 
  summarise(MedianDistance = median(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmedians %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))



summary_medianfull <- merge(summary_sim_medianfull, slfPA_obsmedians)
summary_medianfull %<>% rename(median_obs = MedianDistance) %>% 
  mutate(effect_size = (median_obs - median_sim)/sd_sim)
write.csv(summary_medianfull, "summary_simulations_median_full.csv")


summary_medianfull_cat <- merge(summary_medianfull, Names)
write.csv(summary_medianfull_cat, "summary_simulations_median_full.csv")
```


## FOR MATT SLF 101 MEAN RAREFIED
```{r }
# Simulated means
MeanDistances <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "SimulatedMeans_rarehighriskPA.csv"))
names(MeanDistances)
head(MeanDistances)

#Modify dataset to get distribution of distances with a column for the type of distance, and one column for the type of dataset (Full or Rarefied)
randomPA_long <- MeanDistances %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

randomPA_long_mean <- randomPA_long %>% filter(grepl("_mean", DistanceType))
head(randomPA_long_mean)
randomPA_long_mean$DistanceType <- as.factor(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType) <- gsub(pattern = "_mean", replacement = "", x = levels(randomPA_long_mean$DistanceType))


head(randomPA_long_mean)
summary_sim_rare <- randomPA_long_mean %>% group_by(Category_rare, DistanceType) %>% summarise(mean_sim = mean(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_rare)



slfPA_obsmeans <- slfPA_cat_long %>% 
  group_by(Category_rare, DistanceType) %>% 
  summarise(MeanDistance = mean(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmeans %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))



summary_rare <- merge(summary_sim_rare, slfPA_obsmeans)
summary_rare %<>% rename(mean_obs = MeanDistance) %>% 
  mutate(effect_size = (mean_obs - mean_sim)/sd_sim)
write.csv(summary_rare, "summary_simulations_rare.csv")


summary_rare_cat <- merge(summary_rare, Names)
write.csv(summary_rare_cat, "summary_simulations_mean_rare.csv")


## FOR MATT SLF 101 MEDIANS FULL
randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
head(randomPA_long_median)
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))


head(randomPA_long_median)
summary_sim_medianrare <- randomPA_long_median %>% group_by(Category_rare, DistanceType) %>% summarise(median_sim = median(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_medianrare)



slfPA_obsmedians <- slfPA_cat_long %>% 
  group_by(Category_rare, DistanceType) %>% 
  summarise(MedianDistance = median(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmedians %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))



summary_medianrare <- merge(summary_sim_medianrare, slfPA_obsmedians)
summary_medianrare %<>% rename(median_obs = MedianDistance) %>% 
  mutate(effect_size = (median_obs - median_sim)/sd_sim)
write.csv(summary_medianrare, "summary_simulations_median_rare.csv")

summary_rare_mediancat <- merge(summary_medianrare, Names)
write.csv(summary_rare_mediancat, "summary_simulations_median_rare.csv")
```



## OTHER
```{r other}

randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))





# Observed data
slfPA_cat <- read.csv(file.path(here(), "exported-data", "slfPA_cat.csv"))
slfPA_cat <- read.csv(file.path(here(), "exported-data", "pointsPA_chull.csv"))

slfPA_cat_long <- slfPA_cat %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

slfPA_obsmeans <- slfPA_cat_long %>% 
  group_by(Category_full, DistanceType) %>% 
  summarise(MeanDistance = mean(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmeans %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))

slfPA_obsmeans$Category_full <- factor(slfPA_obsmeans$Category_full, levels = c("Jumpers", "Diffusers", "Negatives"))
randomPA_long$Category_full <- factor(randomPA_long$Category_full, levels = c("Jumpers", "Diffusers", "Negatives"))

# Plot observed vs simulated means ####### ADD SIMULATED MEANS FOR AIRPORTS, PORTS, ROADS....
random_highrisk <- ggplot() +
  geom_histogram(data = randomPA_long_median %>% filter(Category_full == "Jumpers"), aes(x =  DistanceValue/1000, y = ..density.., fill = Category_full), binwidth = 0.1) +
  geom_vline(data = slfPA_obsmeans %>% filter(Category_full == "Jumpers"), mapping = aes(xintercept = MedianDistance/1000, col = Category_full), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

  # coord_cartesian(ylim = c(0,1)) +
  # facet_wrap(~DistanceType, ncol = 3, scale = "free") +
  # theme_classic()

ggsave(file.path(here(), "figures", "vignette_highrisk", "bootstrap_highrisk_chull_median_full.jpg"), random_highrisk, width = 10, height = 6)
```




Rarefied dataset
```{r plot null distribution to high risk, fig.height=2, fig.width = 6, fig.cap="Comparison of the distance of jumpers to high-risk areas to a random distribution."}

# Simulated means
MeanDistances <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "SimulatedMeans_rarehighriskPA.csv"))

#Modify dataset to get distribution of distances with a column for the type of distance, and one column for the type of dataset (Full or Rarefied)
randomPA_long <- MeanDistances %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))


# Observed data
slfPA_cat <- read.csv(file.path(here(), "exported-data", "slfPA_cat.csv"))
slfPA_cat <- read.csv(file.path(here(), "exported-data", "pointsPA_chull.csv"))
slfPA_cat_long <- slfPA_cat %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")
slfPA_obsmeans <- slfPA_cat_long %>% 
  group_by(Category_rare, DistanceType) %>% 
  summarise(MeanDistance = mean(DistanceValue),
            MedianDistance = median(DistanceValue))
slfPA_obsmeans %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))

slfPA_obsmeans$Category_rare <- factor(slfPA_obsmeans$Category_rare, levels = c("Jumpers", "Diffusers", "Negatives"))
randomPA_long$Category_rare <- factor(randomPA_long$Category_rare, levels = c("Jumpers", "Diffusers", "Negatives"))

# Plot observed vs simulated means ####### ADD SIMULATED MEANS FOR AIRPORTS, PORTS, ROADS....
random_highrisk <- ggplot() +
  geom_histogram(data = randomPA_long_median %>% filter(Category_rare == "Jumpers"), aes(x =  DistanceValue/1000, y = ..density.., fill = Category_rare), binwidth = 0.1) +
  geom_vline(data = slfPA_obsmeans %>% filter(Category_rare == "Jumpers"), mapping = aes(xintercept = MedianDistance/1000, col = Category_rare), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

  # coord_cartesian(ylim = c(0,1)) +
  # facet_wrap(~DistanceType, ncol = 3, scale = "free") +
  # theme_classic()

ggsave(file.path(here(), "figures", "vignette_highrisk", "bootstrap_highrisk_chull_median_rare.jpg"), random_highrisk, width = 10, height = 6)


# Count how many simulations are lower than the observed data
# If it's below 5% it's not random
obsboats <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBoats") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBoats", DistanceValue < obsboats))[1]/10000
#0.0032

obsbottle <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBottling") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBottling", DistanceValue < obsbottle))[1]/10000
#0.008

obsintermodal <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToIntermodal") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToIntermodal", DistanceValue < obsintermodal))[1]/10000
#0.1014


obstruck <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToTruckStop") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToTruckStop", DistanceValue < obstruck))[1]/10000
#0.4375


obswineries <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToWineries") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToWineries", DistanceValue < obswineries))[1]/10000
#0.0537

```
We can visualize the results on Figure 2. The histogram represents the distribution of distances to high-risk areas under the null hypothesis of random dispersal of jumpers. The black vertical lines indicate the significance limits. An observed value situated outside of these vertical lines leads to the rejection of the null hypothesis. The red line indicates the average distance between jumpers and high-risk areas observed in our dataset. The observed location of jumpers is significantly closer than random to high-risk areas.  

\newpage 

# 4. PREDICTIONS


```{r binomial model}

# Take jumpers vs diffusers or jumpers vs non-jumpers?
slf_chull <- read.csv(file.path(here(), "exported-data", "points_chull.csv"))
slf_chull %<>% mutate(Jump = ifelse(Category_full == "Jumpers", 1, 0))
table(slf_chull$Jump)

# Test effect of candidate variables
library(MuMIn)
# install.packages("AICcmodavg")
library(AICcmodavg)
# install.packages("reshape")
library(reshape)
library(data.table)

fullmodel <- glm(Jump ~ scale(DistToRoad) + scale(DistToRail) + scale(DistToAirport), data = slf_chull, family = binomial, na.action = na.fail)
plotresid(fullmodel)
summary(fullmodel)
chat = fullmodel$deviance/fullmodel$df.residual

dredge(fullmodel, rank = AICc, extra="R^2")
dredge(fullmodel, rank = QAICc, extra="R^2", chat=chat)

model_airports <- glm(Jump ~ DistToAirport, family = binomial, data = grid_DP16GS15)
model_rail <- glm(Jump ~ DistToRail, family = binomial, data = grid_DP16GS15)
model_road <- glm(Jump ~ DistToRoad, family = binomial, data = grid_DP16GS15)
```

## Binomial model rail
```{r binomial model rail}
#Prediction RAIL
# Sample negatives
negatives <- slf_chull %>% filter(Status == "Negative surveys")
jumps <- slf_chull %>% filter(Jump == "1")
dim(jumps)
range(slf_chull$DistToRail)

DistToRail = seq(0,10000, length.out = 101)
df = NULL
prob = NULL 

for (i in 1:10000){
  sample_negative <- negatives[sample(nrow(negatives), size = dim(jumps)[1], replace = FALSE),]
  dataset <- rbind(jumps, sample_negative)
  
  model <- glm(Jump ~ DistToRail, data = dataset, family = binomial, na.action = na.fail)
  model_res <- summary(model)
  p <- model_res$coefficients[2]
  newdata <- data.frame(DistToRoad)
  newdata %<>% add_column(predict = predict(model, newdata = newdata, type = "response"))
  prob <- rbind(prob, p)
  df <- rbind(df, newdata)
}

head(df)
dim(df)
max(prob)
hist(prob)
write.csv(prob, "p_jumps_rail.csv", row.names = F)
write.csv(df, "prediction_jumps_rail.csv", row.names = F)


prediction_jumps_rail <- ggplot(df) + 
  geom_point(aes(x = DistToRail, y = p)) +
  ylim(c(0,1))+
  theme_classic() +
  ylab("Probability of a jump") +
  xlab("Distance to a railroad")
  
ggsave(file.path(here(), "figures", "vignette-transports", "prediction_jumps_rail.jpg"))


means <- df %>% group_by(DistToRail) %>% 
  summarise(meanp = mean(p),
            p975 = quantile(p, 0.975),
            p025 = quantile(p, 0.025),
            min = min(p),
            max = max(p))

prediction_jumps_rail <- ggplot(means, 
                                aes(x = DistToRail, y = meanp)) + 
  geom_line() +
  geom_point(size = 0.1) +
  ylim(c(0,1))+
  theme_classic() +
  geom_errorbar(aes(ymin = p025, ymax = p975), width=.2,
                 position=position_dodge(.9)) +
  ylab("Probability of a jump") +
  xlab("Distance to a railroad (m)")
  
ggsave(file.path(here(), "figures", "vignette_transports", "prediction_jumps_rail_ic95.jpg"))
       
```


## Binomial model road
```{r binomial model road}
#Prediction RAIL
# Sample negatives
negatives <- slf_chull %>% filter(Status == "Negative surveys")
jumps <- slf_chull %>% filter(Jump == "1")
dim(jumps)
range(slf_chull$DistToRail)

hist(slf_chull$DistToRoad, breaks = 100)

DistToRoad = seq(0,10000, length.out = 101)
df = NULL
prob = NULL

for (i in 1:10000){
  sample_negative <- negatives[sample(nrow(negatives), size = dim(jumps)[1], replace = FALSE),]
  dataset <- rbind(jumps, sample_negative)
  
  model <- glm(Jump ~ DistToRoad, data = dataset, family = binomial, na.action = na.fail)
  model_res <- summary(model)
  p <- model_res$coefficients[2]
  newdata <- data.frame(DistToRoad)
  newdata %<>% add_column(predict = predict(model, newdata = newdata, type = "response"))
  prob <- rbind(prob, p)
  df <- rbind(df, newdata)
}

head(df)
dim(df)
max(prob)
hist(prob)
write.csv(prob, "p_jumps_roads.csv", row.names = F)
write.csv(df, "prediction_jumps_road.csv", row.names = F)



# BOTH PREDICTIONS

df_road <- read.csv(file.path(here(), "prediction_jumps_road.csv"))
df_rail <- read.csv(file.path(here(), "prediction_jumps_rail.csv"))

means_road <- df_road %>% group_by(DistToRoad) %>% 
  summarise(meanp = mean(p),
            p975 = quantile(p, 0.975),
            p025 = quantile(p, 0.025),
            min = min(p),
            max = max(p)) %>% 
    add_column(Transport = "Road") %>% 
  rename(DistTo = DistToRoad)
means_road[11,]
means_rail <- df_rail %>% group_by(DistToRail) %>% 
  summarise(meanp = mean(p),
            p975 = quantile(p, 0.975),
            p025 = quantile(p, 0.025),
            min = min(p),
            max = max(p)) %>% 
  add_column(Transport = "Rail") %>% 
  rename(DistTo = DistToRail)

means_rail[11,]
data <- rbind(means_road, means_rail)


prediction_jumps <- ggplot() + 
  geom_line(data = data, aes(x = DistTo, y = meanp, col = Transport)) +
  geom_point(data = data, aes(x = DistTo, y = meanp, col = Transport), size = 1) +
    geom_errorbar(data = data, aes(x = DistTo, ymin = p025, ymax = p975, col = Transport), width=.2) +
  scale_color_manual(values = c("black", "darkgray")) +
  ylim(c(0,1))+
  xlim(c(0,2000)) +
  theme_classic() +
  ylab("Risk of jump event") +
  xlab("Distance to... (m)")
  
ggsave(file.path(here(), "figures", "vignette_transports", "prediction_jumps_railroad.jpg"), prediction_jumps, width = 6, height = 5)
       
```

\newpage 

# 5. Results and conclusion


In this vignette, we found that:  

(1) Jumpers and diffusers are situated significantly close to high-risk areas. These high-risk areas could be preferential locations for the progression of the invasion.

(2) We created a risk buffer around transport infrastructures comprising all jump events so far. This risk buffer could be used as a guide to focus survey efforts and ensure an early detection of future jump events.

(3) Some categories of high-risk areas are not as close to transport infrastructures as others, and are not situated in the risk buffer. Namely, campgrounds, race tracks, saw mills and summer camps might not be considered as high-risk areas based on these analyses. 


This vignette concludes a series of 3 vignettes on the analysis of spread records of the spotted lanternfly. Results can be used to improve our knowledge of SLF dispersal, to follow the evolution of the invasion, and to direct survey efforts.
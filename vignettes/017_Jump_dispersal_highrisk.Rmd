---
title: "Making the most of invasion records, the case of the spotted lanternfly, part III: Extending knowledge to northeastern US"
author: 
- Nadege Belouard^[Temple University, nadege.belouard@temple.edu]
- Sebastiona De Bona^[Temple University, seba.debona@temple.edu]
- Jocelyn E. Behm^[Temple University, jebehm@temple.edu]
- Matthew R. Helmus^[Temple University, mrhelmus@temple.edu]
date: "5/3/2021"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 2
  html_document:
    toc: TRUE
    toc_depth: 3
params:
  show_code: FALSE
  export_figures: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup for rendering, include = F}
# here we set the images to png, to reduce the size of the output
# we set some global paramters in the yaml to allow us to switch the chunks
# of code on and off when displaying
knitr::opts_chunk$set(dpi = 300, echo = params$show_code)
```

\newpage

# 1. Aim and setup
 
For this third vignette, we want to investigate the relationship between properties generating or receiving high levels of traffic and the actual presence of established populations of SLF. A list of areas considered at high risk of colonization by SLF in PA has been built by the iEcolab.  

We will calculate the distance of jumpers, diffusers and non-detections to high-risk areas, and test whether these distances are shorter than random using the same methods as in the previous vignette.

We first want to check whether SLF are preferentially established near high-risk locations, and whether there is a difference between jumpers, diffusers and non-detections. Because we have listed high-risk areas in PA only, we subset the jumpers, diffusers and non-detections datasets to points situated in PA only.

## Load packages
```{r load packages}
library(tidyverse)
library(sf)
library(spData)
library(dplyr)
library(reshape2)
library(here)
library(magrittr)
```

## States map
```{r states names and centroid for global map, message = FALSE, warning = FALSE, echo = params$display}
# extracts a map of the States and recodes state labels to show the two-letter code rather than the full state name.

# obtaining simple feature objects for states and finding centroids for label positioning
states <- sf::st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))
states <- cbind(states, st_coordinates(st_centroid(states)))
states <- st_transform(states, crs = "ESRI:102010")
st_crs(states)

# making table key for state 2-letter abbreviations
# the vectors state.abb and state.name contains strings of all
# US states and abbreviations
state_abbr <- tibble(state.name = str_to_lower(state.name), state.abb) %>% 
  left_join(tibble(ID = states$ID), ., by = c(ID = "state.name")) %>% 
  mutate(state.abb = replace_na(state.abb, ""))

# adding 2-letter codes to sf
states$code <- state_abbr$state.abb

# Visualize the data
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
    labs(x = "Longitude", y = "Latitude")
```



# 2. Calculate distances of SLF to high risk locations in PA

## Load the location of high risk data
```{r prepare dataset of high-risk areas for PA}
# Create a list with all files names
files <- list.files(path = file.path(here(), "figures", "GIS", "high-risk-areas-PA"), 
           pattern = NULL, all.files = FALSE,
           full.names = T, recursive = FALSE,
           ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)

# Add all the high risk locations in a single table
Highrisk <-  read.csv(files[1], sep=";")
file_name <- gsub("\\.csv", "", files[1])
Highrisk$category = gsub("C:/Users/labuser/Documents/Postdoc_SLF/SLF_jump_dispersal/slfjumps/figures/GIS/high-risk-areas-PA/jocelynb_pa_locations_webmap_table_", "", file_name) 

for (f in files[-1]) {
file <- read.csv(f, sep=";")
file_name = sub("\\.csv", "", f)
file$category = gsub("C:/Users/labuser/Documents/Postdoc_SLF/SLF_jump_dispersal/slfjumps/figures/GIS/high-risk-areas-PA/jocelynb_pa_locations_webmap_table_", "", file_name) 
Highrisk <- rbind(Highrisk, file)
} 

# dim(Highrisk)
unique(Highrisk$category)

write.csv(Highrisk, file.path(here(), "exported-data", "highrisk_locations.csv"), row.names = F)

```


Make categories
```{r calculate distances to high risk areas}

# Make more general categories
Highrisk <- read.csv(file.path(here(), "exported-data", "highrisk_locations.csv"))
unique(Highrisk$category)

Highrisk %<>% mutate(type = recode(category,
                                  "fedex" = "mail carriers", 
                                  "ups" = "mail carriers",
                                  "amazonFullfilment" = "mail carriers", 
                                  "landscape" = "wood", 
                                  "lumberYards" = "wood", 
                                  "sawmill" = "wood",
                                  "amusementParks" = "hobbies",
                                  "auctionCenter" = "hobbies",
                                  "campground" = "hobbies", 
                                  "casino" = "hobbies",
                                  "fairgrounds" = "hobbies",
                                  "fleamarket" = "hobbies",
                                  "racetracks" = "hobbies",
                                  "stadiums" = "hobbies", 
                                  "summerCamp" = "hobbies",
                                  "truckGarage" = "garages", 
                                  "autoRepair" = "garages",
                                  "boatLaunches" = "boat", 
                                  "marinas" = "boat",
                                  "movingCompanies" = "other", 
                                  "bottlingPlants" = "other", 
                                  "college" = "other", 
                                  "farmerMarket" = "other", 
                                  "truckStops" = "other",
                                  "distributionCenter" = "other", 
                                  "intermodal" = "other", 
                                  "armories" = "other"))
unique(Highrisk$type)

write.csv(Highrisk, file.path(here(), "exported-data", "highrisk_cat.csv"), row.names=F)

#Visualize data
Highrisk_layer <- st_as_sf(x = Highrisk, coords = c("Longitude", "Latitude"), crs = 4269)
Highrisk_proj <- st_transform(Highrisk_layer, crs = "ESRI:102010")

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = Highrisk_proj, col = "blue") +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)
```


Create layers for landscape features
```{r make files per category}
# Subset this file in all categories & Apply buffers around points
unique(Highrisk_proj$type)

# Level of interest: high
# Mail carriers
mail <- Highrisk_proj %>% filter(type == "mail carriers")
mail_buffer <- st_buffer(mail, dist = 50)
dim(mail_buffer) #86

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = mail_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Wood
wood <- Highrisk_proj %>% filter(type == "wood")
dim(wood)
wood_buffer <- st_buffer(wood, dist = 100)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = wood_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Wineries
wineries <- Highrisk_proj %>% filter(type == "winery")
wineries_buffer <- st_buffer(wineries, dist = 100)
dim(wineries)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = wineries_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)



# People hobbies
people <- Highrisk_proj %>% filter(type == "hobbies")
people_buffer <- st_buffer(people, dist = 100)
dim(people)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = people_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# Garages, Boat, Other
garages <- Highrisk_proj %>% filter(type == "garages")
garages_buffer <- st_buffer(garages, dist = 50)
dim(garages)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = garages_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)



boats <- Highrisk_proj %>% filter(type ==  "boat")
boats_buffer <- st_buffer(boats, dist = 50)
dim(boats)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = boats_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


others <- Highrisk_proj %>% filter(type == "other")
others_buffer <- st_buffer(others, dist = 50)
dim(others_buffer)

ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = others_buffer, col = "blue", size = 2) +
    labs(x = "Longitude", y = "Latitude")+
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)



```    


Load data for ports and airports
```{r data for ports and airports}
airports <- st_read(file.path(here(), "figures", "GIS", "airports_primary_buffer.shp"), quiet = T)
st_crs(airports)
airports <- st_transform(airports, crs = "ESRI:102010")

ports <- st_read(file.path(here(), "figures", "GIS", "Ports_projected_buffer200.shp"), quiet = T)
st_crs(ports)
```


## Load SLF data

First load the dataset for the SLF data and clip the form of PA
```{r load datasets, message = FALSE, warning = FALSE}

# SLF data (in the folder SLF_datascience)
# First, load the dataset that contains the location of each survey
# Extract each point independently of the year it was sampled (for distance calculations)
grid_unique_chull <- read.csv(file.path(here(), "exported-data", "grid_chull_unique.csv"))
dim(grid_unique_chull) #32911

# Make it a shapefile to visualize the data
grid_chull_layer <- st_as_sf(x = grid_unique_chull, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F) %>% st_transform(crs = "ESRI:102010")

# Visualize the data
ggplot(data = states) +
  geom_sf(data = states, fill = "white") +
  geom_sf(data = grid_chull_layer, col = "red") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE) +
  labs(x = "Longitude", y = "Latitude")

```


## Clip the form of PA

Form of PA
```{r PA form}
US <- st_read(file.path(here(), "figures", "GIS", "gadm36_Cont_USA_county.shp"), crs = "EPSG:4326", quiet = T)
st_crs(US)
US <- st_transform(US, crs = "ESRI:102010")
Pennsylvania <- US %>% filter(NAME_1 == "Pennsylvania")

# Visualize Pennsylvania
ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Pennsylvania, col = "blue") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)
```

In grid data
```{r clip grid data in PA}

slfPA <- st_intersection(grid_chull_layer, Pennsylvania) 
dim(slfPA) #20286

# Visualize shapefiles
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = grid_chull_layer, col = "red") +
  geom_sf(data = slfPA, col = "blue") +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000))
  
# This is PA clipped from the chull
write.csv(slfPA, file.path(here(), "exported-data", "slfPA.csv"), row.names=F)
```

In airports and ports
```{r clip airports and ports in PA}

airportsPA <- st_intersection(airports, Pennsylvania) 
st_write(airportsPA, file.path(here(), "figures", "GIS", "airportsPA.shp"))

# Visualize shapefiles
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = airports) +
  geom_sf(data = airportsPA, col = "blue", size = 5) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000))


portsPA <- st_intersection(ports, Pennsylvania) 
st_write(portsPA, file.path(here(), "figures", "GIS", "portsPA.shp"))

# Visualize shapefiles
ggplot(data = states) +
    geom_sf(data = states, fill = "white") +
  geom_sf(data = ports) +
  geom_sf(data = portsPA, col = "blue", size = 5) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000))
```



## Calculate distances to landscape features
Calculate distances to points of interest in PA (a few hours overnight locally)
It includes:
- mail_buffer, people_buffer, others_buffer, wood_buffer, boats_buffer, garages_buffer, wineries_buffer
- airports, ports

```{r distance of SLF to points of interest, eval = FALSE}
unique(Highrisk$type)

# Create rows for distances
slfPA %<>% add_column(DistToMail = NA,
                      DistToWood = NA,
                      DistToWineries = NA,
                      DistToHobbies = NA,
                      DistToGarages = NA,
                      DistToBoats = NA,
                      DistToOthers = NA,
                      DistToAirports = NA,
                      DistToPorts = NA)

slfPA <- read.csv(file.path(here(), "exported-data", "distances_observed_highrisk.csv"))
slfPA <- st_as_sf(x = slfPA, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F) %>% st_transform(crs = "ESRI:102010")

slfPA[1000,]

#Calculate their distance to transport infrastructures
for (j in 1000:length(slfPA$DistToMail)){ 
  # Print the row being considered
  print(j)
  
  # Calculate distance to the closest mail-related point
  dist_mail <- st_distance(x = slfPA[j,], y = mail_buffer)
  slfPA$DistToMail[j] <- min(dist_mail)
  
  # Calculate distance to the closest wood-related point
  dist_wood <- st_distance(x = slfPA[j,], y = wood_buffer)
  slfPA$DistToWood[j] <- min(dist_wood)
  
  # Calculate distance to the closest winery
  dist_wine <- st_distance(x = slfPA[j,], y = wineries_buffer)
  slfPA$DistToWineries[j] <- min(dist_wine)
  
  # Calculate distance to the closest location for people
  dist_people <- st_distance(x = slfPA[j,], y = people_buffer)
  slfPA$DistToHobbies[j] <- min(dist_people)
  
  # Calculate distance to the closest garage
  dist_garage <- st_distance(x = slfPA[j,], y = garages_buffer)
  slfPA$DistToGarages[j] <- min(dist_garage)

  # Calculate distance to the closest boat launch
  dist_boats <- st_distance(x = slfPA[j,], y = boats_buffer)
  slfPA$DistToBoats[j] <- min(dist_boats)
  
  # Calculate distance to other infrastructures
  dist_others <- st_distance(x = slfPA[j,], y = others_buffer)
  slfPA$DistToOthers[j] <- min(dist_others)
  
  # Calculate distance to airports
  dist_airports <- st_distance(x = slfPA[j,], y = airportsPA)
  slfPA$DistToAirports[j] <- min(dist_airports)
  
  # Calculate distance to ports
  dist_ports <- st_distance(x = slfPA[j,], y = portsPA)
  slfPA$DistToPorts[j] <- min(dist_ports)
  
  if (j %% 1000 == 0){
    distances_structures <- slfPA
    st_geometry(distances_structures) <- NULL
    write.csv(distances_structures, file.path(here(), "exported-data",  "distances_observed_highrisk.csv"), row.names = F)  
    }
}


# Save file
st_geometry(slfPA) <- NULL
write.csv(slfPA, file.path(here(), "exported-data", "distances_observed_poi.csv"), row.names = F)
```


Make sure all distances have been calculated
```{r check distances}
# Distance data
grid_poi <- read.csv(file.path(here(), "exported-data", "distances_observed_highrisk.csv"), h=T)

# Check if there are points without distance
grid_poi %>% filter(DistToMail == Inf | is.na(DistToMail))
grid_poi %>% filter(DistToWood == Inf | is.na(DistToWood))
grid_poi %>% filter(DistToWineries == Inf | is.na(DistToWineries))
grid_poi %>% filter(DistToHobbies == Inf | is.na(DistToHobbies))
grid_poi %>% filter(DistToGarages == Inf | is.na(DistToGarages))
grid_poi %>% filter(DistToBoats == Inf | is.na(DistToBoats))
grid_poi %>% filter(DistToOthers == Inf | is.na(DistToOthers))
grid_poi %>% filter(DistToAirports == Inf | is.na(DistToAirports))
grid_poi %>% filter(DistToPorts == Inf | is.na(DistToPorts))


# #Calculate the distance for points where they are missing
# grid_transports <- st_as_sf(x = grid_data_chull, 
#                             coords = c("longitude_rounded", "latitude_rounded"), 
#                             crs = "EPSG:4269", remove = F)
# grid_transports <- st_transform(grid_transports, crs = "ESRI:102010")
#     
# # calculate the distance for missing points
# for (j in 1:length(grid_transports$DistToRail)){ 
#   if (grid_transports$DistToRail[j] > 50000){
#     print(j)
# 
#     # Calculate distance to the closest railroad
#     dist_rail <- st_distance(x = grid_transports[j,], y = rail_chull)
#     grid_transports$DistToRail[j] <- min(dist_rail)
#   }
#   
#   if (grid_transports$DistToRoad[j] > 50000){
#     print(j)
# 
#     # Calculate distance to the closest road
#     dist_road <- st_distance(x = grid_transports[j,], y = road_chull)
#     grid_transports$DistToRoad[j] <- min(dist_road)
#   }
# }
# 
# # Check result
# grid_transports %>% filter(DistToRail == Inf | is.na(DistToRail))
# grid_transports %>% filter(DistToRoad == Inf | is.na(DistToRoad))
# 
# # Save file
# st_geometry(grid_transports) <- NULL
# write.csv(grid_transports, file.path(here(), "exported-data", "distances_observed_transports_complete.csv"), row.names = F)
```

\newpage


# 3. Create datasets for jumpers/diffusers/negatives

We need to associate each point to the fact that it's a jumper, or diffuser, or negative point, by merging the table with observed distances and the table with status.

1. Prepare the tables
```{r choose which dataset you are testing}

grid_poi <- read.csv(file.path(here(), "exported-data", "distances_observed_highrisk.csv"))
head(grid_poi)
dim(grid_poi)


# Merge it with the grid data to get the whole dataset back, including column slf established
slfPA <- read.csv(file.path(here(), "exported-data", "slfPA.csv"))
dim(slfPA)

slfPA %<>% left_join(dist_poi) %>% select(-c(GID_0, NAME_0, GID_1, NAME_1, NL_NAME_1, GID_2, NAME_2, VARNAME_2, NL_NAME_2, TYPE_2, CC_2, HASC_2, ENGTYPE_2))
head(slfPA)
dim(slfPA)

# Verify if all points got a distance
missingdata <- slfPA %>% filter(DistToMail == Inf | is.na(DistToMail))
dim(missingdata)
slfPA %>% filter(DistToRoad == Inf | is.na(DistToRoad))
slfPA %>% filter(DistIntRlRd == Inf | is.na(DistIntRlRd))

# Visualize the SLF data
ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = missingdata, col = "blue") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)

# Create the categories diffusers (if established) or negatives (if not)
slfPA %<>% mutate(Category_out = ifelse(slf_established == TRUE, "Diffusers", "Negatives"))

# Next load the dataset that contains all jumpers identified by sets of parameters
jumpers <- read.csv(file.path(here(), "exported-data", "jumps_full_rarefied.csv"))
jumpers %<>% add_column(Category = "Jumpers")
```

2. Create full dataset (multiple jumps per location)
```{r create full dataset}
# Put jumpers into the grid data and complete with the rest
# Verify if all jumps are added or only PA!
slfPA_full <- slfPA %>% 
  left_join(jumpers %>% select(latitude_rounded, longitude_rounded, bio_year, Category, Status)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(slfPA_full %>% filter(Category == "Jumpers"))[1] == dim(jumpersPA)[1]

slfPA_full %<>% rename(Category_full = Category)
```

3. Create rarefied dataset (one jump per location)
```{r create rarefied dataset}
# Put jumpers into the grid data and complete with the rest
slfPA_rarefied <- slfPA %>% 
  left_join(jumpers %>% filter(Rarefied == TRUE) %>% 
                                    select(latitude_rounded, longitude_rounded, bio_year, Category, Status)) %>% 
  mutate(Category = ifelse(is.na(Category), Category_out, Category)) %>% 
  select(-Category_out)

# Verify we still have the right number of jumps
dim(slfPA_rarefied %>% filter(Category == "Jumpers"))[1] == dim(jumpersPA %>% filter(Rarefied == TRUE))[1]

slfPA_rarefied %<>% rename(Category_rarefied = Category) 
```


4. Reassemble in one long dataset with one column for the type of dataset
```{r reassemble full and rarefied dataset}
slfPA_cat <- merge(slfPA_full, slfPA_rarefied)

write.csv(slfPA_cat, file.path(here(), "exported-data", "slfPA_cat.csv"), row.names = F)
```

\newpage



# 4. Create dataset "as of today" or "most up to date"

Count each point only once as positive or negative (summarise data for each point)
```{r generate a grid of unique points for situation as of 2020}

slfPA_cat <- read.csv(file.path(here(), "exported-data", "slfPA_cat.csv"))
dim(slfPA_cat)

# Show the number of duplicates per point
slfPA_cat %>% group_by(latitude_rounded, longitude_rounded) %>% count() %>% 
  group_by(n) %>% count(n)

# Order the category level
unique(slfPA_cat$Category_rarefied)
slfPA_cat$Category_rarefied <- factor(slfPA_cat$Category_rarefied, levels = c("Negatives", "Diffusers", "Jumpers"))
slfPA_cat$Category_full <- factor(slfPA_cat$Category_full, levels = c("Negatives", "Diffusers", "Jumpers"))


# Translate factors into ordinal
slfPA_uptodate <- slfPA_cat %>% mutate(Category_rare_num = as.numeric(Category_rarefied),
                    Category_full_num = as.numeric(Category_full)) %>%  
  group_by(latitude_rounded, longitude_rounded, DistToMail, DistToWood, DistToWineries, DistToPeople, DistToGarages, DistToBoats, DistToOther, DistToAirport, DistToPort) %>% 
  summarize(Category_rare_max = max(Category_rare_num),
            Category_full_max = max(Category_full_num)) %>% 
  mutate(Category_rare = recode(Category_rare_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers"),
         Category_full = recode(Category_full_max, "1" = "Negatives", "2" = "Diffusers", "3" = "Jumpers")) %>% 
  select(-Category_rare_max, -Category_full_max)
  

dim(slfPA_uptodate) #21,601
head(slfPA_uptodate)

# Save this file
write.csv(slfPA_uptodate, file.path(here(), "exported-data", "slfPA_uptodate.csv"), row.names=F)
```


Calculate statistics
```{r calculate proportions of data}
positive <- slfPA_uptodate %>% filter(Category_full %in% c("Diffusers", "Jumpers")) 
dim(positive)[1]/dim(slfPA_uptodate)[1] #17.93%
```

\newpage




# 5. Generate a random dispersal distribution of distances of jumpers to high-risk areas

The idea is to generate a distribution of distances to landscape features under the null hypothesis that SLF disperse randomly in the landscape. If a high number of random distributions are generated, we obtain the distribution of random dispersal distances to transports. The comparison of the random distribution and the observed average value gives the probability that the observed value is random.

Here, we generate 9,999 random datasets of distances to transport infrastructure within the convex hull of the positive SLF surveys. If the average value of the observed data is comprised within the simulated random values, it means that the pattern could be found by chance, and the distance between observed points and transport infrastructures is not significant.

To simplify calculations, we calculate all possible coordinates. We could remove those that were already calculated with slfPA, but here the calculation is relatively quick (and I could not make the code work because the coordinates seem to be slightly off between the slfPA and Coordinates_PA layers, for some reason)

Then the analysis consists in: (1) generating a random dataset of the same number of points as in the observed data, (2) for each random point, calculating the distance to transport infrastructures, (3) taking the average distance to each transport infrastructure for the dataset, (4) redoing the same cycle again for a total of 9,999 simulated random datasets.


## Create random coordinates
Form of PA
```{r PA form}
US <- st_read(file.path(here(), "figures", "GIS", "gadm36_Cont_USA_county.shp"), crs = "EPSG:4326", quiet = T)
st_crs(US)
US <- st_transform(US, crs = "ESRI:102010")
Pennsylvania <- US %>% filter(NAME_1 == "Pennsylvania")

# Visualize Pennsylvania
ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Pennsylvania, col = "blue") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)
```

Create coordinates
```{r dataset with points only for PA, echo=FALSE, warning =FALSE, message = FALSE}

# Load the SLF data
slfPA <- read.csv(file.path(here(), "exported-data", "slfPA_uptodate.csv"))

# (1) Calculate all potential coordinates
maxlat <- max(slfPA$latitude_rounded)
minlat <- min(slfPA$latitude_rounded)
maxlong <- max(slfPA$longitude_rounded)  
minlong <- min(slfPA$longitude_rounded)

Seqlat <- seq(from = minlat, to = maxlat, by = 1/111)
Seqlong <- seq(from = minlong, to = maxlong, by = 1/85)
Coordinates <- expand.grid(latitude_rounded = Seqlat, longitude_rounded = Seqlong)
Coordinates <- st_as_sf(x = Coordinates, coords = c("longitude_rounded", "latitude_rounded"), crs = "EPSG:4269", remove = F)
Coordinates <- st_transform(Coordinates, crs = "ESRI:102010")

# Plot this and check if this is correct
ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Coordinates, alpha = 0.5, col = "blue") +
  geom_sf(data = slfPA, col = "red") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# (2) Keep only those in PA
Coordinates_PA <- st_intersection(Coordinates, Pennsylvania)

ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Coordinates_PA, col = "blue") +
  geom_sf(data = slfPA, col = "red") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)

Coordinates_PA %<>% select(latitude_rounded, longitude_rounded, geometry)


# (3) Keep only the coordinates that are in the minimum convex polygon
chull <- st_read(file.path(here(), "figures", "GIS", "chull.shp"), quiet = T)

Coordinates_chull <- st_intersection(Coordinates, hull)

ggplot(data = US, fill = "white") +
  geom_sf() +
  geom_sf(data = Coordinates_chull, alpha = 0.5) +
  geom_sf(data = slfEstab_layer, col = "blue") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(1000000, 2000000), ylim = c(-200000, 600000), expand = FALSE)


# (4) Keep only those that are on land!
Coordinates_land <- st_intersection(Coordinates_chull, US)

random_coord <- ggplot(data = states, fill = "white") +
  geom_sf() +
  # geom_sf(data = Coordinates_land, alpha = 0.5) +
  geom_sf(data = hull, alpha = 0.5, fill = "white") + 
  geom_point(data = slfEstab_layer,
             aes(x = longitude_rounded, y = latitude_rounded), col = "black") +
  labs(x = "Longitude", y = "Latitude") +
  coord_sf(xlim = c(-82, -72), ylim = c(37, 43)) +
  theme_classic()


# Save file
Coordinates_land %<>% select(latitude, longitude, geometry)
st_geometry(Coordinates_land) <- NULL 
st_write(Coordinates_land, file.path(here(), "exported-data", "simulated_coordinates_PA.csv"))

```


## Calculate distances
Calculate distances to high risk for those points (copy paste code from above). Should be done in a few hours locally. 

Can reduce the time by removing points for which we already have data (observed data)

```{r select points with missing distances}
Coordinates_PA <- read.csv(file.path(here(), "exported-data",  "simulated_coordinates_PA.shp"))

grid_poi <- read.csv(file.path(here(), "exported-data", "distances_observed_highrisk.csv"), h=T)
grid_poi %<>% select()

Coordinates_simulated <- setdiff(Coordinates_PA, grid_poi)
``` 


```{r calculate distances of PA points to POI}

# Create rows for distances
Coordinates_simulated %<>% add_column(DistToMail = NA,
                      DistToWood = NA,
                      DistToWineries = NA,
                      DistToPeople = NA,
                      DistToGarages = NA,
                      DistToBoats = NA,
                      DistToOthers = NA,
                      DistToAirports = NA,
                      DistToPorts = NA)

# Transform into a sf layer
Coordinates_simulated <- st_as_sf(x = Coordinates_simulated, coords = c("longitude_rounded", "latitude_rounded"), crs = 4269, remove = F)
Coordinates_simulated <- st_transform(Coordinates_simulated, crs = "ESRI:102010")

#Calculate their distance to transport infrastructures
for (j in 1:length(Coordinates_simulated$DistToMail)){ 
  
  # Calculate distance to the closest mail-related point
  dist_mail <- st_distance(x = Coordinates_simulated[j,], y = mail_buffer)
  Coordinates_simulated$DistToMail[j] <- min(dist_mail)
  
  # Calculate distance to the closest wood-related point
  dist_wood <- st_distance(x = Coordinates_simulated[j,], y = wood_buffer)
  Coordinates_simulated$DistToWood[j] <- min(dist_wood)
  
  # Calculate distance to the closest winery
  dist_wine <- st_distance(x = Coordinates_simulated[j,], y = wineries_buffer)
  Coordinates_simulated$DistToWineries[j] <- min(dist_wine)
  
  # Calculate distance to the closest location for people
  dist_people <- st_distance(x = Coordinates_simulated[j,], y = people_buffer)
  Coordinates_simulated$DistToPeople[j] <- min(dist_people)
  
  # Calculate distance to the closest garage
  dist_garage <- st_distance(x = Coordinates_simulated[j,], y = garages_buffer)
  Coordinates_simulated$DistToGarages[j] <- min(dist_garage)

  # Calculate distance to the closest boat launch
  dist_boats <- st_distance(x = Coordinates_simulated[j,], y = boats_buffer)
  Coordinates_simulated$DistToBoats[j] <- min(dist_boats)
  
  # Calculate distance to the category others
  dist_others <- st_distance(x = Coordinates_simulated[j,], y = others_buffer)
  Coordinates_simulated$DistToOthers[j] <- min(dist_others)
  
  # Calculate distance to the closest airport
  dist_airport <- st_distance(x = Coordinates_simulated[j,], y = airportsPA)
  Coordinates_simulated$DistToAirport[j] <- min(dist_airport)
  
  # Calculate distance to the closest port
  dist_port <- st_distance(x = Coordinates_simulated[j,], y = portsPA)
  Coordinates_simulated$DistToPort[j] <- min(dist_port)
  
  if (j %% 1000 == 0){
    print(j)
    distances_random_PA <- Coordinates_simulated
    st_geometry(distances_random_PA) <- NULL
    write.csv(distances_random_PA, file.path(here(), "exported-data",  "distances_simulated_highrisk.csv"), row.names = F)  
    }
}


# Verify that there is no 0
Coordinates_simulated %>% filter(DistToMail == Inf | is.na(DistToMail))
Coordinates_simulated %>% filter(DistToWood == Inf | is.na(DistToWood))

st_geometry(Coordinates_simulated) <- NULL

# Reassemble the whole dataset
Coordinates <- rbind(Coordinates_simulated, grid_poi) 
dim(Coordinates)[1] == dim(Coordinates_PA)[1]
anyDuplicated(Coordinates)

# Save file
write.csv(Coordinates, file.path(here(), "exported-data",  "distances_simulated_highrisk.csv"), row.names = F)
```



## Select random dataset, full dataset
From slfPA uptodate (the dataset we use in the end)
```{r select random datasets}

# Load 
slfPA_uptodate <- read.csv(file.path(here(), "exported-data", "slfPA_uptodate.csv"))

Coordinates_simulated <- read.csv(file.path(here(), "exported-data", "distances_simulated_highrisk.csv"))

# Size of the dataset to be sampled
jumpers_full = dim(slfPA_uptodate %>% filter(Category_full == "Jumpers"))[1]

for (i in 1:9999){
  #Generate a set of coordinates
  Random_coordinates <- Coordinates_simulated[sample(nrow(Coordinates_simulated), size = jumpers_full, replace = F),] %>%
    add_column(Category_full = "Jumpers")
  
  #Calculate the mean and median distance per simulation
  Random_means <- Random_coordinates %>% group_by(Category_full) %>% 
    summarise_at(vars(starts_with("DistTo")), list(mean = mean, median = median, sd = sd)) %>% 
    add_column(Simulation = i)
  
  #Save the table with the simulation number
  if (i == 1){
    Simulations <- Random_means
  } else {
    Simulations <- bind_rows(Simulations, Random_means)
  }
  
  if (i %% 100 == 0){ print(i)}
} 

write.csv(Simulations, file.path(here(), "exported-data", "slf_sim_full_highrisk.csv"), row.names = F)
```


## Select random datasets, rarefied dataset

```{r select random datasets rarefied}

slfPA_cat <- read.csv(file.path(here(), "exported-data", "pointsPA_chull.csv"))

Coordinates_simulated <- read.csv(file.path(here(), "exported-data",  "distances_simulated_highrisk.csv"))

# Size of the dataset to be sampled
jumpers_rare = dim(slfPA_cat %>% filter(Category_rare == "Jumpers"))[1]


for (i in 1:9999){
  #Generate a set of coordinates
  Random_coordinates <- Coordinates_simulated[sample(nrow(Coordinates_simulated), size = jumpers_rare, replace = F),] %>%
    add_column(Category_rare = "Jumpers")
  
  #Calculate the mean distance per simulation
  Random_means <- Random_coordinates %>% group_by(Category_rare) %>% 
    summarise_at(vars(starts_with("DistTo")), list(mean = mean, median = median)) %>% 
    add_column(Simulation = i)
  
  #Save the table with the simulation number
  if (i == 1){
    Simulations <- Random_means
  } else {
    Simulations <- bind_rows(Simulations, Random_means)
  }
  
  if (i %% 100 == 0){ print(i)}
} 

write.csv(Simulations, file.path(here(), "exported-data", "slf_sim_rarefied_highrisk.csv"), row.names = F)
```


# Check a map of random points
```{r map of random points for jumpers, fig.width= 6, fig.height=7, eval = FALSE}
# Check on the first randomly generated dataset that the points location corresponds to the expectation in each disk portion (Figure 2).

states <- st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))

ggplot(data = states) +
    geom_sf(fill = "white") +
    geom_point(data = Random_coordinates,
            aes(x = longitude_rounded, y = latitude_rounded), shape = 19, size = 2) +
    labs(x = "Longitude", y = "Latitude")+
    theme(legend.position="top") +
  coord_sf(xlim = c(-81, -73), ylim = c(38, 42.5), expand = FALSE)

```


#6. Visualize results

Load observed data
```{r load observed data full}

# Convert the observed data to long format, get the average values
slfPA_uptodate <- read.csv(file.path(here(), "exported-data", "slfPA_uptodate.csv"))
dim(slf_uptodate)

# Convert to long format
slfPA_uptodate_long <- slfPA_uptodate %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

# Calculate mean and median
slf_obsmeans <- slfPA_uptodate_long %>% 
  group_by(Category_full, DistanceType) %>% 
  summarise(MeanDistance = mean(DistanceValue),
            MedianDistance = median(DistanceValue))

```

## Full dataset
Select mean and median for full dataset
```{r plot null distribution to high risk, fig.height=2, fig.width = 6, fig.cap="Comparison of the distance of jumpers to high-risk areas to a random distribution."}

# Load the simulated values
Simulations_full <- read.csv(file.path(here(), "exported-data", "slf_sim_full_highrisk.csv"))
names(Simulations_full)
head(Simulations_full)

# Convert simulations to long format
Simulations_full_long <- Simulations_full %>% pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

# Select only the means
# Modify this using by filtering those that contain "means"
# Simulations_full_long_mean <- Simulations_full_long %>%
  # filter(DistanceType %in% c("DistToRail_mean", "DistToRoad_mean"))
Simulations_full_long_mean$DistanceType <- factor(Simulations_full_long_mean$DistanceType, levels = c("DistToRail", "DistToRoad"))

# Select only the medians
# Modify this using by filtering those that contain "medians"
# Simulations_full_long_median <- Simulations_full_long %>% filter(DistanceType %in% c("DistToRail_median", "DistToRoad_median"))
Simulations_full_long_median$DistanceType <- factor(Simulations_full_long_median$DistanceType, levels = c("DistToRail", "DistToRoad"))
```

Visualize results
```{r mean and median for observed values}

#Plot means
random_transport <- ggplot() +
  geom_histogram(data = Simulations_full_long_mean %>% filter(Category_full == "Jumpers"), 
                 aes(x =  DistanceValue/1000, y = ..density.., fill = Category_full), binwidth = 0.1) +
  geom_vline(data = slf_obsmeans %>% filter(Category_full == "Jumpers"),
             mapping = aes(xintercept = MeanDistance/1000, col = Category_full), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

ggsave(file.path(here(), "figures", "jump_transports", "bootstrap_transports_fullmeans.jpg"), random_transport, width = 10, height = 3)



# Plot medians
random_transport <- ggplot() +
  geom_histogram(data = Simulations_full_long_median %>% filter(Category_full == "Jumpers"), 
                 aes(x =  DistanceValue/1000, y = ..density.., fill = Category_full), binwidth = 0.1) +
  geom_vline(data = slf_obsmeans %>% filter(Category_full == "Jumpers"),
             mapping = aes(xintercept = MedianDistance/1000, col = Category_full), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

random_transport

ggsave(file.path(here(), "figures", "vignette_transports", "bootstrap_transports_fullmedianschull_jumpers.jpg"), random_transport, width = 10, height = 3)
``` 

Count simulations
```{r count simulations}
# COUNT HOW MANY SIMULATIONS ARE SMALLER THAN THE OBS VALUE
obsrail <- slf_obsmeans %>% filter(Category_full == "Jumpers", DistanceType == "DistToRail") %>% pull(MedianDistance) 
dim(Simulations_full_long_median %>% filter(Category_full == "Jumpers", DistanceType == "DistToRail", DistanceValue < obsrail))[1]
#0

obsroad <- slf_obsmeans %>% filter(Category_full == "Jumpers", DistanceType == "DistToRoad") %>% pull(MedianDistance) 
dim(Simulations_full_long_median %>% filter(Category_full == "Jumpers", DistanceType == "DistToRoad", DistanceValue < obsrail))[1]
#0
```




## Rarefied dataset

Calculate mean and median for simulated data
```{r count simulations rarefied}

# Load the simulated values
Simulations_rare <- read.csv(file.path(here(), "exported-data", "slf_sim_rarefied_transports.csv"))

# Convert simulations to long format
Simulations_rare_long <- Simulations_rare %>% pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")
Simulations_rare_long %<>% rename(Category_rare = Category_rarefied) 
Simulations_rare_long$Category_rare <- factor(Simulations_rare_long$Category_rare, levels = c("Jumpers", "Diffusers", "Negatives"))


# Select only the means
Simulations_rare_long_mean <- Simulations_rare_long %>% filter(DistanceType %in% c("DistToRail_mean", "DistToRoad_mean", "DistToAirport_mean", "DistToPort_mean"))
Simulations_rare_long_mean$DistanceType <- as.factor(Simulations_rare_long_mean$DistanceType)
levels(Simulations_rare_long_mean$DistanceType)
levels(Simulations_rare_long_mean$DistanceType) <- c("DistToAirport", "DistToPort", "DistToRail", "DistToRoad")

# Select only the medians
Simulations_rare_long_median <- Simulations_rare_long %>% filter(DistanceType %in% c("DistToRail_median", "DistToRoad_median", "DistToAirport_median", "DistToPort_median"))
Simulations_rare_long_median$DistanceType <- as.factor(Simulations_rare_long_median$DistanceType)
levels(Simulations_rare_long_median$DistanceType)
levels(Simulations_rare_long_median$DistanceType) <- c("DistToAirport", "DistToPort", "DistToRail", "DistToRoad")
```

Visualize results
```{r visualize rare}

#Plot means
random_transport <- ggplot() +
  geom_histogram(data = Simulations_rare_long_mean %>% filter(Category_rare == "Jumpers"), 
                 aes(x =  DistanceValue/1000, y = ..density.., fill = Category_rare), binwidth = 0.1) +
  geom_vline(data = slf_obsmeans,
             mapping = aes(xintercept = MeanDistance/1000, col = Category_rare), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~Category_rare + DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

ggsave(file.path(here(), "figures", "vignette_transports", "bootstrap_transports_raremeanschull.jpg"), random_transport, width = 10, height = 9)


# Plot median
random_transport <- ggplot() +
  geom_histogram(data = Simulations_rare_long_median %>% filter(Category_rare == "Jumpers"), 
                 aes(x =  DistanceValue/1000, y = ..density.., fill = Category_rare), binwidth = 0.1) +
  geom_vline(data = slf_obsmeans %>% filter(Category_rare == "Jumpers"),
             mapping = aes(xintercept = MedianDistance/1000, col = Category_rare), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

ggsave(file.path(here(), "figures", "vignette_transports", "bootstrap_transports_raremedianschull_jumpers.jpg"), random_transport, width = 10, height = 3)

#Same?
random_highrisk <- ggplot() +
  geom_histogram(data = randomPA_long_median %>% filter(Category_full == "Jumpers"), aes(x =  DistanceValue/1000, y = ..density.., fill = Category_full), binwidth = 0.1) +
  geom_vline(data = slfPA_obsmeans %>% filter(Category_full == "Jumpers"), mapping = aes(xintercept = MedianDistance/1000, col = Category_full), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

  # coord_cartesian(ylim = c(0,1)) +
  # facet_wrap(~DistanceType, ncol = 3, scale = "free") +
  # theme_classic()

ggsave(file.path(here(), "figures", "vignette_highrisk", "bootstrap_highrisk_chull_median_full.jpg"), random_highrisk, width = 10, height = 6)
```

```{r plot null distribution to high risk, fig.height=2, fig.width = 6, fig.cap="Comparison of the distance of jumpers to high-risk areas to a random distribution."}

# Simulated means
MeanDistances <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "SimulatedMeans_rarehighriskPA.csv"))

#Modify dataset to get distribution of distances with a column for the type of distance, and one column for the type of dataset (Full or Rarefied)
randomPA_long <- MeanDistances %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))


random_highrisk <- ggplot() +
  geom_histogram(data = randomPA_long_median %>% filter(Category_rare == "Jumpers"), aes(x =  DistanceValue/1000, y = ..density.., fill = Category_rare), binwidth = 0.1) +
  geom_vline(data = slfPA_obsmeans %>% filter(Category_rare == "Jumpers"), mapping = aes(xintercept = MedianDistance/1000, col = Category_rare), size = 1) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  xlab("Distance to the nearest... (km)") +
  ylab("Count (simulations)") +
  facet_wrap(~DistanceType, ncol = 4, scale = "free") +
  theme_classic() +
  guides(col = guide_legend("SLF category"), fill = guide_legend("SLF category"))

  # coord_cartesian(ylim = c(0,1)) +
  # facet_wrap(~DistanceType, ncol = 3, scale = "free") +
  # theme_classic()

ggsave(file.path(here(), "figures", "vignette_highrisk", "bootstrap_highrisk_chull_median_rare.jpg"), random_highrisk, width = 10, height = 6)


```

Count simulations
```{r count simulations rare}

# Count how many simulations are lower than the observed data
# If it's below 5% it's not random
obsboats <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBoats") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBoats", DistanceValue < obsboats))[1]/10000
#0.0032

obsbottle <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBottling") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToBottling", DistanceValue < obsbottle))[1]/10000
#0.008

obsintermodal <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToIntermodal") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToIntermodal", DistanceValue < obsintermodal))[1]/10000
#0.1014


obstruck <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToTruckStop") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToTruckStop", DistanceValue < obstruck))[1]/10000
#0.4375


obswineries <- slfPA_obsmeans %>% filter(Category_rare == "Jumpers", DistanceType == "DistToWineries") %>% pull(MedianDistance) 
dim(randomPA_long_median %>% filter(Category_rare == "Jumpers", DistanceType == "DistToWineries", DistanceValue < obswineries))[1]/10000
#0.0537
```

# 7. Calculate effect sizes

Load observed data
```{r load observed data}
# Observed data
slfPA_cat <- read.csv(file.path(here(), "exported-data", "slfPA.csv"))

slfPA_cat_long <- slfPA_cat %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

slfPA_obsmeans <- slfPA_cat_long %>% 
  group_by(Category_full, DistanceType) %>% 
  summarise(MeanDistance = mean(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmeans %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))

slfPA_obsmeans$Category_full <- factor(slfPA_obsmeans$Category_full, levels = c("Jumpers", "Diffusers", "Negatives"))
randomPA_long$Category_full <- factor(randomPA_long$Category_full, levels = c("Jumpers", "Diffusers", "Negatives"))
```

## Full dataset
Means
Calculate mean and median for full dataset
```{r mean and median for simulated values}

# mean
randomPA_long_mean <- randomPA_long %>% filter(grepl("_mean", DistanceType))
head(randomPA_long_mean)
randomPA_long_mean$DistanceType <- as.factor(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType) <- gsub(pattern = "_mean", replacement = "", x = levels(randomPA_long_mean$DistanceType))

head(randomPA_long_mean)
summary_sim_full <- randomPA_long_mean %>% group_by(Category_full, DistanceType) %>% summarise(mean_sim = mean(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_full)

# calculate effect size
summary_full <- merge(summary_sim_full, slfPA_obsmeans)
summary_full %<>% rename(mean_obs = MeanDistance) %>% 
  mutate(effect_size = (mean_obs - mean_sim)/sd_sim)
write.csv(summary_full, "summary_simulations_full.csv")


Category = as.vector(unique(summary_full$DistanceType))
str(Category)
Properties = c("Boat launches and marinas", 
               "Bottling plants",
               "Colleges",
               "Distribution centers",
               "Truck garages and auto repairs",
               "Intermodal platforms",
               "Amazon fulfillment, Fedex and UPS",
               "Farmers markets",
               "Moving companies",
               "Popular destinations: amusement parks, auction centers, campgrounds, casinos, fairgrounds, flea markets, race tracks, stadiums, summer camps",
               "Truck stops",
               "Wineries",
               "Landscaping companies, lumber yards, sawmills")
Names <- data.frame(DistanceType = Category, Properties = Properties)


summary_full_cat <- merge(summary_full, Names)
write.csv(summary_full_cat, "summary_simulations_full.csv")
```

Medians
```{r plot median full}

randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
head(randomPA_long_median)
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))


head(randomPA_long_median)
summary_sim_medianfull <- randomPA_long_median %>% group_by(Category_full, DistanceType) %>% summarise(median_sim = median(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_medianfull)


summary_medianfull <- merge(summary_sim_medianfull, slfPA_obsmedians)
summary_medianfull %<>% rename(median_obs = MedianDistance) %>% 
  mutate(effect_size = (median_obs - median_sim)/sd_sim)
write.csv(summary_medianfull, "summary_simulations_median_full.csv")


summary_medianfull_cat <- merge(summary_medianfull, Names)
write.csv(summary_medianfull_cat, "summary_simulations_median_full.csv")
```

Visualize results
```{r plot}

# Plot means
ggplot(summary_full_cat, aes(y = effect_size, x = DistanceType)) + 
  geom_point(aes(col = Category_full)) +
  # scale_fill_brewer(palette = "Dark2") +
  # facet_wrap(~Category_full, scales = "free_y", ncol = 1) +
             # labeller = labeller(DistanceType = 
  #   c("DistToAirport" = "Airport",
  #     "DistToBoats" = "Boating",
  #     "DistToBottling" = "Bottling plants",
  #     "DistToColleges" = "Colleges",
  #     "DistToDistrib" = "Distribution centers",
  #     "DistToGarages" = "Garages",
  #     "DistToIntermodal" = "Intermodal platforms",
  #     "DistToMail" = "Mail carriers",
  #     "DistToMarket" = "Farmers market",
  #     "DistToMoving" = "Moving companies",
  #     "DistToPeople" = "Popular destinations",
  #     "DistToPort" = "Port",
  #     "DistToRail" =  "Railroad",
  #     "DistToRoad" = "Major road",
  #     "DistToTruckStop" = "Truck stops",
  #     "DistToWineries" = "Wineries",
  #     "DistToWood" = "Wood-related activities"))) +
  # # coord_cartesian(ylim=c(0, 30000)) +
  # xlab("Category") + ylab("Distance to the nearest... (km)") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


## Rarefied dataset

Means full
```{r }
# Simulated means
MeanDistances <- read.csv(file.path(here(), "exported-data", "Distances_random distrib", "SimulatedMeans_rarehighriskPA.csv"))
names(MeanDistances)
head(MeanDistances)

#Modify dataset to get distribution of distances with a column for the type of distance, and one column for the type of dataset (Full or Rarefied)
randomPA_long <- MeanDistances %>%
  pivot_longer(cols = starts_with("DistTo"), names_to = "DistanceType", values_to = "DistanceValue")

randomPA_long_mean <- randomPA_long %>% filter(grepl("_mean", DistanceType))
head(randomPA_long_mean)
randomPA_long_mean$DistanceType <- as.factor(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType)
levels(randomPA_long_mean$DistanceType) <- gsub(pattern = "_mean", replacement = "", x = levels(randomPA_long_mean$DistanceType))


head(randomPA_long_mean)
summary_sim_rare <- randomPA_long_mean %>% group_by(Category_rare, DistanceType) %>% summarise(mean_sim = mean(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_rare)

summary_rare <- merge(summary_sim_rare, slfPA_obsmeans)
summary_rare %<>% rename(mean_obs = MeanDistance) %>% 
  mutate(effect_size = (mean_obs - mean_sim)/sd_sim)
write.csv(summary_rare, "summary_simulations_rare.csv")


summary_rare_cat <- merge(summary_rare, Names)
write.csv(summary_rare_cat, "summary_simulations_mean_rare.csv")
```

Medians full
```{r medians full}

## FOR MATT SLF 101 MEDIANS FULL
randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
head(randomPA_long_median)
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))


head(randomPA_long_median)
summary_sim_medianrare <- randomPA_long_median %>% group_by(Category_rare, DistanceType) %>% summarise(median_sim = median(DistanceValue), sd_sim = sd(DistanceValue))
head(summary_sim_medianrare)



slfPA_obsmedians <- slfPA_cat_long %>% 
  group_by(Category_rare, DistanceType) %>% 
  summarise(MedianDistance = median(DistanceValue)#,
            # MedianDistance = median(DistanceValue)
            )
slfPA_obsmedians %<>% filter(!DistanceType %in% c("DistToRoad", "DistToAirport", "DistToRail", "DistToPort"))



summary_medianrare <- merge(summary_sim_medianrare, slfPA_obsmedians)
summary_medianrare %<>% rename(median_obs = MedianDistance) %>% 
  mutate(effect_size = (median_obs - median_sim)/sd_sim)
write.csv(summary_medianrare, "summary_simulations_median_rare.csv")

summary_rare_mediancat <- merge(summary_medianrare, Names)
write.csv(summary_rare_mediancat, "summary_simulations_median_rare.csv")

randomPA_long_median <- randomPA_long %>% filter(grepl("_median", DistanceType))
randomPA_long_median$DistanceType <- as.factor(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType)
levels(randomPA_long_median$DistanceType) <- gsub(pattern = "_median", replacement = "", x = levels(randomPA_long_median$DistanceType))

```


We can visualize the results on Figure 2. The histogram represents the distribution of distances to high-risk areas under the null hypothesis of random dispersal of jumpers. The black vertical lines indicate the significance limits. An observed value situated outside of these vertical lines leads to the rejection of the null hypothesis. The red line indicates the average distance between jumpers and high-risk areas observed in our dataset. The observed location of jumpers is significantly closer than random to high-risk areas.  

\newpage 